\chapter{Method}\label{ch:method}

\section{Position Based Dynamics}\label{s:pbd}
As discussed in Section \ref{s:equations-of-motion}, classical approaches for dynamics simulation are force-based. Forces are accumulated and 
resulting accelerations are computed based on Newton's second law. These accelerations are then integrated over time via numerical integration. 
If successful, this strategy yields physically accurate results. However, designing integration schemes that are robust and stable,
particularly in the presence of stiff forces, is challenging. Corresponding issues often manifest themselves in the context of contact and collision 
handling. In real-time applications, physically accurate results are often not required. Thus, algorithms that yield visually
plausible simulations in a robust and stable manner are preferred. To address these needs, Müller et al.\ \cite{mueller2006} propose manipulating
positions directly on a per-constraint basis without integrating accelerations of velocities in an approach called Position Based Dynamics (PBD).
This way, collisions can simply be handled one-by-one by projecting particles to valid locations instead of by integrating accelerations from 
stiff forces, leading to improved robustness and controllability. 

The main drawback of PBD is that constraints become arbitrarily stiff when the iteration count is increased or when the time step is decreased.
Macklin et al.\ \cite{macklin2016} devise an extension of PBD called extended Position Based Dynamics (XPBD) that is derived from the implicit
integration of the equations of motion (see Eq.\ \ref{eq:equations-of-motion}) with constraint potentials based on PBD constraints. The overall structure 
of the PBD algorithms is preserved with 
minor changes to the projection of individual constraints. XPBD reduces the coupling of stiffness to iteration count and time step and relates 
constraints to corresponding, well-defined constraint forces. According to Macklin et al., XPBD and PBD are equivalent in the limit of infinite
stiffness. 

Since PBD and XPBD only differ in the way individual constraints are projected, we give a general overview over PBD-style algorithms 
in Section \ref{ss:pbd-framework}. 
The details of individual constraint projection in PBD and XPBD are covered in Section \ref{ss:pbd-constraint-projection} and 
Section \ref{ss:xpbd-constraint-projection}, respectively. A comprehensive discussion of the properties of both solvers is provided in 
Section \ref{ss:pbd-properties} and Section \ref{ss:xpbd-properties}, respectively. Lastly, we show how to simulate deformable bodies using physically-based 
material models with PBD in Section \ref{ss:pbd-deformable-bodies} and with XPBD in Section \ref{ss:xpbd-deformable-bodies}.

\subsection{Overview Over the PBD Framework}\label{ss:pbd-framework}
Both PBD and XPBD share the same algorithmic structure. Let a dynamic object be defined by a set of $m$ 
vertices with inverse masses $w_i$, positions $\vecm{q}_i$ and velocities $\vecm{v}_i$. Additionally, the motion of the object is governed by 
$r \in \mathbb{N}$ constraints of the form 

\[
C \colon \mathbb{R}^{3m} \to \mathbb{R}, \vecm{q} \mapsto C(\vecm{q})
\]

\noindent where $j$ is the constraint index. Note how constraints are defined solely in terms of particle positions. Equality and inequality constraints 
are satisfied if $C(\vecm{q}) = 0$ and $C(\vecm{q}) \geq 0$, respectively. In PBD, each constraint has an additional stiffness parameter $k_j \in [0,1]$. 
Each constraint has a cardinality $n_j \in \mathbb{N}$ and particle indices $i_1, \ldots, i_{n_j}$ of particles that actively contribute to the 
constraint value. In other words, for $l \in [1, \ldots, r]$ with $l \notin \{i_1, \ldots, i_{n_j}\}$ it is $\nabla_{\vecm{p}_l}C_j(\vecm{q}) = \vecm{0}$.

An overview over the PBD framework is given in Algorithm \ref{alg:pbd} \cite{mueller2006}. PBD and XPBD work by moving the particles according to their current 
velocities and the external forces acting on them and using the resulting positions as a starting point for constraint projection. This is achieved by 
performing symplectic Euler integration (lines 3-4). The resulting positions 
are projected onto the constraint manifolds of the constraints (line 5). Projecting a constraint means changing the positions of involved particles 
such that the constraint is satisfied and linear and angular momentum are preserved. The projected positions are used to carry out an implicit 
velocity update (line 7) and eventually passed on to the next time step (line 8) in correspondence with a Verlet integration step. Note that the only
difference between PBD and XPBD is the constraint projection in \textsc{projectConstraints} (line 5).

For general, nonlinear constraints, moving the initial estimates from the symplectic Euler integration to positions that satisfy the constraints
requires solving a nonlinear system of equations. Solving this system of equations is further complicated by the presence of inequality constraints, which
need to be added or removed depending on whether they are satisfied during the current iteration. Thus, Müller et al.\ \cite{mueller2006} opt for a 
nonlinear adaptation of the Gauss-Seidel solver in their original PBD solver. Macklin et al.\ \cite{macklin2016} adapt this approach in XPBD. 
Just like the original Gauss-Seidel algorithm, which is only suitable for linear systems of equations, 
constraints are solved independently one after another. During each constraint solve, only the particles that contribute to the current constraint are
moved while all the other particle positions remain untouched. Additionally, position updates from the projection of a constraint are immediately 
visible during the projection of the constraints following thereafter. Inequality constraints that are already satisfied are simply skipped. 
During each solver iteration, all constraints are cycled through once.

\begin{algorithm}
\caption{Position Based Dynamics Framework}\label{alg:pbd}
\begin{algorithmic}[1]
\Procedure{solvePBD}{$\vecm{q}_n$, $\vecm{v}_n$, $f_{\text{ext}}$, $h$}
\State $\vecm{q} = \vecm{q}_n, \vecm{v} = \vecm{v}_n$
\State \textbf{for} all vertices $i$ \textbf{do} $\vecm{v}_i = \vecm{v}_i + hw_i\vecm{f}_{\text{ext}}(\vecm{x}_i)$
\State \textbf{for} all vertices $i$ \textbf{do} $\vecm{p}_i = \vecm{q}_i + h\vecm{v}_i$
\State $\textsc{projectConstraints}(C_1, \ldots, C_r, \vecm{p}_1, \ldots, \vecm{p}_m)$ (\cref{alg:pbd-solver} for PBD, 
\StatexIndent[2] \cref{alg:xpbd-solver} for XPBD)
\For{all vertices $i$}
\State $\vecm{v}_i = (\vecm{p}_i - \vecm{q}_i) / h$
\State $\vecm{q}_i = \vecm{p}_i$
\EndFor
\State \textbf{return with } $\vecm{q}_{n+1} = \vecm{q}, \vecm{v}_{n+1} = \vecm{v}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Due to the fact that PBD is a geometrical method that is not derived from Newton's laws of motion (see Sec.\ \ref{ss:pbd-constraint-projection}) and that 
constraints are solved locally one after each 
other, Müller et al.\ \cite{mueller2006} take great care that projections for internal constraints, i.e.\ constraints that are independent of rigid-body 
motion, preserve linear and angular momentum. Otherwise, internal constraints may introduce ghost forces which manifest themselves in artificial 
rigid-body motion \cite{mueller2006}. Of course, non-internal constraints such as collision or 
attachment constraints may have global effects on an object. For internal constraints, it is easy to show that both momenta are automatically preserved 
if the PBD position updates are performed in the direction of the mass-weighted constraint gradient \cite{mueller2006}. Even though XPBD -- unlike 
PBD -- is in fact derived from Newton's second law, Macklin et al.\ \cite{macklin2016} arrive at position updates that are multiples of the mass-weighted 
constraint gradient as well after a couple of simplifying assumptions (see Sec.\ \ref{ss:xpbd-constraint-projection}). Thus PBD and XPBD projections 
are performed along the same direction and only differ in their scaling factors. The update formulas for a single constraint update in PBD and XPBD are 
derived in Section \ref{ss:pbd-constraint-projection} and Section \ref{ss:xpbd-constraint-projection} and the resulting algorithms for projecting all constraints 
acting on simulated bodies are given in Algorithm \ref{alg:pbd-solver} and Algorithm \ref{alg:xpbd-solver}, respectively.

\subsection{PBD Constraint Projection}\label{ss:pbd-constraint-projection}

Mueller et al.\ \cite{mueller2006} derive the projection of a single constraint in PBD as follows. Let $C$ be a constraint of cardinality $n_c$ 
acting on particles $i_1, \ldots, i_{n_c}$ with predicted positions $\vecm{p}_{i_1}, \ldots, \vecm{p}_{i_{n_c}}$. Let $k_c$ be the constraint 
stiffness. The goal is to find a position update $\Delta \vecm{p}$ such that 

\begin{equation}\label{eq:pbd-delta}
    C(\vecm{p} + \Delta \vecm{p}) = 0.
\end{equation}

\noindent To preserve linear and angular momenta, $\Delta \vecm{p}$ is required to be in the direction of the mass-weighted constraint 
gradient, or formally

\begin{equation}\label{eq:pbd-update-general}
    \Delta \vecm{p} = \lambda \matm{W} \nabla C(\vecm{p})
\end{equation}

\noindent for some $\lambda \in \mathbb{R}$ and $\matm{W} = \text{diag}(w_1, w_1, w_1, \ldots, w_m, w_m, w_m)$. 
Plugging into Equation \ref{eq:pbd-delta} and approximating by first-order Taylor expansion yields

\[
    C(\vecm{p} + \lambda \matm{W} \nabla C(\vecm{p})) \approx C(\vecm{p}) + \nabla C(\vecm{p})^T \lambda \matm{W}
    \nabla C(\vecm{p}) = 0.
\]

\noindent Solving for $\lambda$ yields

\begin{equation}\label{eq:pbd-lambda}
    \lambda = -\frac{C(\vecm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\vecm{p}_i}C(\vecm{p}) \vert^2 }.
\end{equation}

\noindent Plugging $\lambda$ into Equation \ref{eq:pbd-update-general} results in the final position update

\begin{equation}\label{eq:pbd-update}
    \Delta \vecm{p} = -\frac{C(\vecm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\vecm{p}_i}C(\vecm{p}) \vert^2 } 
    \matm{W}\nabla C(\vecm{p}).
\end{equation}

\noindent For the position of a single point $\vecm{p}_i$, this gives the update

\begin{equation}\label{eq:pbd-update-individual}
    \Delta \vecm{p}_i = -\frac{C(\vecm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\vecm{p}_i}C(\vecm{p}) \vert^2 } 
    w_i \nabla_{\vecm{p}_i} C(\vecm{p})
\end{equation}

Finally, the stiffness $k_c$ of the constraint needs to be taken into account. The simplest way is to simply multiply the projection update
$\Delta \vecm{p}$ by $k_c$. However, after multiple iterations of the solver, the effect of the stiffness on the update is nonlinear. Consider
a distance constraint with rest length 0 acting on predictions $\vecm{p}_{i_1}, \vecm{p}_{i_2}$ given by

\begin{equation}\label{eq:pbd-distance}
    C_{\text{dist}}(\vecm{p}) = \vert \vecm{p}_{i_1} - \vecm{p}_{i_2} \vert.
\end{equation}

\noindent Then, after $n_s$ solver iterations the remaning error is going to be $\vert \vecm{p}_{i_1} - \vecm{p}_{i_2} \vert (1-k)^{n_s}$. Müller et al.\ 
suggest establishing a linear relationship by multiplying corrections by $k^{\prime} = 1 - (1-k)^{1/n_s}$. This way, the error becomes
$\vert \vecm{p}_{i_1} - \vecm{p}_{i_2} \vert (1-k)$ after $n_s$ solver iterations. A summary of the constraint solver is given in Algorithm 
\ref{alg:pbd-solver}.

\begin{algorithm}
\caption{PBD Constraint Solver}\label{alg:pbd-solver}
\begin{algorithmic}[1]
\Procedure{projectConstraints}{$C_1, \ldots, C_r, \vecm{p}_1, \ldots, \vecm{p}_m$}
\For{all iterations $n_s$}
\ForNoDo{all constraints $C_j$ with cardinality $n_j$, } 
\StatexIndent[3] particle indices $i_1, \ldots, i_{n_j}$ \algorithmicdo
\If{$C_j$ is an inequality constraint and $C_j(\vecm{p}) \geq 0$}
\State \textbf{continue} to next constraint
\EndIf
\For{all particles $i \in \{ i_1, \ldots, i_{n_j} \}$}
\State $\Delta \vecm{p}_i = -\frac{C_j(\vecm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_j} \}} w_i \vert \nabla_{\vecm{p}_i}
C_j(\vecm{p}) \vert^2 } w_i \nabla_{\vecm{p}_i} C_j(\vecm{p})$
\State $\vecm{p}_i = \vecm{p}_i + k \Delta \vecm{p}_i$ or $\vecm{p}_i = \vecm{p}_i + (1-(1-k)^{1/n_s}) \Delta \vecm{p}_i$
\EndFor
\EndFor
\EndFor
\State \textbf{return with result } $\vecm{p}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Properties of PBD}\label{ss:pbd-properties}
Due to its simplicity and controllability, PBD is a popular choice for real-time simulations where visually plausible results are sufficient. 
In the following section, we take a closer look at the properties of the PBD solver.

\paragraph{Gauss-Seidel Solver.}
At the core of the PBD algorithm is the nonlinear Gauss-Seidel-type solver for constraint projections. Immediately making position
updates from one constraint projection visible in the following constraint projections enables faster propagation of 
constraints through the simulated body \cite{mueller2006}. However, the same property makes parallelization of the constraint projections 
in lines 8-9 of Algorithm \ref{alg:pbd-solver}
more challenging. Synchronization is required to make sure that constraints that involve the same particle do not run into race conditions. 
Alternatively, graph coloring algorithms where constraints of the same color are guaranteed to work on separate sets of particles can be employed. 
Due to the fact that constraints are handled individually, the solver is incapable of finding a 
compromise between contradicting constraints \cite{mueller2006, bouaziz2014}. In fact, oscillations can occur in over-constrainted situations. 
The exact result depends on the order in which constraints are handled.

\paragraph{Relation to the Newton-Raphson Method.}
The position update due to a single constraint $C$ in Equation \ref{eq:pbd-update} is related to the Newton-Raphson method for finding roots of nonlinear 
functions $f \colon \mathbb{R} \to \mathbb{R}$ \cite{mueller2006}. There, the current guess $x_i \in \mathbb{R}$ for a root of $f$ is refined 
using the following update formula 

\begin{equation}\label{eq:newton-raphson}
    x_{i+1} = x_i - \frac{f(x_i)}{f^{\prime}(x_0)}.
\end{equation}

\noindent Indeed, applying the Newton-Raphson update to 

\begin{equation}\label{eq:newton-raphson-f}
    f \colon \mathbb{R} \to \mathbb{R}, \lambda \mapsto C(\vecm{p} + \lambda \matm{W} \nabla C(\vecm{p}))
\end{equation}

\noindent yields

\[
    \lambda_{i+1} = \lambda_i - \frac{C(\vecm{p}_i + \lambda_i \matm{W} \nabla C(\vecm{p}_i))}
    {\nabla C(\vecm{p}_i + \lambda_i \matm{W} \nabla C(\vecm{p}_i))^T \matm{W} \nabla C(\vecm{p}_i)}.
\]

\noindent With $\lambda_0 = 0$, the update formula for the first iteration is 

\[
    \lambda_1 = -\frac{C(\vecm{p}_0)}{\nabla C(\vecm{p}_0)^T \matm{W} \nabla C(\vecm{p}_0)}.
\]

\noindent Here, subscripts denote the current iteration instead of the particle index. Note that this is exactly the same as the formula for 
$\lambda$ used in the constraint solver given in Equation \ref{eq:pbd-lambda}. Thus, a single 
constraint projection corresponds to the first iteration of the Newton-Raphson method applied to Equation \ref{eq:newton-raphson-f} with 
$\lambda_0 = 0$. It is worth pointing out that the correspondence breaks down after the first iteration of PBD constraint projections. To 
see this, consider the second PBD iteration for the constraint $C$ under the assumption that the positions of the particles that $C$ acts on 
are not altered by any other constraint projections. Then, the second constraint projection is simply

\[
    \lambda_2 = -\frac{C(\vecm{p_1})}{\nabla C(\vecm{p}_1)^T \matm{W} \nabla C(\vecm{p}_1)}.
\]

\noindent However, since the positions after the first iteration are given by $\vecm{p}_1 = \vecm{p}_0 + \lambda_1 \matm{W} \nabla C(\vecm{p_0})$, 
the corresponding Newton-Raphson update is equivalent to 

\[
    \lambda_2 = \lambda_1 - \frac{C(\vecm{p}_1)}{\nabla C(\vecm{p}_1)^T \matm{W} \nabla C(\vecm{p}_0)}.
\]

\noindent Due to these differences, it is not clear whether convergence and stability guarantees of the Newton-Raphson solver are applicable to 
PBD constraint projection.

\paragraph{Stability.}
Müller et al.\ \cite{mueller2006} claim that PBD is unconditionally stable since the projected positions $\vecm{p}_i$ computed by the constraint 
solver are physically valid in the sense that all constraints are satisfied and no extrapolation into the future takes place in lines 7-8 of
Algorithm \ref{alg:pbd}. They further state that the only source of instabilities is the constraint solver itself, which is based on the 
Newton-Raphson method. The position updates in Equation \ref{eq:pbd-update-individual} are independent of the time step and solely depend on the 
shape of the constraints. 

At this point, it is worth taking into consideration that the constraint solver does not always succeed at moving 
particles to physically valid positions as implied. As mentioned above, oscillations can occur if there are contradictory constraints. 
In particular, constraint projections that are performed towards the end might undo progress achieved by previous projections. 
Moreover, we have shown above that the correspondence between the PBD constraint projections and the Newton-Raphson method breaks down 
after the first iteration. However, since it is known that the Newton-Raphson solver may fail to converge if the initial guess $\lambda_0$
is not sufficiently close to a true root $\lambda^*$ of Equation \ref{eq:newton-raphson-f}, it is expected that the same issue can occur for 
repeated applications of PBD constraint projections. Lastly, for general nonlinear constraints, it is the shape of the constraint at the 
current configuration that matters for the stability of the position update. Whether Newton-Raphson iterations are effective or not cannot be 
answered for a function -- or in this case for a constraint -- in its entirety, but only in the proximity of specific values.

\paragraph{Dependence of Stiffness On Iterations and Time Step Size.}
The main disadvantage of PBD is the fact that the stiffness depends on the iteration count and the chosen time step \cite{mueller2006}. Again, 
we take a look at
a distance constraint with rest length 0 (see Eq.\ \ref{eq:pbd-distance}). As discussed in Section \ref{ss:pbd-constraint-projection}, the remaining error after
$n_s$ solver iterations is simply $\vert \vecm{p}_{i_1} - \vecm{p}_{i_2} \vert (1-k)^{n_s}$. In the limit of infinite iterations

\[
    \lim_{n_s \to \infty} (\vert \vecm{p}_{i_1} - \vecm{p}_{i_2} \vert (1-k)^{n_s}) = 0,
\]

\noindent meaning that the distance constraint becomes infinitely stiff, regardless of the exact value of $k_c$. If instead $k^{\prime}
= 1 - (1-k)^{1/n_s}$ is used, then the error after $n_s$ solver iterations becomes $\vert \vecm{p}_{i_1} - \vecm{p}_{i_2} \vert (1-k)$. Thus,
infinite stiffness due to large iteration counts is prevented in this setting. However, the perceived stiffness still depends on the time
step. In the limit of infinitely short time steps, the material is going to appear infinitely stiff. Generally, soft bodies can only be 
simulated by restricting the number of PBD iterations.

\paragraph{Preservation of Individual Momenta.}
While the simulated object's global linear and angular momentum are preserved, the linear momenta of individual particles are at risk of 
being washed out by the PBD constraint solver \cite{bouaziz2014}. This is because even though the structure of the position updates 
preserves global momentum, there is no punishment for moving individual particles away from their inertial positions. Generally, the 
penalty for moving particles away from their inertial positions should increase with growing particle masses. However, in the PBD
position update in Equation \ref{eq:pbd-update-individual} it is only the ratio of the particle masses that matters. This can be seen by multiplying
all inverse masses $w_i$ in Equation \ref{eq:pbd-update-individual} with a constant factor $a \in \mathbb{R}^+$:

\begin{equation}\label{eq:pbd-masses}
    \begin{split}
        \Delta \vecm{p}_i 
        &= -\frac{C(\vecm{p})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} aw_j \vert \nabla_{\vecm{p}_j}C(\vecm{p}) \vert^2 } aw_i \nabla_{\vecm{p}_i} C(\vecm{p}) \\
        &= -\frac{C(\vecm{p})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} \frac{aw_j}{aw_i} \vert \nabla_{\vecm{p}_j}C(\vecm{p}) \vert^2 } \nabla_{\vecm{p}_i} C(\vecm{p}) \\
        &= -\frac{C(\vecm{p})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} \frac{w_j}{w_i} \vert \nabla_{\vecm{p}_j}C(\vecm{p}) \vert^2 } \nabla_{\vecm{p}_i} C(\vecm{p})
    \end{split}
\end{equation}

\noindent Note that the factor $a$ gets cancelled out, meaning that increasing or decreasing the weights of all particles in the simulation by a constant
factor does not affect position updates. Washing out of individual momenta also becomes evident in the limit of infinite iterations while multiplying 
with the stiffness $k_c$ directly, or in the limit of infinitely short time steps. In both cases, the simulated material will appear infinitely stiff, 
meaning that momenta of individual particles are not necessarily preserved.

\subsection{Simulating Deformable Bodies using PBD}\label{ss:pbd-deformable-bodies}
As discussed in Section \ref{ss:pbd-constraint-projection}, the PBD constraint projection is designed to solve geometric constraints. However, Bender et al.\ 
\cite{bender2014} simulate continuous elastic materials by deriving constraints from physical material models. Let $\Psi$ be the energy density of the 
material model and let $E_e$, $\matm{F}_e$ and $V_e$ be the elastic energy, deformation gradient and volume of a tetrahedral element $e$, respectively
(see Sec.\ \ref{ss:deformable-bodies}). Then, the authors introduce a constraint $C_e$ with $C_e(\vecm{q}) = E_e(\vecm{q}) = V_e\Psi(\matm{F}_e)$ for each 
tetrahedral element, with small adjustments to achieve robust inversion handling. In short, the tetrahedral energies are simply repurposed as geometric 
constraints. Note that this approach for simulating 
deformable bodies comes with the disadvantages inherent to PBD (see Sec.\ \ref{ss:pbd-properties}). Most notably, the perceived stiffness of the material is 
dependent on the time step size and the number of iterations. In the limit of infinite iterations and zero time step size, the simulated body will 
appear rigid. As a result, the simulations are not physically accurate, even though the constraints are derived directly from the energy density $\Psi$. 
Still, complex physical phenomena such as lateral contraction can be simulated with PBD using this setup \cite{bender2014}.

\subsection{XPBD Constraint Projection}\label{ss:xpbd-constraint-projection}
The derivation of XPBD \cite{macklin2016} starts from the position-level implicit Euler update formula for the equations of motion 
(see Eq.\ \ref{eq:implicit-positional-detailed}), which is restated here again for the sake of convenience

\begin{equation}\label{eq:implicit-positional-detailed-2}
    \matm{M}(\vecm{q}_{n+1} - \vecm{q}_n - h\vecm{v}_n) = h^2\left(\vecm{f_\text{ext}} - \sum_j \nabla \psi_j(\vecm{q}_{n+1})\right).
\end{equation}

\noindent Let $m$ be the number of particles in the simulated body and $r$ be the number of conservative potentials $\psi_j$ with $j \in [1, r]$.
In the context of XPBD, $\vecm{q}, \vecm{v}, \vecm{f}_{\text{ext}} \in \mathbb{R}^{3m}$ and $\psi_j \colon \mathbb{R}^{3m} \to \mathbb{R}$. Simple 
manipulation of Equation \ref{eq:implicit-positional-detailed-2} yields

\begin{equation}\label{eq:implicit-positional-detailed-3}
    \matm{M} \left( \vecm{q}_{n+1} - \tilde{\vecm{q}} \right) = - h^2 \sum_j \nabla \psi_j(\vecm{q}_{n+1}),
\end{equation}

\noindent where $\tilde{\vecm{q}} = \vecm{q}_n + h\vecm{v}_n + h^2 \matm{M}^{-1} \vecm{f}_{\text{ext}}$ is the predicted, inertial position. XPBD builds on
top of the compliant constraint formulation discussed in Section \ref{ss:compliant-constraints}. In the compliant constraint framework, each $\psi_j$ 
can be written in terms of some positional constraint function $C_j$ 

\begin{equation}\label{eq:xpbd-potential-j}
    \psi_j(\vecm{q}) = \frac{1}{2} \alpha^{-1}_j C_j(\vecm{q})^2,
\end{equation}

\noindent where $\alpha_j$ is the inverse stiffness of the constraint. If the constraint functions are grouped into a vector-valued function
$\vecm{C}$ with $\vecm{C}(\vecm{q}) = [C_1(\vecm{q}), \ldots, C_r(\vecm{q})]^T$ and the inverse stiffnesses are aggregrated into the diagonal matrix
$\matm{\alpha} = \text{diag}(\alpha_1, \ldots, \alpha_r)$, then

\begin{equation}\label{eq:xpbd-potential}
    \psi(\vecm{q}) \coloneqq \sum_j \psi_j(\vecm{q}) = \frac{1}{2}\vecm{C}(\vecm{q})^T \matm{\alpha}^{-1} \vecm{C}(\vecm{q}).
\end{equation}

\noindent where $\psi$ is the combined internal energy potential. The force from the internal potential is given by

\begin{equation}\label{eq:xpbd-internal-force}
    \vecm{f}_{\text{int}} = -\nabla \psi(\vecm{q}) = -\nabla \vecm{C}(\vecm{q})^T \matm{\alpha}^{-1} \vecm{C}(\vecm{q}).
\end{equation}

\noindent Plugging the internal force $\vecm{f}_{\text{int}}$ into Equation \ref{eq:implicit-positional-detailed-3} and pulling $h^2$ into the 
compliance matrix $\matm{\alpha}$ results in

\[
    \matm{M}(\vecm{q}_{n+1} - \tilde{\vecm{q}}) = - \nabla C(\vecm{q}_{n+1})^T \tilde{\matm{\alpha}}^{-1} \vecm{C}(\vecm{q}_{n+1}),
\]

\noindent where $\tilde{\matm{\alpha}} = \frac{\matm{\alpha}}{h^2}$. Now, the internal force $\vecm{f}_{\text{int}}$ is split into a directional 
and a scalar component by introducing the Lagrange multiplier

\begin{equation}\label{eq:lagrange-multiplier}
    \vecm{\lambda} = -\tilde{\matm{\alpha}}^{-1}\vecm{C}(\vecm{q}).
\end{equation}

\noindent This leads to the following nonlinear system of equations in terms of $\vecm{q}_{n+1}$ and $\vecm{\lambda}_{n+1}$:

\begin{align}
    \matm{M}(\vecm{q}_{n+1} - \tilde{\vecm{q}}) - \nabla (\vecm{q}_{n+1})^T \vecm{\lambda}_{n+1} &= \vecm{0} \label{eq:xpbd-g} \\
    \vecm{C}(\vecm{q}_{n+1}) + \tilde{\matm{\alpha}}\vecm{\lambda}_{n+1} &= \vecm{0} \label{eq:xpbd-h}.
\end{align}

\noindent The left-hand side of Equation \ref{eq:xpbd-g} and Equation \ref{eq:xpbd-h} are referred to as $\vecm{g}$ and $\vecm{h}$, respectively. The nonlinear 
system of equations is solved using a fixed-point iteration based on Newton's method. We replace the index $(n+1)$ indicating the current
time step by the index of the current guess in the fixed-point iteration indicated by $(i+1)$ for the sake of clarity. During each iteration, 
guesses $\vecm{q}_i, \vecm{\lambda}_i$ for a solution of the nonlinear system are improved by updates $\Delta \vecm{q}, \Delta \vecm{\lambda}$ to 
yield new iterates $\vecm{q}_{i+1}, \vecm{\lambda}_{i+1}$. The updates are determined by solving the following linear system of equations, 
which arises from the linearization of Equation \ref{eq:xpbd-g} and Equation \ref{eq:xpbd-h}:

\begin{equation}\label{eq:xpbd-lse}
    \begin{pmatrix}
        \matm{K} & -\nabla\vecm{C}^T(\vecm{q}_i)\\
        \nabla\vecm{C}(\vecm{q}_i) & \tilde{\matm{\alpha}}
    \end{pmatrix}
    \begin{pmatrix}
        \Delta \vecm{q} \\
        \Delta \vecm{\lambda}
    \end{pmatrix}
    = -
    \begin{pmatrix}
    \vecm{g}(\vecm{q}_i, \vecm{\lambda}_i) \\
    \vecm{h}(\vecm{q}_i, \vecm{\lambda}_i)
    \end{pmatrix},
\end{equation}

\noindent Here, $\matm{K}$ is partial derivative of $\vecm{g}$ with respect to $\vecm{q}$ at $\vecm{q}_i$ given by

\begin{equation}\label{eq:xpbd-K}
    \matm{K} = \frac{\partial \vecm{g}}{\partial \vecm{q}}(\vecm{q}_i) = \matm{M} - \frac{\partial \nabla \vecm{C}(\vecm{q_i})^T \vecm{\lambda_i}}{\partial \vecm{q}}.
\end{equation}

\noindent Note how the second term on the right side corresponds to the geometric stiffness $d\vecm{f}(\vecm{q})/d\vecm{q}$ 
\cite{tournier2015}. We refer to the system matrix of Equation \ref{eq:xpbd-lse} as $\matm{H}$. At this point, two simplifying assumptions 
are made.

\paragraph{Assumption 1.} Computing the geometric stiffness in $\matm{K}$ requires evaluating second derivatives of the constraint functions
$C_j$. This is expensive and error-prone. To avoid the challenges of computing second derivatives and to re-establish a connection 
to PBD (see Sec.\ \ref{ss:pbd-constraint-projection}), Macklin et al.\ \cite{macklin2016} drop the geometric stiffness by approximating 

\begin{equation}\label{eq:xpbd-assumption-1}
    \matm{K} \approx \matm{M}. 
\end{equation}

\noindent According to the authors, this simplification does not affect the solution that the fixed-point iteration converges to. However, 
altering the system matrix decreases the convergence rate akin to a Quasi-Newton method for solving nonlinear systems of equations.

\paragraph{Assumption 2.} Macklin et al.\ \cite{macklin2016} further assume that 

\begin{equation}\label{eq:xpbd-assumption-2}
    \vecm{g}(\vecm{q}_i, \vecm{\lambda}_i) = \vecm{0}. 
\end{equation}

\noindent If initial guesses
$\vecm{q}_0 = \tilde{\vecm{q}}$ and $\vecm{\lambda}_0 = \vecm{0}$ are used, plugging into Equation \ref{eq:xpbd-g} shows that this assumption is trivially
satisfied during the first iteration. To understand the justification for further iterations, it is helpful to take a look at the simplified
version of Equation \ref{eq:xpbd-lse} with both assumptions in place:

\begin{equation}\label{eq:xpbd-simplified-lse}
    \begin{pmatrix}
        \matm{M} & -\nabla\vecm{C}^T(\vecm{q}_i) \\
        \nabla \vecm{C}(\vecm{q}_i) & \tilde{\matm{\alpha}}
    \end{pmatrix}
    \begin{pmatrix}
        \Delta \vecm{p} \\
        \Delta \vecm{\lambda}
    \end{pmatrix}
    = -
    \begin{pmatrix}
    \vecm{0} \\
    \vecm{h}(\vecm{q}_i, \vecm{\lambda}_i)
    \end{pmatrix}.
\end{equation}

\noindent We refer to the system matrix as $\matm{H}_{\text{simp}}$. After the first iteration, the upper row of Equation \ref{eq:xpbd-simplified-lse} 
is satisfied. Thus, after the first iteration with $\vecm{q}_0 = \tilde{\vecm{q}}$ and $\vecm{\lambda}_0 = \vecm{0}$, it is

\begin{equation}
\begin{split}
    \vecm{0} = \matm{M}\Delta\vecm{q} - \nabla \vecm{C}(\vecm{q}_0)^T \Delta \vecm{\lambda} &= \matm{M}(\vecm{q}_1 - \vecm{q}_0) - \nabla \vecm{C}(\vecm{q}_0)^T 
    (\vecm{\lambda}_1 - \vecm{\lambda}_0) \\
    &= \matm{M}(\vecm{q}_1 - \tilde{\vecm{q}}) - \nabla \vecm{C}(\vecm{q}_0)^T \vecm{\lambda}_1. \label{eq:xpbd-assumption-2-detail}
\end{split}
\end{equation}

\noindent Using Equation \ref{eq:xpbd-assumption-2-detail}, $\vecm{g}(\vecm{q}_1, \vecm{\lambda}_1)$ can be rewritten as

\begin{equation}
\begin{split}
    &\vecm{g}(\vecm{q}_1, \vecm{\lambda}_1) = \vecm{g}(\vecm{q}_1, \vecm{\lambda}_1) - \vecm{0} \\
    &= \matm{M}(\vecm{q}_1 - \tilde{\vecm{q}}) - \nabla \vecm{C}(\vecm{q}_1)^T \vecm{\lambda}_1 - \vecm{0} \\
    &= \matm{M}(\vecm{q}_1 - \tilde{\vecm{q}}) - \nabla \vecm{C}(\vecm{q}_1)^T \vecm{\lambda}_1 
    - \matm{M}(\vecm{q}_1 - \tilde{\vecm{q}}) - \nabla \vecm{C}(\vecm{q}_0)^T \vecm{\lambda}_1 \\
    &= \nabla \vecm{C}(\vecm{q}_0)^T \vecm{\lambda}_1 - \nabla \vecm{C}(\vecm{q}_1)^T \vecm{\lambda}_1 \\
    &= (\nabla \vecm{C}(\vecm{q}_0)^T - \nabla \vecm{C}(\vecm{q}_1)^T) \vecm{\lambda}_1
\end{split}
\end{equation}

\noindent Note that if $\nabla \vecm{C}(\vecm{q}_0)^T = \nabla \vecm{C}(\vecm{q}_1)^T$, then 
$\vecm{g}(\vecm{q}_1, \vecm{\lambda}_1) = \vecm{0}$. Thus, Macklin et al.\ \cite{macklin2016} argue that 
$\vecm{g}(\vecm{q}_1, \vecm{\lambda}_1) \approx \vecm{0}$, as long as $\nabla \vecm{C}(\vecm{q})$ 
does not change too quickly.

Since the mass matrix $\matm{M}$ in the upper-left block of $\matm{H}_{\text{simp}}$ is invertible by design, it is possible
to take the Schur complement with respect to $\matm{M}$ to obtain a reduced system in terms of $\Delta \vecm{\lambda}$:

\begin{equation}\label{eq:xpbd-schur}
    (\nabla \vecm{C}(\vecm{q}_i) \matm{M}^{-1} \nabla \vecm{C}(\vecm{q}_i)^T + \tilde{\matm{\alpha}}) \Delta \vecm{\lambda} = -\vecm{C}(\vecm{q}_i) - 
    \tilde{\matm{\alpha}}\vecm{\lambda}_i
\end{equation}

\noindent The position update $\Delta \vecm{q}$ can be derived from $\Delta \vecm{\lambda}$ via the formula

\begin{equation}\label{eq:xpbd-position-update}
    \Delta \vecm{q} = \matm{W} \nabla \vecm{C}(\vecm{q}_i)^T \Delta \vecm{\lambda},
\end{equation}

\noindent where $\matm{W} = \matm{M}^{-1}$

Up until here, all constraints were handled together during each iteration. To make a connection to PBD and to return to the framework of a
nonlinear Gauss-Seidel solver Section \ref{ss:pbd-framework}, it is necessary to specify how to solve a single constraint. To that end we rewrite 
Equation \ref{eq:xpbd-schur} for a single constraint $C_j$ and get the update for its scalar Lagrange multiplier $\lambda_j$ by computing

\begin{equation}\label{eq:xpbd-lambda-j}
    \Delta \lambda_j = \frac{-C_j(\vecm{q}_i) - \tilde{\alpha}_j \lambda_{ji}}{\nabla C_j(\vecm{q}_i) \matm{W} \nabla C_j(\vecm{q}_i)^T + \tilde{\alpha}_j}.
\end{equation}

\noindent Here, $\lambda_{ji}$ is the value of the Lagrange multiplier of the $j$-th constraint after the $i$-th solver iteration. The position update for 
a single particle with index $l$ contributing to $C_j$ becomes

\begin{equation}\label{eq:xpbd-position-update-i}
    \Delta \vecm{q}_l = w_l \nabla_{\vecm{q}_l} C_j(\vecm{q}_i)^T \Delta \lambda_j.
\end{equation}

\noindent Note that $\Delta \lambda_j$ is scalar. Thus, the position update is a multiple of the mass-weighted gradient, just like in PBD 
(see Eq.\ \ref{eq:pbd-update-individual}).

In summary, we simply compute $\Delta \lambda_j$ via Equation \ref{eq:xpbd-lambda-j} and use it to 
update $\lambda_{j+1} = \lambda_j + \Delta \lambda$ and to determine $\Delta \vecm{q}$ via Equation \ref{eq:xpbd-position-update} while solving the $j$-th constraint. 
This leads to a natural extension of the PBD algorithm, where the general structure in Algorithm \ref{alg:pbd} is preserved. The only changes occur in the 
computation of the scaling factor for the 
mass-weighted constraint gradient in \textsc{projectConstraints} in line 5. The XPBD version of \textsc{projectConstraints} is given in 
Algorithm \ref{alg:xpbd-solver}. Note that Algorithm \ref{alg:xpbd-solver} is specified in terms of the projection points $\vecm{p}$ or $\vecm{p}_i$ instead of the 
positions $\vecm{q}$ or $\vecm{q}_i$ used in Equation \ref{eq:xpbd-position-update} and Equation \ref{eq:xpbd-lambda-j} to maintain notational consistency with the
PBD solver in Algorithm \ref{alg:pbd-solver}.

\begin{algorithm}
\caption{XPBD Constraint Solver}\label{alg:xpbd-solver}
\begin{algorithmic}[1]
\Procedure{projectConstraints}{$C_1, \ldots, C_r, \vecm{p}_1, \ldots, \vecm{p}_m$}
\State \textbf{for} all constraints $C_j$ \textbf{do} $\lambda_j = 0$
\For{all iterations $n_s$}
\ForNoDo{all constraints $C_j$ with cardinality $n_j$, particle indices $i_1, \ldots, i_{n_j}$,}
\StatexIndent[3] Lagrange multiplier $\lambda_j$ \algorithmicdo
\If{$C_j$ is an inequality constraint and $C_j(\vecm{p}) \geq 0$}
\State \textbf{continue} to next constraint
\EndIf
\State $\Delta \lambda_j = \frac{-C_j(\vecm{p}) - \tilde{\alpha}_j \lambda_{j}}{\nabla C_j(\vecm{p}) \matm{W} \nabla C_j(\vecm{p})^T + \tilde{\alpha}_j}$
\State $\lambda_{j} = \lambda_{j} + \Delta \lambda_j$
\For{all particles $i \in \{ i_1, \ldots, i_{n_j} \}$}
\State $\Delta \vecm{p}_i = \Delta \lambda_j w_i \nabla_{\vecm{p}_i} C_j(\vecm{p})$
\State $\vecm{p}_i = \vecm{p}_i + \Delta \vecm{p}_i$
\EndFor
\EndFor
\EndFor
\State \textbf{return with result } $\vecm{p}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Properties of XPBD}\label{ss:xpbd-properties}
XPBD is a natural extension of PBD that addresses some of PBD's shortcoming while maintaining the simplicity of the original algorithm. Due to
the similarity of both algorithms, PBD implementations can readily be extended to XPBD at the minor cost of storing an additional variable per 
constraint. In the following, the properties of XPBD are discussed.

\paragraph{Relation between XPBD and PBD.}
The derivation of the XPBD constraint projection builds on the concept of compliant constraints developed by Servin et al.\ 
\cite{servin2006}. As discussed in Section \ref{ss:compliant-constraints}, the compliant constraint formulation often allows handling hard constraints by
setting $\matm{\alpha} = \matm{0}$. Indeed, a closer look at the PBD update formula in Equation \ref{eq:pbd-update-individual} and the XPBD update 
formulas in Equation \ref{eq:xpbd-lambda-j}, Equation \ref{eq:xpbd-position-update-i} reveals that XPBD and 
PBD are equivalent if the compliance term $\alpha_j$ of constraint $C_j$ is zero. This matches with the observation that bodies 
simulated by PBD are infinitely stiff in the limit of infinite iterations (see Sec.\ \ref{ss:pbd-properties}). Note that this correspondence between XPBD 
and PBD gets lost if the stiffnesses are not moved out of the constraints and moved into the compliances. To see this, consider the energy 
potential $\psi(\vecm{q}) = \frac{1}{2} \alpha^{-1} C(\vecm{q})^2$. If we construct alternative constraints $C^\prime$ with $C^\prime(\vecm{q}) = 
\alpha^{-1/2}C(\vecm{q})$ we can alternatively express the energy potential $\psi$ as follows

\[
    \psi(\vecm{q}) = \frac{1}{2} C^{\prime}(\vecm{q})^2 = \frac{1}{2} \alpha^{\prime -1}C^{\prime}(\vecm{q})^2,
\]

\noindent with compliance $\alpha^\prime = 1$ independent of material stiffness. In this setting, modelling infinite stiffness by setting 
$\alpha^\prime = 0$ does not work.

If $\alpha_j \neq 0$, the compliance terms in Equation \ref{eq:xpbd-lambda-j} regularize the constraint in such a way that the constraint force is 
limited and corresponds to the constraint potential \cite{macklin2016}. This addresses the issue of coupling between iteration count and stiffness in 
the original PBD algorithm (see Sec.\ \ref{ss:pbd-properties}). Since the time step is later baked into $\tilde{\alpha}_j$, coupling between time step size 
and stiffness is also removed.

\paragraph{Generality.}
The XPBD derivation builds on the assumption that energy potentials $\psi$ fit into the compliant constraint framework (see Eq.\ \ref{eq:xpbd-potential-j}).
Thus, implementing an energy potential $\psi$ in XPBD requires constructing a constraint $C$ such that 
$\psi(\vecm{q}) = \frac{1}{2} \alpha^{-1} C(\vecm{q})^2$. Since $\alpha \geq 0$ and $C(\vecm{q})^2 \geq 0$ for all $\vecm{q}$ irrespective of $C$, this 
can only be achieved for non-negative energy potentials 
$\psi$. Thus, XPBD is not compatible with energy potentials that can take on negative values without further modifications. However, we can take 
advantage of the fact that adding a constant offset $c \in \mathbb{R}$ to $\psi$ does not affect the resulting forces $\vecm{f} = d\psi / d\vecm{q}$ 
to construct an equivalent energy potential $\psi^\prime$ if $\psi$ is bounded from below. Let $b \in \mathbb{R}$ be a lower bound of $\psi$. Then,
an equivalent non-negative energy potential $\psi^\prime$ can be constructed by setting

\begin{equation}\label{eq:xpbd-potential-non-negative}
    \psi^\prime(\vecm{q}) = \psi(\vecm{q}) + \vert b \vert.
\end{equation}

\noindent Note that this strategy does not work if $\psi$ does not have a lower bound. For example, the Neohookean energy density from 
Equation \ref{eq:neohookean-material-model} is unbounded from below due to the volume-preserving log terms. Consequently, it is imcompatible with the XPBD 
solver.

\paragraph{Simplifying Assumptions.}
As mentioned in Section \ref{ss:xpbd-constraint-projection}, assumption 1 (see Eq.\ \ref{eq:xpbd-assumption-1}) corresponds to dropping the geometric stiffness 
$\delta \nabla \vecm{C}(\vecm{q_i})^T \vecm{\lambda_i} / \delta \vecm{q}$. It is worth noting that with $\vecm{\lambda}_0 = \vecm{0}$, this assumption is 
trivially satisfied during the first iteration. According to Equation \ref{eq:lagrange-multiplier}, after a sufficient number of iterations it is $\vecm{\lambda}_i 
\approx \tilde{\matm{\alpha}} \vecm{C}(\vecm{q}_i)$, meaning that the entries of the geometric stiffness grow with increasing constraint stiffness and iteration
count. Thus, with stiffer constraints and larger iteration counts, assumption 1 becomes more aggressive. Tournier et al.\ \cite{tournier2015} state that
the iterative nature of PBD-style solvers ameliorates instabilities in the transverse direction of stiff constraints that is often observed as a result
of neglecting geometric stiffness.

Macklin et al.\ \cite{macklin2016} claim that replacing $\matm{H}$ with $\matm{H}_{\text{simp}}$ in assumption 1 can be interpreted as applying a quasi-Newton 
method -- also known as Broyden methods -- to the NLSE given by Equation \ref{eq:xpbd-g} and Equation \ref{eq:xpbd-h}, only affecting the convergence rate. While it is 
true that changing the Hessian 
matrix in Newton's method for unconstrained optimization to some positive definite approximation only changes the convergence rate under mild conditions
\cite{nocedal2006}, it is difficult to verify whether this also holds for the simplification from $\matm{H}$ to $\matm{H}_{\text{simp}}$ in the context of
solving NLSEs. There, it is often the case that quasi-Newton methods are not guaranteed to converge at all if aggressive approximations
of the system matrix are performed \cite{nocedal2006}. This is because there is no natural merit function available to help with the selection of 
step sizes along the suggested update directions. In their XPBD derivation, Macklin et al.\ \cite{macklin2016} do
point out that a line search strategy might be required to keep the fixed-point iteration based on Equation \ref{eq:xpbd-lse} robust, but it is also important
to mention that approximations of the system matrix without an appropriate line search procedure in place are potentially more aggressive.

Assumption 2 in the XPBD derivation is justified by the observation that Equation \ref{eq:xpbd-assumption-2-detail} and $\vecm{g}(\vecm{q}_1, 
\vecm{\lambda}_1)$ are the same, except that $\nabla \vecm{C}(\vecm{q}_0)^T$ is replaced by $\nabla \vecm{C}(\vecm{q}_1)^T$. Thus, Macklin et al.\ 
\cite{macklin2016} claim that Equation \ref{eq:xpbd-assumption-2-detail} is close to zero as well if $\vecm{g}(\vecm{q}_0, \vecm{\lambda}_0) = \vecm{0}$, 
which is true by definition of $\vecm{q}_0$ and $\vecm{\lambda}_0$. However, this neglects the fact that $\nabla \vecm{C}(\vecm{q}_i)$ occurs in 
a product with $\vecm{\lambda}_i$ in $\vecm{g}(\vecm{q}_i, \vecm{\lambda}_i)$. As mentioned in the discussion of assumption 1, 
$\vecm{\lambda}_i$ gets very large for stiff constraints after a 
sufficient number of iterations. Thus, even small changes to $\nabla \vecm{C}(\vecm{q}_i)$ eventually drive the value of $\vecm{g}$ away from zero
significantly. As a result, assumption 2 becomes more aggressive with stiffer constraints and larger iteration counts, just like observed
for assumption 1. Additionally, assuming that $\vecm{g}(\vecm{q}_i, \vecm{\lambda}_i) = \vecm{0}$ leads to a change of the right side between 
the LSEs in Equation \ref{eq:xpbd-lse} and Equation \ref{eq:xpbd-simplified-lse}. In contrast to the changes to the system matrix during assumption 1, 
this does affect the solution the solver converges to. Thus, due to assumption 2, the XPBD solver cannot be said to solve the original 
implicit equations of motion \cite{macklin2016}.

\paragraph{Preservation of Individual Momenta.}
When investigating the properties of PBD (see Sec.\ \ref{ss:pbd-properties}), we mentioned that multiplying all particle masses $m_i$ with a constant
positive factor $a \in \mathbb{R}^+$ does not impact the PBD update, highlighting that there is no punishment for moving individual
particles from their inertial positions in PBD. The fact that both positions and Lagrange multipliers are updated during each
iteration of the XPBD solver makes an analysis similar to Equation \ref{eq:pbd-masses} for XPBD challenging for arbitrary iterations $i$. However, it 
is simple to look at the effect of scaling all particle masses by $a$ on the position update during the first iteration, assuming that 
$\vecm{\lambda} = \vecm{0}$. The resulting update of particle $i$ is given by

\begin{equation}\label{eq:xpbd-masses}
    \Delta \vecm{q}_i 
    = -\frac{C(\vecm{q})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} \frac{w_j}{w_i} \vert \nabla_{\vecm{q}_j}C(\vecm{q}) \vert^2 + \tilde{\alpha}a m_i} 
    \nabla_{\vecm{q}_i} C(\vecm{q}).
\end{equation}

\noindent Note how the factor $a$ does occur in the second summand in the denominator in a way that decreases the size of the position update
if $a$ is increased. However, it appears in a product with the small $\tilde{\alpha}$. Thus, the effect of increasing all particle masses on
the position update is still rather small. It is worth pointing out that the inclusion of $a$ in the position update of the first iteration
penalizes moving particles with large masses in all directions. Ideally, moving particles towards the inertial positions $\tilde{\vecm{q}}$
should be encouraged whereas as moving particles away from $\tilde{\vecm{q}}$ should be discouraged. This directionality is only possible if
$\tilde{\vecm{q}}$ is not simply used as an initial guess for the XPBD solver, but also used explicitly in the update equations. However, setting
$\vecm{g}(\vecm{q}_i, \vecm{\lambda}_i) = \vecm{0}$ in assumption 2 removes all occurrences of the inertial positions from Equation \ref{eq:xpbd-simplified-lse}.

\paragraph{Initial Guess For $\vecm{\lambda}_0$.}
Both assumptions 1 and 2 exploit the choice $\vecm{\lambda}_0 = \vecm{0}$. It is worth mentioning that this precludes the use of the more natural
initial guess given by $\vecm{\lambda}_0 = -\tilde{\matm{\alpha}} \vecm{C}(\tilde{\vecm{q}})$. This candidate results from plugging the 
inertial positions into the
definition of the Lagrange multipliers in Equation \ref{eq:lagrange-multiplier}. Picking an initial guess that is as close as possible to the true
solution is important for keeping the linearization error during the fixed-point iteration based on Newton's method in the XPBD derivation 
small. 

\paragraph{Numerical Damping.}
While motion due to external forces is handled by the symplectic Euler integration in lines 3-4 of Algorithm \ref{alg:pbd}, the way 
elasticity is handled is derived from the implicit equations of motions (see Eq.\ \ref{eq:implicit-positional-detailed-2}). As a result 
elastic forces are subjected to numerical damping that gets more severe with growing time step sizes in XPBD (see Sec.\ \ref{ss:numerical-integration}). 
For this reason, even though baking the time step into $\tilde{\matm{\alpha}}$ in the compliant constraint formulation reduces coupling 
between time step and stiffness, the perceived stiffness of simulated materials is still time step dependent to some extent.

\paragraph{Gauss-Seidel Solver.}
Finally, it is worth pointing out that the implications of using a Gauss-Seidel-type solver discussed in the context of PBD 
(see Sec.\ \ref{ss:pbd-properties}) apply to XPBD as well.

\subsection{Simulating Deformable Bodies using XPBD}\label{ss:xpbd-deformable-bodies}
To simulate deformable bodies using the material models presented in Section \ref{ss:material-models}, we introduce constraints $C_j$ with 
compliance $\alpha_j$ for each tetrahedral element such that the corresponding constraint energy 
potential $\psi_j$ satisfies

\begin{equation}\label{eq:xpbd-deformation-goal}
    \psi_j(\vecm{q}) = \frac{1}{2}\alpha^{-1}_jC_j(\vecm{q})^2 = V_j\Psi_{\text{mat}}(\matm{F}_j).
\end{equation}

\noindent Here, $V_j$ is the volume of the undeformed tetrahedron, $\Psi_{\text{mat}}$ is the energy density of the material 
model and $\matm{F}_j$ is the deformation gradient of the deformed tetrahedron. As discussed in Section \ref{ss:xpbd-properties}, this 
cannot be achieved for the classical Neohookean material model in Equation \ref{eq:neohookean-material-model}. In the following, we show 
how to implement the strain material model (see Eq.\ \ref{eq:strain-material-model}) and the simplified Neohookean material model 
(see Eq.\ \ref{eq:smith-neohookean-material-model}) in XPBD.

\paragraph{Strain Material Model.}
For the strain material model $\Psi_{\text{strain}}$ in Equation \ref{eq:strain-material-model}, Equation \ref{eq:xpbd-deformation-goal} is 
satisfied by setting 

\[
    \alpha_j = \frac{1}{k V_j} \, \, \, \text{and} \, \, \, C_j(\vecm{q}) = \norm{\matm{I} - \matm{\Sigma}_j}_F,
\]

\noindent where $k$ is the stiffness of the strain material model and $\matm{\Sigma}_j$ is the diagonal matrix whose entries 
are the singular values of $\matm{F}_j$. Note that $k$ only appears in the compliance $\alpha_j$, but not in of the constraint 
$C_j$. Thus, the behavior of PBD can be recovered by setting $\alpha_j = 0$.

\paragraph{Simplified Neohookean Material Model.}
For the simplified Neohookean material model in Equation \ref{eq:smith-neohookean-material-model}, constructing suitable constraints 
$C_j$ and compliances $\alpha_j$ is more complicated. This is due to the fact that $\Psi_{\text{Smith}}$ can take on 
negative values. First, we observe that $\Psi_{\text{Smith}}$ is bounded from below by rearranging terms as follows

\begin{align*}
    \Psi_{\text{Smith}}(\matm{F}) &= \frac{\mu}{2}(\text{tr}(\matm{F}^T\matm{F}) - 3) + \frac{\lambda}{2}\left(\text{det}(\matm{F}) - 
    \left(1 + \frac{\mu}{\lambda}\right)\right)^2\\
                                  &= \frac{\mu}{2}\text{tr}(\matm{F}^T\matm{F}) + \frac{\lambda}{2}\left(\text{det}(\matm{F}) - 
                                  \left(1 + \frac{\mu}{\lambda}\right)\right)^2 - \frac{3\mu}{2}.
\end{align*}

\noindent Note that the first two terms are non-negative, while the last term is negative and independent of 
$\vecm{q}$. Consequently, $-\frac{3\mu}{2}$ is a lower bound of $\Psi_{\text{Smith}}$ and the equivalent 
non-negative energy density $\Psi^\prime_{\text{Smith}}$ given by

\[
    \Psi^\prime_{\text{Smith}}(\mat{F}) = \frac{\mu}{2}\text{tr}(\matm{F}^T\matm{F})     
    + \frac{\lambda}{2}\left(\text{det}(\matm{F}) - \left(1 + \frac{\mu}{\lambda}\right)\right)^2
\]

\noindent can be constructed (see Sec.\ \ref{ss:xpbd-properties}). We refer to the first and second term of 
$\Psi^\prime_{\text{Smith}}$ as the deviatoric and hydrostatic term, respectively.

To prepare pulling out the large Lamé coefficients $\mu$ and $\lambda$ that 
control the stiffness and incompressibility of the simulated material, we factor out the larger coefficient 
$x \coloneqq \text{max}(\mu, \lambda)$ as follows

\[
    \Psi^\prime_{\text{Smith}}(\mat{F}) = \frac{x}{2} \left(\frac{\mu}{x}\text{tr}(\matm{F}^T\matm{F})     
    + \frac{\lambda}{x}\left(\text{det}(\matm{F}) - \left(1 + \frac{\mu}{\lambda}\right)\right)^2\right).
\]

\noindent Now, Equation \ref{eq:xpbd-deformation-goal} is satisfied for $\Psi_{\text{mat}} = \Psi^\prime_{\text{Smith}}$ if 
we set

\[
    \alpha_j = \frac{1}{x V_j} \, \, \, \text{and} \, \, \, C_j(\vecm{q}) = \sqrt{\frac{\mu}{x}\text{tr}(\matm{F}_j^T\matm{F}_j)     
    + \frac{\lambda}{x}\left(\text{det}(\matm{F}_j) - \left(1 + \frac{\mu}{\lambda}\right)\right)^2}.
\]

\noindent We refer to this type of constraint as the combined Neohookean constraint. Note that $x$ does not only appear in the 
compliance $\alpha_j$, but in the constraint $C_j$ as well. Thus, this formulation can only be applied directly if $\alpha_j \neq 0$. 
Otherwise, we need to adjust $C_j$ in order to maintain consistency by either computing $C^\mu_j \coloneqq \lim_{\mu\to\infty}C_j$ 
or $C^\lambda_j \coloneqq \lim_{\lambda\to\infty}C_j$. If $x = \mu$, then $C^\mu_j$ is undefined since $\lim_{\mu\to\infty}$ diverges. 
However, if $x = \lambda$, it is easy to see that $C^\lambda_j$ must be

\begin{equation}\label{eq:combined-neohookean-0-compliance}
    C^\lambda_j(\vecm{q}) = \lim_{\lambda\to\infty}  C_j(\vecm{q}) = \sqrt{(\text{det}(\matm{F}_j) - 1)^2} = \text{det}(\matm{F}_j) - 1.
\end{equation}
    

\noindent Note that $C^\lambda_j$ only enforces that the volume of its tetrahedron is preserved. Still, it does not prevent stretching the 
tetrahdron in one direction if compressing it in another direction balances out the change in volume. 

Macklin et al.\ \cite{macklin2021} suggest a different way of implementing the simplified Neohookean material model with XPBD. The trick is 
to introduce not one, but two constraints for each tetrahedral element. The authors construct separate constraints $C^D_j$ with compliance 
$\alpha^D_j$ and $C^H_j$ with compliance $\alpha^H_j$ for the deviatoric and hydrostatic terms of $\Psi^\prime_{\text{Smith}}$, respectively, 
given by 

\begin{equation}\label{eq:deviatoric-constraint}
    C^D_j(\vecm{q}) = \sqrt{\text{tr}(\matm{F}_j^T\matm{F}_j)}, \, \, \, \, \, \, \alpha^D_j = \frac{1}{\mu V_j}
\end{equation}

\noindent and 

\begin{equation}\label{eq:hydrostatic-constraint}
    C^H_j(\vecm{q}) = \text{det}(\matm{F}_j) - \left(1 + \frac{\mu}{\lambda}\right), \, \, \, \, \, \, \alpha^H_j = \frac{1}{\lambda V_j}.
\end{equation}

\noindent It is easily verified that

\[
    \psi_j(\vecm{q}) = \frac{1}{2}(\alpha^{D}_j)^{-1} C^D_j(\vecm{q})^2 + \frac{1}{2}(\alpha^{H}_j)^{-1} C^H_j(\vecm{q})^2 
    = V_j\Psi^\prime_{\text{Smith}}(\matm{F}_j).
\]

The advantage of splitting constraints becomes apparent when modelling hard incompressibility by setting $\alpha^H_j = 0$. Since $\lambda$ 
appears in both $\alpha^H_j = 0$ and $C^H_j$, it is necessary to adjust $C^H_j$ by computing $\lim_{\lambda\to\infty}C^H_j$ again. It is 

\[
    \lim_{\lambda\to\infty}C^H_j(\vecm{q}) = \text{det}(\matm{F}_j) - 1,
\]

\noindent which is the same as what was observed for combined Neohookean constraints in Equation \ref{eq:combined-neohookean-0-compliance}.
However, this time, there is an independent deviatoric constraint $C^D_j$ that additionally drives the tetrahedron towards configurations 
where the principal stretches of the deformation gradient $\matm{F}_j$ are not unevenly distributed. Note that setting $\alpha^D_j = 0$ is 
impossible again, since $\lim_{\mu\to\infty}C^H_j$ diverges.

On the other hand, constructing separate constraints for the deviatoric and hydrostatic terms also introduces problems. In 
Section \ref{ss:simplified-neohookean-material}, we discussed that the hydrostatic term needs to be corrected to ensure the rest stability of the simplified 
Neohookean material model. The 
correction is chosen such that tetrahedral elements are artificially inflated by exactly the right amount to make up for the deflation caused 
by the deviatoric term. The derivation of the correction term relies on the assumption that both the deviatoric and the hydrostatic term act 
on the same positions simultaneously \cite{smith2018}. However, due to the nature of the Gauss-Seidel-type solver used in XPBD, the constraints 
$C^D_j$ and $C^H_j$ change the tetrahedral positions after each other. Thus, elements are inflated and deflated sequentially during each solver 
iteration. This way, rest stability cannot be ensured. The issue is particularly severe for simulations with large Lamé coefficient $\mu$, 
since this increases the degree to which both $C^D_j$ and $C^H_j$ deflate and inflate the elements, respectively. Similarly, we expect 
larger time steps to make matters worse.

\section{Projective Dynamics}\label{s:pd}

In the approaches to physical simulations via implicit time integration that we have encountered so far, a new linear system needs to be solved
at every time step. If the linear system is solved directly, this can quickly become prohibitively expensive for large simulations since 
a new matrix factorization needs to be computed every time a new sytem needs to be solved. In XPBD, this issue is dealt with by using an iterative 
solver. In Projective Dynamics (PD\index{PD}), Bouaziz et al.\ \cite{bouaziz2014} instead restrict energy potentials to a specific structure 
which allows for efficient implicit time integration via alternating steps of local and global optimization \cite{bouaziz2014}. The local 
optimization steps are comprised of per-constraint projections of particle positions onto constraint manifolds. The global optimization 
step combines the results from the individual 
local projection steps while taking into consideration global effects including inertia and external forces. This is achieved by solving a 
linear system of equations whose system matrix is constant across time steps. Since the local steps can be carried out in parallel and the 
factorization for the system matrix of the global step can be precomputed and reused, physical simulations that are restricted to energy 
potentials from the PD framework can be solved efficiently. In Section \ref{ss:pd-overview}, an overview over the PD solver is provided. There, 
we focus on introducing the broad structure of PD energy potentials and the way it benefits the convergence properties of the solver. In 
Section \ref{ss:pd-potentials}, an exact formulation of PD energy potentials is provided. This formulation is used in Section \ref{ss:pd-solver} 
to fill in the gaps in the overview given in Section \ref{ss:pd-overview} and to give a complete description of the PD solver. The 
properties of the PD solver are discussed in Section \ref{ss:pd-properties}. We show how to simulate deformable bodies using the strain 
material model (see Eq.\ \ref{eq:strain-material-model}) in Section \ref{ss:pd-deformable-bodies}. Lastly, we make a connection between the PD 
solver and Quasi-Newton methods for unconstrained optimization in Section \ref{ss:pd-quasi-newton}.

\subsection{Overview Over Projective Dynamics}\label{ss:pd-overview}
Projective Dynamics starts from the variational form of implicit Euler integration of the equations of motion (see Eq.\ \ref{eq:variational-implicit}),
which is restated here again for the sake of convenience

\begin{equation}\label{eq:pd-variational-implicit}
    \min_{\matm{q}_{n+1}} \frac{1}{2h^2} \norm{\matm{M}^{\frac{1}{2}}(\matm{q}_{n+1} - \tilde{\matm{q}})}^2_F + \sum_j \psi_j(\matm{q}_{n+1}).
\end{equation}

\noindent Recall that in the context of PD, the particle positions are stored in matrices, i.e.\ $\matm{q}_{n+1}, \tilde{\matm{q}} \in 
\mathbb{R}^{m \times 3}$ and $\matm{M} \in \mathbb{R}^{m \times m}$, where $m \in \mathbb{N}$ is the number of particles in the simulated
body. In this section, we simply write $\matm{q}$ instead of $\matm{q}_{n+1}$ to improve legibility. The solution of this unconstrained 
optimization problem corresponds to the particle positions of the simulated body at the next time
step (see Sec.\ \ref{ss:numerical-integration}) and can be determined using general purpose algorithms for unconstrained optimization 
such as Newton's method. Naive application of line search methods can often lead to unfeasibly high runtimes for real-time applications. 
The core idea of PD
is to speed up the optimization by restricting the energy potentials $\psi_j$ to a structure that allows for efficient minimization.
This allows substituting the line search methods -- which are designed for the minimization of general nonlinear objective functions 
-- with a specialized solver that exploits the structure of PD energy potentials. 

Consider the restriction of energy potentials $\psi_j$ to quadratic functions of $\matm{q}$. Then, as the sum of the inertial term 
(always quadratic) and the constraint energy (quadratic by assumption) the entire objective function of Equation \ref{eq:pd-variational-implicit} 
is quadratic in $\matm{q}$. Thus, the solution to the minimization problem can be found in a single linear solve \cite{nocedal2006}. 
While this choice
of energy potentials does enable efficient implicit Euler integration of the equations of motion, it comes at the sacrifice of generality.
In particular, quadratic energy potentials always yield linear forces. Linear forces generally do not suffice to model realistic
elastic behavior \cite{wang2011}. Now, the challenge lies in enhancing quadratic energy potentials to allow expressing some degree
of nonlinearity while still keeping the minimization efficient. 

In PD, Bouaziz et al.\ \cite{bouaziz2014} achieve this by introducing energy potentials that roughly measure the square of the
distance of the current particle positions to their projections onto some -- potentially nonlinear -- constraint manifold $\cman{C}_j$. 
In this setting, the energy potential $\psi_j$ is defined entirely by the squared distance function $d_j$ and the corresponding constraint 
manifold $\cman{C}_j$. By picking an appropriate distance measure, the squared distance $d_j$ can be made quadratic in $\matm{q}$ 
(see Sec.\ \ref{ss:pd-potentials}). Since the constraint manifold $\cman{C}_j$ is potentially nonlinear, the energy potential 
$\psi_j$ can produce nonlinear forces as well. 

Assume that the constraint has cardinality 
$n_j \in \mathbb{N}$ and acts on the particles with indices $i_1, \ldots, i_{n_j}$ and let $\matm{q}_j \in \mathbb{R}^{n_j \times 3}$ be

\[
    \matm{q}_j = \begin{pmatrix}
        \matm{q}_{i_1}^T \\
        \ldots \\
        \matm{q}_{i_{n_j}}^T
    \end{pmatrix}.
\]

\noindent Then, Bouaziz et al.\ \cite{bouaziz2014} introduce auxiliary variables $\matm{p}_j \in \mathbb{R}^{n_j \times 3}$ per constraint 
and define the energy potential in terms of the function $W_j$ given by 

\begin{equation}\label{eq:pd-Wj}
    W_j(\matm{q}_j, \matm{p}_j) = d_j(\matm{q}_j, \matm{p}_j) + \delta_{\cman{C}_j}(\matm{p}_j).
\end{equation}

\noindent Here, $\delta_{\cman{C}_j}$ is an indicator function with 

\[
\delta_{\cman{C}_j}(\matm{p}_j)= 
\begin{cases}
0,& \text{if } \matm{p}_j \text{ lies on the constraint manifold } \cman{C}_j \\
\infty,& \text{otherwise.}
\end{cases}
\]

\noindent Consider $\matm{p}_{\matm{q}_j} \coloneqq \argmin{\matm{p}_j} W(\matm{q}_j, \matm{p}_j)$ while keeping $\matm{q}_j$ 
fixed. Then obviously 
$\delta_{\cman{C}_j}(\matm{p_{\matm{q}_j}}) = 0$, meaning that $\matm{p_{\matm{q}_j}}$ lies on $\cman{C}_j$. Additionally, 
for all other
$\matm{p}^* \in \mathbb{R}^{n_j \times 3}$ with $\delta_{\cman{C}_j}(\matm{p}^*) = 0$ it is $d_j(\matm{q}_j, \matm{p}_{\matm{q}_j}) 
\leq
d_j(\matm{q}_j, \matm{p}^*)$. Together, $\matm{p}_{\matm{q}_j}$ is the configuration on the constraint manifold that is the closest to 
the configuration specified by positions $\matm{q}_j$ in terms of $d_j$. Thus, $\matm{p}_{\matm{q}_j}$ can be 
interpreted as the projection of $\matm{q}_j$ onto the constraint manifold $\cman{C}_j$. Note that $d_j$ itself is not a distance 
function, but $\sqrt{d_j}$ is (see Sec.\ \ref{ss:pd-potentials}). Still, we follow the example of Bouaziz et al.\ \cite{bouaziz2014} 
and define closeness between pairs of configurations in terms of $d_j$ instead of $\sqrt{d_j}$. This is justified since for two pairs
of configurations $\matm{q}, \matm{p}$ and $\matm{q}^\prime, \matm{p}^\prime$ it is 

\[
    d_j(\matm{q}, \matm{p}) < d_j(\matm{q}^\prime, \matm{p}^\prime) \iff \sqrt{d_j}(\matm{q}, \matm{p}) < \sqrt{d_j}(\matm{q}^\prime, 
    \matm{p}^\prime).
\]

Bouaziz et al.\ \cite{bouaziz2014} define the energy potential $\psi_j$ as 

\begin{equation}\label{eq:pd-min-W}
    \psi_j(\matm{q}) = \min_{\matm{p}_j} W(\matm{S}_j\matm{q}, \matm{p}_j) 
    = \min_{\matm{p}_j} d_j(\matm{q}_j, \matm{p}_j) + \delta_{\cman{C}_j}(\matm{p}_j)
    = d_j(\matm{q}_j, \matm{p}_{\matm{q}_j}),
\end{equation}

\noindent where $\matm{S}_j$ is the matrix that maps $\matm{q}$ to $\matm{q}_j$. This is exactly the squared distance as measured by 
$d_j$ between configuration $\matm{q}_j$ and its projection $\matm{p}_{\matm{q}_j}$ onto the constraint manifold $\cman{C}_j$. 
Plugging the energy potentials into the variational form of implicit Euler integration (see Eq.\ \ref{eq:pd-variational-implicit}) yields

\begin{equation}\label{eq:pd-variational-overview}
    \min_{\matm{q}, \matm{p}_j} \frac{1}{2h^2} \norm{\matm{M}^{\frac{1}{2}}(\matm{q} - \tilde{\matm{q}})}^2_F + 
    \sum_j d_j(\matm{S}_j \matm{q}, \matm{p}_j) + \delta_{\cman{C}_j}(\matm{p}_j).
\end{equation}

\noindent Here, with abuse of notation, $\vecm{p}_j$ denotes either the auxiliary variable of the $j$-th constraint or 
the family of auxiliary variables $(\vecm{p}_j)_{j \in \mathcal{J}}$, where $\mathcal{J}$ is the index set of the 
constraints. Note that if the projections $\matm{p}_{\matm{q}_j}$ are known in advance and kept fixed for all constraint 
manifolds $C_j$, then the minimization problem becomes

\begin{equation}\label{eq:pd-global-d}
    \min_\matm{q} \frac{1}{2h^2} \norm{\matm{M}^{\frac{1}{2}}(\matm{q} - \tilde{\matm{q}})}^2_F + \sum_j d_j(\matm{S}_j
    \matm{q}, \matm{p}_{\matm{q}_j}).
\end{equation}

\noindent In this case, the objective function is a quadratic function of $\matm{q}$ again. As a result, it can be optimized in a single 
linear step. 

These insights suggest a local/global structure for the PD solver. In the local step, the projection points $\matm{p}_{\matm{q}_j}$
are computed for each constraint. Finding the projection points $\matm{p}_{\matm{q}_j}$ corresponds to minimizing 
Equation \ref{eq:pd-variational-overview} over the projection variables $\matm{p}_j$ while keeping the positions $\matm{q}$ fixed, yielding
the following optimization problem

\begin{equation}\label{eq:pd-local-d}
    \min_{\matm{p}_j} \sum_j d_j(\matm{S}_j \matm{q}, \matm{p}_j) + \delta_{\cman{C}_j}(\matm{p}_j).
\end{equation}

\noindent Since each constraint has its own auxiliary projection variables, this minimization can be carried out independently 
for each constraint. In the global step, Equation \ref{eq:pd-global-d} is minimized, which is equivalent to minimizing 
Equation \ref{eq:pd-variational-overview} over the positions $\matm{q}$ while keeping the projection variables $\matm{p}_j$ 
fixed. Local and global steps are repeated for a fixed number of iterations during each time step. Finally, the 
resulting positions are used as the positions of the next time step.

\subsection{PD Energy Potentials}\label{ss:pd-potentials}
To arrive at a working implementation of the PD solver outlined in Section \ref{ss:pd-overview}, a squared distance function 
$d_j$ and a projection operator onto some constraint manifold $\cman{C}_j$ need to be provided for each energy potential $\psi_j$. 
While the projection operators vary significantly between different types of constraints, Bouaziz et al.\ \cite{bouaziz2014} 
always use squared distance functions $d_j$ of the form

\begin{equation}\label{eq:pd-distance}
    d_j(\matm{q}_j, \matm{p}_j) = \frac{w_j}{2} \norm{\matm{A}_j\matm{q}_j - \matm{B}_j\matm{p}_j}^2_F,
\end{equation}

\noindent where $\matm{A}_j, \matm{B}_j$ are matrices of appropriate dimensions and $w_j \in \mathbb{R}$ is the weight assigned to the
$j$-th constraint. Plugging the definition of $d_j$ in Equation \ref{eq:pd-distance} into the PD energy potentials in Equation \ref{eq:pd-min-W} 
yields

\begin{equation}\label{eq:pd-potentials}
    \psi_j(\matm{q}) = \min_{\matm{p}_j} \frac{w_j}{2} \norm{\matm{A}_j\matm{q}_j - \matm{B}_j\matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j).
\end{equation}

Note that $\sqrt{d_j}$ is the distance function that is induced by a Frobenius norm with weights $\matm{A}_j, 
\matm{B}_j$ in the standard manner. Formally, $d_j$ itself cannot be considered a distance function since it violates the absolute
homogeneity property, i.e. 

\[
    d_j(a\matm{q}_j, a\matm{p}_j) = a^2d_j(\matm{q}_j, \matm{p}_j) \neq \vert a \vert d_j(\matm{q}_j, \matm{p}_j) \text{ for } 
    a \in \mathbb{R}. 
\]


\subsection{Projective Implicit Euler Solver}\label{ss:pd-solver}
The PD solver can be derived by plugging the squared distance functions from Equation \ref{eq:pd-distance} into the variational 
form of implicit
Euler integration for PD energy potentials (see Eq.\ \ref{eq:pd-variational-overview}). This yields the optimization problem given by 

\begin{equation}\label{eq:pd-variational}
    \min_{\matm{q}, \matm{p}_j} \frac{1}{2h^2} \norm{\matm{M}^{\frac{1}{2}}(\matm{q} - \tilde{\matm{q}})}^2_F + 
    \sum_j \frac{w_j}{2} \norm{\matm{A}_j\matm{S}_j\matm{q} - \matm{B}_j\matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j)
\end{equation}

\noindent To make the relation between the projection variables $\matm{p}_j$ and the relevant particle positions 
$\matm{q}_j$ more apparent, we required $\text{dim}(\matm{S}_j\matm{q}) = \text{dim}(\matm{p}_j)$ so far. However, the 
notation can be simplified by introducing the alternative constraint manifold $\cman{C}^\prime_j = \{ \matm{B}_j\matm{p} 
\mid \matm{p} \in \cman{C}_j \}$. Of course, this requires changing the shape of the projection variables. If 
$\matm{B}_j \in \mathbb{R}^{r \times n_j}$, then $\matm{p}_j \in \mathbb{R}^{r \times 3}$. If further $\matm{A}_j\matm{S}_j$ 
are combined into a single matrix $\matm{G}_j$, an equivalent optimization problem given by 

\begin{equation}\label{eq:pd-minimization}
    \min_{\matm{q}, \matm{p}_j} \tilde{g}(\matm{q}, \matm{p}_j) = 
    \min_{\matm{q}, \matm{p}_j} \frac{1}{2h^2} \norm{\matm{M}^{1/2}(\matm{q} - \tilde{\matm{q}})}^2_F + \sum_j \frac{w_j}{2} \norm{\matm{G}_j\matm{q}
    - \matm{p}_j}^2_F + \delta_{\cman{C}^\prime_j}(\matm{p}_j)
\end{equation}

\noindent can be derived. From now on, we simply write $\cman{C}_j$ instead of $\cman{C}^\prime_j$.

As discussed in Section \ref{ss:pd-overview}, the local step consists of minimizing the objective function 
Equation \ref{eq:pd-minimization} over the auxiliary variables $\matm{p}_j$ while keeping the positions $\matm{q}$ fixed. For each 
energy potential, we solve the following minimization problem

\begin{equation}\label{eq:pd-local-minimization}
    \min_{\matm{p}_j} \tilde{g}(\matm{q}, \matm{p}_j) =
    \min_{\matm{p}_j} \frac{w_j}{2}\norm{\matm{G}_j\matm{q} - \matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j).
\end{equation}

\noindent In the global step, the minimization problem Equation \ref{eq:pd-minimization} is optimized over the positions $\matm{q}$ 
while keeping the auxiliary variables $\matm{p}_j$ fixed. The optimization problem for the global solve is 
given by

\begin{equation}\label{eq:pd-global-minimization}
    \min_{\matm{q}} \tilde{g}(\matm{q}, \matm{p}_j) =
    \min_{\matm{q}} \frac{1}{2h^2} \norm{\matm{M}^{1/2}(\matm{q} - \tilde{\matm{q}})}^2_F + \sum_j \frac{w_j}{2} \norm{\matm{G}_j\matm{q} - \matm{p_j}}^2_F.
\end{equation}

\noindent The gradient of the objective function with respect to the positions $\nabla_{\matm{q}} 
\tilde{g}(\matm{q}, \matm{p}_j)$ is given by 

\begin{equation}\label{eq:pd-gradient-q}
    \nabla_{\matm{q}}\tilde{g}(\matm{q}, \matm{p}_j) = \frac{1}{h^2}\matm{M}(\matm{q} - \tilde{\matm{q}}) + \sum_j w_j \matm{G}^T_j \matm{G}_j \matm{q}
    - \sum_j w_j \matm{G}^T_j \matm{p}_j.
\end{equation}

\noindent By design of the PD energy potentials, the objective function of the global optimization problem is quadratic in the positions 
$\matm{q}$. Consequently, the minimization can be carried out in a single step by picking $\matm{q}$ such that the first-order optimality 
conditions are satisfied \cite{nocedal2006}. This leads to the following system of equations

\begin{equation}\label{eq:pd-global-system}
    (\frac{1}{h^2}\matm{M} + \sum_j w_j \matm{G}_j^T \matm{G}_j)\matm{q} = \frac{1}{h^2}\matm{M}\tilde{\vecm{q}} + \sum_j w_j \matm{G}_j^T \matm{p}_j.
\end{equation}

\noindent In the rest of Section \ref{s:pd} we refer to the system matrix of the global system by 
$\matm{S} \coloneqq \frac{1}{h^2}\matm{M} + \sum_j w_j \matm{G}_j^T \matm{G}_j$.

Note that $\matm{S}$ is constant as long as the constraint set remains unchanged. The right side needs to be recomputed in every 
iteration as the projections $\matm{p}_j$ change during the local optimization steps.  An overview over the algorithm is given in 
Algorithm \ref{alg:pd}.

\begin{algorithm}
\caption{Projective Implicit Euler Solver}\label{alg:pd}
\begin{algorithmic}
\Procedure{solvePD}{$\matm{q}_n$, $\matm{v}_n$, $\matm{f}_{\text{ext}}$, $h$}
\State $\tilde{\matm{q}} = \matm{q}_n + h\matm{v}_n + h^2\matm{M}^{-1}\matm{f}_{\text{ext}}$
\State $\matm{q}_k = \tilde{\matm{q}}$
\For{all iterations}
\For{constraints $j$}
\State $\matm{p}_j = \min_{\matm{p}_j} \frac{w_j}{2}\norm{\matm{G}_j\matm{q}_k - \matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j)$
\EndFor
\State $\matm{q}_{k} \gets$ solution of $\matm{S}\matm{q} = \frac{1}{h^2}\matm{M}\tilde{\matm{q}} + \sum_j w_j \matm{G}_j^T \matm{p}_j$.
\EndFor
\State \textbf{return with } $\matm{q}_{n+1} = \matm{q}_k, \matm{v}_{n+1} = (\matm{q}_{n+1} - \matm{q}_n) / h$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Properties of Projective Dynamics}\label{ss:pd-properties}
Projective dynamics is an efficient algorithm for implicit euler integration of the equations of motion with energy potentials of the form 
presented in Equation \ref{eq:pd-potentials}. Its properties are discussed in detail in this section.

\paragraph{Efficient Implementation.}
The structure of the PD energy potentials allows for Algorithm \ref{alg:pd} to be implemented efficiently. Since the constraint projections
in Equation \ref{eq:pd-local-minimization} can be carried out independently, the local optimization step lends itself to massive parallelization. 
Further, because the system matrix $\matm{S}$ is constant, its prefactorization can be computed at initialization, enabling
efficient solves of the linear system in the global optimization step. Note that since $\matm{q} \in \mathbb{R}^{m \times 3}$ in Equation \ref{eq:pd-global-system}, 
the global system can be solved independently and in parallel for each coordinate.

\paragraph{Generality.}
The last property follows from the fact that the squared distance functions $d_j$ in Equation \ref{eq:pd-distance} have no dependencies between 
$x$-, $y$- and $z$-coordinates. This detail demonstrates that restricting to PD energy potentials comes at the cost of generality: 
Many arbitrary nonlinear elastic potentials, particulary those that have dependencies between $x$-, $y$- and $z$-coordinates, cannot be expressed 
in terms of PD elastic potentials. Further, since PD energy potentials $\psi_j$ are defined in terms of a squared distance function $\d_j$, the 
resulting forces are always proportional to the distance from the constraint manifold $\cman{C}_j$ \cite{overby2017}. Many classical energies 
like the Neohookean and St.\ Venant-Kirchhoff energies do not fit into the PD framework \cite{liu2017}.  On the other hand, the authors show that 
a variety of constraints, including strain constraints, bending constraints, collisions and position constraints can be expressed in terms of PD 
potentials and handled by the PD solver in a unified manner \cite{bouaziz2014}. Where applicable, the constraints are derived from continuous 
energies, leaving them reasonably independent to the underlying meshing.

\paragraph{Hard Constraints.}
There is no obvious way to implement hard constraints with the PD solver since energy potentials with infinite stiffness cannot be formulated in terms of PD energy 
potentials. Making stiffness arbitrarily large allows approximating hard constraints. However, this comes with adverse effects to the numerical properties of 
the system matrix (see Section \ref{ss:penalty-forces}). Using position constraints with arbitrarily large stiffness values to move particles 
away from their inertial positions is particular challenging in light of the fact that the position constraints need to overcome both competing constraints 
and the time step dependent inertial penalty in Equation \ref{eq:variational-implicit}. This is particularly relevant for small time step sizes where the 
inertial penalty is increased dramatically.

\paragraph{Convergence.}
While a simplified minimization problem is constructed by restricting to PD energy potentials, the solver attempts to find the 
true solution of Equation \ref{eq:pd-minimization} instead of computing an approximation. The objective function is quadratic, bounded below 
and both local and global steps are guaranteed to weakly decrease it. As a result, the optimization converges without additional 
safeguards, even if non-convex constraint manifolds are used in the energy potentials. However, this property alone does not ensure that 
PD converges to the positions that minimize the objective function of the variational form of implicit Euler integration. 
According to Bouaziz et al.\ \cite{bouaziz2014}, the true implicit positions preserve linear and angular momentum if the elastic potential 
is rigid motion invariant. It is not clear whether this property is satisfied for the positions that PD converges to as well.

\paragraph{Changing Constraint Sets.}
Lastly, it is important to note that the PD solver is not suited for handling frequently changing constraint sets. For example, every time 
a collision is detected, a new constraint needs to be added to the simulation and the global system matrix $\matm{S}$ needs
to be refactorized. This can slow down the PD solver quite significantly and can lead to unpredictable solver speeds that are infeasible in the
context of real-time simulations.

\subsection{Simulating Deformable Bodies using PD}\label{ss:pd-deformable-bodies}
As discussed in Section \ref{ss:pd-properties}, classical material models such as the St.\ Venant-Kirchhoff and Neohookean model cannot be expressed in 
terms of PD energy potentials and are incompatible with the PD solver as a result. However, we demonstrate how the strain material model in 
Equation \ref{eq:strain-material-model} can be used with PD. For each tetrahedron in the tetrahedral mesh of the simulated body, we need to 
construct a PD energy potential $\psi_i$ such that 

\[
    \psi_j(\matm{q}) = \min_{\matm{p}_j} \frac{w_j}{2} \norm{\matm{A}_j\matm{q}_j - \matm{B}_j\matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j)
    = V_j\psi_{\text{strain}}(\matm{F}_j),
\]

\noindent where $V_j$ is the volume of the undeformed tetrahedron. Recall that $\matm{F}_j$ is the constant deformation gradient over the volume 
of the tetrahedron and can be computed via Equation \ref{eq:deformation-gradient-tet}. 

Since the energy potential of a single tetrahedron solely depends on its four tetrahedral vertices, it 
is $\matm{q}_j, \matm{p}_j \in \mathbb{R}^{4 \times 3}$. We set the constraint manifold $\cman{C}_j$ to the set of all matrices $\matm{p} 
\in \mathbb{R}^{4 \times 3}$ that correspond to undeformed tetrahedra if the rows of $\matm{p}$ are interpreted as the positions of the 
tetrahedral vertices. Let $\matm{D} \in \mathbb{R}^{3 \times 4}$ be the matrix that maps such matrices $\matm{p}$ to the transpose of their deformation 
gradient $\matm{F}_\matm{p}^T$. Then $\cman{C}_j$ can be defined as

\begin{equation}\label{eq:pd-strain-constraint}
    \cman{C}_j = \{ \matm{p} \mid \matm{D}\matm{p} = \matm{F}_\matm{p}^T \in \text{SO}(3) \},
\end{equation}

\noindent where $\text{SO}(3)$ is the group of three-dimensional rotational matrices. We set $\matm{A}_j = \matm{B}_j = \matm{D}$ and $w_j = k_jV_j$, 
where $V_j$ is the volume of the undeformed tetrahedron and $k_j$ is a user-defined stiffness value. Together, it is

\begin{align}
    \begin{split}\label{eq:pd-strain}    
    \psi_j(\matm{q}) 
    = \min_{\matm{p}_j} W(\matm{S}_j\matm{q}, \matm{p}_j) 
    &= \min_{\matm{p}_j} \frac{k_jV_j}{2} \norm{\matm{D}\matm{q}_j - \matm{D}\matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j) \\
    &= \min_{\matm{F}_{\matm{p}_j}} \frac{k_jV_j}{2} \norm{\matm{F}_j^T - \matm{F}_{\matm{p}_j}^T}^2_F + \delta_{\text{SO}(3)}(\matm{F}_{\matm{p}_j}).
    \end{split}
\end{align}

\noindent It is easy to show that $\matm{F}_{\matm{p}_j}$ can be computed as $\matm{F}_{\matm{p}_j} = \matm{UIV}^T$ where $\matm{F}_j = 
\matm{U \Sigma V}^T$ is the singular value decomposition of the deformation gradient $\matm{F}_j$. Plugging into Equation \ref{eq:pd-strain}
yields

\[
    \psi_j(\matm{q}) = \frac{k_jV_j}{2} \norm{\matm{U}^T\matm{\Sigma}\matm{V} - \matm{U}^T\matm{I}\matm{V}}^2_F 
    = \frac{k_jV_j}{2} \norm{\matm{\Sigma} - \matm{I}}^2_F = V_j \psi_{\text{strain}}(\matm{F}_i),
\]

\noindent showing that the strain material model can be expressed in terms of PD energy potentials.

\subsection{Projective Dynamics as a Special Case of Quasi-Newton Methods}\label{ss:pd-quasi-newton}
In PD, the variational form of implicit Euler integration that results from restricting to PD energy potentials (see Eq.\ \ref{eq:pd-minimization}) 
is solved by using a specialized local/global alternating minimization technique (see Sec.\ \ref{ss:pd-solver}). If the projection points 
$\matm{p}^j_{\matm{q}}$ with 

\[
    \matm{p}_{\matm{q}_j} 
    = \argmin{\matm{p}_j} \psi_j(\matm{q}) 
    = \argmin{\matm{p}_j} \frac{w_j}{2} \norm{\matm{G}_j\matm{q} - \matm{p}_j}^2_F + \delta_{\cman{C}_j}(\matm{p}_j)
\]

\noindent are considered functions of $\matm{q}$ with $\matm{p}_j(\matm{q}) = \matm{p}^j_{\matm{q}}$, then the equivalent optimization problem

\begin{equation}\label{eq:pd-minimization-q}
    \min_{\matm{q}} g(\matm{q}) = 
    \min_{\matm{q}} \frac{1}{2h^2} \norm{\matm{M}^{1/2}(\matm{q} - \tilde{\matm{q}})}^2_F + \sum_j \frac{w_j}{2} \norm{\matm{G}_j\matm{q}
    - \matm{p_j}(\matm{q})}^2_F
\end{equation}

\noindent can be solved using general purpose algorithms for unconstrained optimization. We show that the PD solver can be interpreted as a Quasi-Newton 
method applied to the objective function $g$ in Equation \ref{eq:pd-minimization-q} \cite{liu2017}.

We start by briefly introducing Newton's method, which is one of the most popular algorithms for unconstrained optimization. For a more detailed introduction, 
we refer the interested reader to the relevant chapters in the textbook on numerical optimization by Nocedal and Wright \cite{nocedal2006}. Newton's method 
is an iterative procedure that starts with some initial guess $\matm{q}_0$ and then iteratively improves it by applying updates in a direction that is 
guaranteed to reduce the objective function until a local minimum is achieved. Applying Newton's method to the objective function $g$ in Equation 
\ref{eq:pd-minimization-q} yields the following update formula 

\begin{equation}\label{eq:pd-newton-update}
    \matm{q}_{k+1} = \matm{q}_k - \alpha_k \nabla^2 g(\matm{q}_k)^{-1} \nabla g(\matm{q}_k) = \matm{q}_k - \alpha_k \matm{r}^N_k.
\end{equation}

\noindent Here, $\nabla^2 g(\matm{q}_k)$ is the Hessian matrix of $g$ at $\matm{q}_k$, $\matm{r}^N_k = \nabla^2 g(\matm{q}_k)^{-1} \nabla g(\matm{q}_k)$ 
is called the Newton direction and $\alpha_k \in \mathbb{R}^+$ is called the step size. If $\nabla^2 g(\matm{q}_k)$ is invertible and $\alpha_k$ is 
sufficiently small, the Newton update is guaranteed to decrease the objective function. However, to ensure that each Newton update makes sufficient progress 
towards a local minimum, it is desirable to keep $\alpha_k$ as large as possible. Newton's method exhibits favorable convergence properties, but the computation 
and storage of the inverse Hessian matrix $\nabla^2 g(\matm{q}_k)^{-1}$ is often prohibitively expensive. This gives rise to the so-called Quasi-Newton methods. 
There, the Hessian matrix $\nabla^2 g(\matm{q}_k)$ is approximated by some matrix $\matm{B}_k$ that is faster to compute, but still yields suitable search directions 
$\matm{r}_k$. The update formula for Quasi-Newton methods is given by

\begin{equation}\label{eq:pd-qn-update}
    \matm{q}_{k+1} = \matm{q}_k - \alpha_k \matm{B}^{-1}_k \nabla g(\matm{q}_k).
\end{equation}

Now, consider the Quasi-Newton update formula with constant step size $\alpha_k = 1$ and Hessian approximation $\matm{B}_k = \matm{S}$, where $\matm{S}$
is the system matrix from the global optimization in PD (see Eq.\ \ref{eq:pd-global-system}), given by

\begin{equation}\label{eq:pd-qn-update-S}
    \matm{q}_{k+1} = \matm{q}_k - \matm{S}^{-1}_k \nabla g(\matm{q}_k).
\end{equation}

\noindent Liu et al. \cite{liu2017} show that $\nabla g$ is equal to

\begin{equation}\label{eq:pd-gradient-qn}
    \nabla g(\matm{q}) = \frac{1}{h^2}\matm{M}(\matm{q} - \tilde{\matm{q}}) + \sum_j w_j \matm{G}^T_j \matm{G}_j \matm{q}
    - \sum_j w_j \matm{G}^T_j \matm{p}_j(\matm{q}).
\end{equation}

\noindent Surprisingly, this is the same as the gradient $\nabla_{\matm{q}} \tilde{g}(\matm{q}, \matm{p}_j)$ of the global optimization problem of the original
PD algorithm (see Eq.\ \ref{eq:pd-gradient-q}). Thus, the gradient is unaffected by whether $\matm{p}_j$ is considered constant or a function
$\matm{p}_j(\matm{q})$ of the positions $\matm{q}$. Plugging $\nabla g(\vecm{q}_k)$ into Equation \ref{eq:pd-qn-update-S} results in 

\begin{align*}
    \matm{q}_{k+1} &= \matm{q}_k - \matm{S}^{-1}\left(\frac{1}{h^2}\matm{M}(\matm{q}_k - \tilde{\matm{q}}) + \sum_j w_j \matm{G}^T_j \matm{G}_j \matm{q}_k
    - \sum_j w_j \matm{G}^T_j \matm{p}_j(\matm{q}_k)\right)\\
                   &= \matm{q}_k - \matm{S}^{-1}\left(\matm{S}\matm{q}_k - \frac{1}{h^2}\tilde{\matm{q}} - \sum_j w_j \matm{G}^T_j \matm{p}_j(\matm{q}_k)\right)\\
                   &= \matm{S}^{-1}\left(\frac{1}{h^2}\tilde{\matm{q}} + \sum_j w_j \matm{G}^T_j \matm{p}_j(\matm{q}_k)\right).
\end{align*}

\noindent Note that this is exactly the solution of the global linear system from PD in Equation \ref{eq:pd-global-system}. Together, this shows 
that performing a Quasi-Newton step with Hessian approximation $\matm{B}_k = \matm{S}$ and step size $\alpha_k = 1$ on the 
minimization problem in Equation \ref{eq:pd-minimization-q} is equivalent to performing a local/global iteration of the PD solver 
(\cref{alg:pd}). The Quasi-Newton version of PD is summarized in Algorithm \ref{alg:pd-qn}.

\begin{algorithm}
\caption{Projective Dynamics as a Quasi-Newton Method}\label{alg:pd-qn}
\begin{algorithmic}
\Procedure{solvePDViaQN}{$\matm{q}_n$, $\matm{v}_n$, $\matm{f}_{\text{ext}}$, $h$}
\State $\tilde{\matm{q}} = \matm{q}_n + h\matm{v}_n + h^2\matm{M}^{-1}\matm{f}_{\text{ext}}$
\State $\matm{q}_k = \tilde{\matm{q}}$
\For{all iterations}
\State $\matm{p}_k \gets$ solution of $\matm{S}\matm{p} = -\nabla g(\matm{q}_k)$
\State $\matm{q}_k = \matm{q}_k + \matm{p}_k$
\EndFor
\State \textbf{return with result } $\matm{q}_{n+1} = \matm{q}_k, \matm{v}_{n+1} = (\matm{q}_{n+1} - \matm{q}_n)/h$
\EndProcedure
\end{algorithmic}
\end{algorithm}

The insight that PD is a special case of Quasi-Newton methods applied to Equation \ref{eq:pd-minimization-q} can be leveraged to
bring performance improvements to the original PD solver and to design a natural extension of PD to energies that do not fit 
into the original PD framework. Both are discussed in Section \ref{s:qn-rts}.

\section{Quasi-Newton Methods for Physical Simulations}\label{s:qn-rts}
In Section \ref{ss:pd-quasi-newton}, we discussed that the PD solver for the minimization problem in Equation \ref{eq:pd-minimization}
can be interpreted as a special case of a Quasi-Newton method with constant Hessian approximation and step size $\alpha = 1$
applied to the corresponding minimization problem Equation \ref{eq:pd-minimization-q}. The formulation that is suitable for Quasi-Newton
methods

\begin{equation}\label{eq:pd-minimization-q2}
    \min_{\matm{q}} g(\matm{q}) = 
    \min_{\matm{q}} \frac{1}{2h^2} \norm{\matm{M}^{1/2}(\matm{q} - \tilde{\matm{q}})}^2_F + \sum_j \frac{w_j}{2} \norm{\matm{G}_j\matm{q}
    - \matm{p_j}(\matm{q})}^2_F
\end{equation}

\noindent and the global system matrix $\matm{S}$ serving as the constant Hessian approximation

\begin{equation}\label{eq:global-matrix}
    \matm{S} \coloneqq \frac{1}{h^2}\matm{M} + \sum_j w_j \matm{G}_j^T \matm{G}_j  
\end{equation}

\noindent are restated for convenience of the reader. This highlights one of the weaknesses of the PD solver. Since the Hessian approximation 
is constant, the PD solver does not take advantage of local curvature information around the current positions $\vecm{q}_k$ during its position 
update. This is in contrast to Newton's method, where the curvature of the objective function around $\vecm{q}_k$ is captured by the Hessian 
matrix $\nabla^2 g(\matm{q}_k)$ and is used to find an effective search direction. Most Quasi-Newton methods aim at computing Hessian 
approximations $\matm{B}_k$ that are as close to $\nabla^2 g(\matm{q}_k)$ as possible and capture the local curvature of the objective function 
reasonably well as a result. The L-BFGS method is a Quasi-Newton method that achieves this by computing a Hessian approximation $\matm{B}_k$ 
from some initial Hessian approximation $\matm{B}_0$, the previous $l \in \mathbb{N}^+$ iterates $\matm{q}_{k-1}, \ldots, \matm{q}_{k-l}$ 
and their gradients $\nabla g(\matm{q}_{k-1}), \ldots, \nabla g(\matm{q}_{k-l})$ \cite{nocedal2006}. The choice of the initial Hessian 
approximation $\matm{B}_0$ has a strong impact on the performance of the L-BFGS method. Usually, a scaled version of the identity matrix is 
used. Liu et al.\ \cite{liu2017} suggest that setting $\matm{B}_0 = \matm{S}$ combines the strengths of the PD solver and L-BFGS method 
and gives rise to a powerful approach to implicit Euler integration when applied to the optimization problem in Equation \ref{eq:pd-minimization-q2}.
In the rest of this thesis, we refer to the resulting solver as the QN solver. It is discussed in detail in Section \ref{ss:qn-pd}.

Since Quasi-Newton methods can be applied to the variational form of implicit Euler integration with general conservative energy potentials 
(see Eq.\ \ref{eq:variational-implicit}), this suggests a natural extension of the approach mentioned above to energies that do not fit into 
the original PD framework. However, if general conservative energy potentials are used, it is not obvious how to construct the initial Hessian 
approximation $\matm{S}$ anymore. Liu et al.\ suggest a way to emulate the global system matrix $\matm{S}$ for energies that can be written in
the Valanis-Landel form, which includes Neohookean and St.\ Venant-Kirchhoff energies. This extension is covered in Section 
\ref{ss:qn-valanis-landel}. Finally, the properties of the QN solver are discussed in Section \ref{ss:properties-qn}.


\subsection{Quasi-Newton Methods for PD Energy Potentials}\label{ss:qn-pd}
An overview over the L-BFGS method with initial Hessian approximation $\matm{B}_0 = \matm{S}$ applied to the optimization problem in Equation 
\ref{eq:pd-minimization-q2} is given in Algorithm \ref{alg:pd-lbfgs}. For more details on the L-BFGS method, we again refer to the book 
on numerical optimization by Nocedal and Wright \cite{nocedal2006}. To start off the L-BFGS solver, an initial guess $\matm{q}_0$ for a local 
minimizer of the objective function in Equation \ref{eq:pd-minimization-q2} is required. In the QN solver, the initial guess is set to the 
inertial positions, i.e.\ $\matm{q}_0 = \tilde{\matm{q}}$ (lines 3-4). For each iteration $k$, the search direction $\matm{p}_k = 
-\matm{B}_k^{-1}\nabla g(\matm{q}_k)$ is computed in lines 6-7. In lines 8-12, an appropriate step size $\alpha_k$ for the current search 
direction $\matm{p}_k$ is determined. Given the step size $\alpha_k$ and the search direction $\matm{p}_k$, the next iterate 
is computed in line 12. Finally, the positions and the velocities for the next time step are updated after the last iteration in line 15.

\begin{algorithm}
\caption{L-BFGS method for PD energies}\label{alg:pd-lbfgs}
\begin{algorithmic}[1]
\State \textbf{require } $\beta \in (0, 1)$, $t \in (0, 1)$
\Procedure{solvePDViaLBFGS}{$\matm{q}_n$, $\matm{v}_n$, $\matm{f}_{\text{ext}}$, $m$, $h$}
\State $\tilde{\matm{q}} = \matm{q}_n + h\matm{v}_n + h^2\matm{M}^{-1}\matm{f}_{\text{ext}}$
\State $\matm{q}_k = \tilde{\matm{q}}$
\For{all iterations}
\State $\matm{s_k} = \matm{q}_k - \matm{q}_{k-1}, \matm{y}_k = \nabla g(\matm{q}_k) - \nabla g(\matm{q}_{k-1}), \rho_k = 1 / \text{tr}(\matm{s}^T_k \matm{y}_k)$
\State $\matm{p}_k = \text{\textsc{twoLoopRecursion}}(\matm{S}, \matm{q}_k, \matm{s}, \matm{y}, \rho, m, k)$   (\cref{alg:lbfgs-recursion})
\State $\alpha_k = 1$
\If{$\alpha_k$ does not satisfy the strong Wolfe conditions}
\State compute $\alpha_k$ that satisfies the strong Wolfe conditions 
\State \textbf{or} $\alpha_k = \text{\textsc{backtrack}}(\matm{q}_k, \matm{p}_k, 1, \beta, t)$ (\cref{alg:backtracking})
\EndIf
\State $\matm{q}_k = \matm{q}_k + \alpha_k \matm{p}_k$
\EndFor
\State \textbf{return with result } $\matm{q}_{n+1} = \matm{q}_k, \matm{v}_{n+1} = (\matm{q}_{n+1} - \matm{q}_n)/h$
\EndProcedure
\end{algorithmic}
\end{algorithm}

The search direction $\matm{p}_k$ is computed using the two-loop recursion shown in Algorithm \ref{alg:lbfgs-recursion} \cite{nocedal2006, liu2017}.
Here, the Hessian approximation used in the L-BFGS method $\matm{B}_k$ does not need to be stored or computed explicitly. Instead, the 
search direction $\matm{p}_k$ can be calculated directly at the cost of $\mathcal{O}(l)$ inner products and vector additions (lines 3-5 and 8-10) 
and solving an LSE with constant system matrix $\matm{S}$ (line 7). The quantities $\matm{s}_k, \matm{y}_k$ and $\rho_k$ are computed from the 
positions and gradients from previous iterations and are stored over a window of $l$ iterations (see Alg.\ \ref{alg:pd-lbfgs}, line 6). This 
enables capturing curvature information during the computation of the search direction $\matm{p}_k$ in the two-loop recursion. 

\begin{algorithm}
\caption{L-BFGS two-loop Recursion}\label{alg:lbfgs-recursion}
\begin{algorithmic}[1]
\Procedure{twoLoopRecursion}{$\matm{B}_0$, $\matm{q}_k$, $\matm{s}$, $\matm{y}$, $\rho$, $l$, $k$}
\State $l^* = \min(l, k), \matm{t} = -\nabla g(\matm{q}_k)$
\For{$i = k-1, k-2, \ldots, k-l^*$}
\State $\alpha_i = \rho_i \text{tr}(\matm{s}^T_i \matm{t})$
\State $\matm{t} = \matm{t} - \alpha_i \matm{y}_i$
\EndFor
\State solve $\matm{B}_0 \matm{r} = \matm{t}$
\For{$i = k-l^*, k-l^*+1, \ldots, k-1$}
\State $\beta = \rho_i \text{tr}(\matm{y}^T_i \matm{r})$
\State $\matm{r} = \matm{r} + \matm{s}_i(\alpha_i - \beta)$
\EndFor
\State \textbf{return with result } -$\matm{B}^{-1}_k \nabla g(\matm{q}_k) = \matm{r}$.
\EndProcedure
\end{algorithmic}
\end{algorithm}

Step sizes $\alpha_k$ for the L-BFGS method are usually chosen such that they satisfy the Wolfe conditions, which ensures that sufficient progress 
towards a local minimizer is made during each L-BFGS iteration (see \cite{nocedal2006}). Finding such step sizes typically requires the execution of 
so-called step size selection algorithms. Instead, Liu et al.\ \cite{liu2017} opt for a simpler strategy called backtracking (see Alg.\ 
\ref{alg:backtracking}). There, the natural step size associated with Newton's method $\alpha_k = 1$ is iteratively reduced by a factor of $\beta$ 
until the first Wolfe condition is satisfied (lines 4-5). This is guaranteed to happen if $\matm{p}_k$ is a descent 
direction and if $\alpha_k$ is sufficiently small. In practice, backtracking is stopped after $\alpha_k < t$ for some user defined threshold $t$ to 
prevent pathologically small step sizes (line 4).

\begin{algorithm}
\caption{Backtracking Line Search}\label{alg:backtracking}
\begin{algorithmic}[1]
\State \textbf{require } $\tilde{\alpha} > 0, c_1 \in (0, 1), \beta \in (0, 1), t \in (0, \tilde{\alpha})$
\Procedure{backtrack}{$\matm{q}_k$, $\matm{p}_k$, $\tilde{\alpha}$, $\beta$, $t$}
\State $\alpha = \tilde{\alpha}$
\While{$g(\matm{q}_k + \alpha \matm{p}_k) > g(\matm{q}_k) + c_1 \alpha \nabla g(\matm{q}_k)^T \matm{p}_k$ and $\alpha > t$}
\State $\alpha = \beta \alpha$
\EndWhile
\State \textbf{return with } $\alpha_k = \alpha$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Quasi-Newton Methods for Valanis-Landel Energies}\label{ss:qn-valanis-landel}
To achieve satisfactory performance when applying the L-BFGS method to the variational form of implicit Euler integration 
(see Eq.\ \ref{eq:variational-implicit}) without the need to restrict energy potentials to the PD framework (see Eq.\ \ref{eq:pd-potentials}), a suitable
candidate for the initial Hessian approximation $\matm{B}_0$ or its inverse $\matm{H}_0$ needs to be found. The choice $\matm{B}_0 = 
\matm{S} = \frac{1}{h^2}\matm{M} + \sum_j w_j \matm{G}_j^T \matm{G}_j$ from Algorithm \ref{alg:pd-lbfgs} cannot be applied to the general setting 
without modification as the matrices $\matm{G}_j$ are taken directly from the definitions of the individual PD energy potentials.

We focus on the setting of tetrahedral meshes with energy potentials that are derived from one of the material models in Section \ref{ss:material-models} 
for each tetrahedron. Here, the energy of the entire body is the sum of the individual tetrahedral energies (see Sec.\ \ref{ss:deformable-bodies}).
As shown in Section \ref{ss:pd-deformable-bodies}, the energy of a single tetrahedron can be emulated using PD potentials when the strain material model is 
used (see Eq.\ \ref{eq:pd-strain}). Here, $\matm{G}_j = \matm{A}_j$, where $\matm{A}_j$ is the linear operator that maps $\matm{q}$ 
to the tranpose of the deformation gradient $\matm{F}^T_j$, $\cman{C}_j = \text{SO}(3)$ and $w_j = k_jV_j$, where $V_j$ is the
volume of the undeformed tetrahedron and $k_j$ is a user-defined stiffness value. 
Liu et al.\ suggest approximating more general tetrahedral energies with PD strain potentials and using the global system
matrix $\matm{S}$ that arises as the initial Hessian approximation $\matm{B}_0$ given by

\begin{equation}\label{eq:global-matrix-strain}
    \matm{B}_0 = \matm{S} = \frac{1}{h^2}\matm{M} + \sum_j w_j \matm{A}_j^T \matm{A}_j.
\end{equation}

Instead of using user-defined stiffness values $k_j$, a procedure for setting $k_j$ from the original, more general energy
potential is required. The discussion is restricted to isotropic and world-space rotation invariant material models that 
can be defined in terms of the singular 
values $\sigma_1, \sigma_2, \sigma_3$ of $\matm{F_j}$ called the principal stretches \cite{sifakis2012}. Liu et al.\ 
\cite{liu2017} present a strategy for a subclass of these material models that can be written in Valanis-Landel form

\begin{equation}\label{eq:valanis-landel}
    \Psi(\sigma_1, \sigma_2, \sigma_3) = a(\sigma_1) + a(\sigma_2) + a(\sigma_3) + b(\sigma_1 \sigma_2) 
    + b(\sigma_2 \sigma_3) + b(\sigma_1 \sigma_3)
\end{equation}

\noindent with $a, b, c : \mathbb{R} \to \mathbb{R}$. Many popular material models including the St.\ Venant-Kirchhoff model and 
the Neohookean model can be expressed in this form.

The approach uses the insight that for linear materials that follow Hooke's law, the stiffness $k_j$ is given as the second 
derivative of the energy potential. Computing first and second partial derivatives in the rest configuration $\sigma_1, 
\sigma_2, \sigma_3 = 1$ yields

\begin{align}
    \evalat[\bigg]{\frac{d \psi}{d \sigma_i}}{\sigma_j, \sigma_k = 1} 
    &= a^{\prime}(\sigma_i) + 2b^{\prime}(\sigma_i) + c^{\prime}(\sigma_i) \label{eq:valandis-landel-first} \\
    \evalat[\bigg]{\frac{d^2 \psi}{d \sigma_i}}{\sigma_j, \sigma_k = 1} 
    &= a^{\prime\prime}(\sigma_i) + 2b^{\prime\prime}(\sigma_i) + c^{\prime\prime}(\sigma_i) \label{eq:valandis-landel-second},
\end{align}

\noindent where $i, j, k \in [1, 3], i \neq j \neq k$. Thus, the first and second partial derivatives at the rest configuration are the same
for each of the principal stretches, allowing for convenient representation of the material stiffness in a single scalar value. However,
simply picking

\[
    k_j = \evalat[\bigg]{\frac{d^2 \psi}{d \sigma_i}}{\sigma_i, \sigma_j, \sigma_k = 1} 
    &= a^{\prime\prime}(1) + 2b^{\prime\prime}(1) + c^{\prime\prime}(1)
\]

\noindent runs into issues as the expression often evaluates to zero, even in common non-pathological cases. This issue arises because
the second derivative in Equation \ref{eq:valandis-landel-second} is not representative of the stiffness behavior of the material in the 
entire range of principal stretches $[\sigma_{\text{min}}, \sigma_{\text{max}}]$ that is expected to be encountered during the simulation.

To alleviate this, Liu et al.\ \cite{liu2017} propose approximating the rate of change of the first derivative Equation \ref{eq:valandis-landel-first}
by computing the slope of its best linear approximation over the interval $[\sigma_{\text{min}}, \sigma_{\text{max}}]$. Formally, $k$ is 
defined by

\begin{equation}\label{eq:valanis-landel-k}
    k \coloneqq \argmin{k} \int^{\sigma_{\text{max}}}_{\sigma_{\text{min}}} (k(\sigma - 1) - (a^{\prime}(\sigma) + 2b^{\prime}(\sigma) + 
    c^{\prime}(\sigma))^2 d\sigma
\end{equation}

\noindent Using these stiffness values in Equation \ref{eq:global-matrix-strain} yields a suitable initial Hessian approximation $\matm{B}_0 = S$ for
the minimization of the variational form of the implicit Euler integration with Valanis-Landel materials via Algorithm \ref{alg:pd-lbfgs}. According
to Liu et al.\ Algorithm \ref{alg:pd-lbfgs} is insensitive to the size of the interval $[\sigma_{\text{min}}, \sigma_{\text{max}}]$. It is important
to note that while PD strain energies are used to approximate the original energy potentials when constructing $\matm{B}_0$, the function
evaluations $g(\matm{q}_k)$ and gradients $\nabla g(\matm{q}_k)$ are computed from the original potential energies in Algorithm \ref{alg:pd-lbfgs}.

\subsection{Properties of Quasi-Newton Methods for Physical Simulations}\label{ss:properties-qn}
The QN solver described in Sections \ref{ss:qn-pd} and \ref{ss:qn-valanis-landel} emerges from combining ideas from PD and the L-BFGS method for 
unconstrained optimization. As a result, the QN solver has superior convergence properties and is more general than the PD solver. We discuss the 
properties of the QN solver below.

\paragraph{Relation to the PD Solver.}
As described in Section \ref{ss:pd-quasi-newton}, the PD solver can be interpreted as a Quasi-Newton method with constant step size and Hessian approximation 
applied to the optimization problem in Equation \ref{eq:pd-minimization-q2}. The QN solver enhances the PD solver by applying L-BFGS updates that capture local
curvature information to the constant Hessian approximation $\matm{S}$ and performing backtracking to find a step size that is guaranteed to at least satisfy 
the first Wolfe condition. Experimental data provided by Liu et al.\ \cite{liu2017} suggests that this leads to 
significantly improved convergence properties. This is in line with the fact that the convergence properties of Quasi-Newton methods benefit from Hessian 
approximations $\matm{B}_k$ that are as close as possible to the true Hessian matrix $\nabla^2 g(\matm{q}_k)$ \cite{nocedal2006}. As described in Section 
\ref{ss:qn-valanis-landel}, the QN solver can be applied to material models that can be written in the Valanis-Landel form. Thus, the QN solver is 
more general than the PD solver.

\paragraph{Step Size.}
In our discussion of PD (see Sec.\ \ref{ss:pd-properties}), we pointed out that PD iterations are guaranteed to weakly decrease the objective function of 
the variational form of implicit Euler integration. As such, using a constant step size of $\alpha_k = 1$ is a viable choice when the constant Hessian 
approximation $\matm{B}_k = \matm{S}$ is chosen. In contrast, it is well known that search directions $\matm{p}_k$ produced by the L-BFGS method may not 
be directions of descent if the step sizes $\alpha_k$ are not guaranteed to satisfy the Wolfe conditions \cite{nocedal2006}. In such settings, convergence 
of the L-BFGS method 
is not guaranteed. Since the step size $\alpha_k$ determined by backtracking (see Alg.\ \ref{alg:pd-lbfgs}) may not satisfy the second Wolfe 
condition, this applies for the QN solver as well. However, Liu et al.\ \cite{liu2017} report that skipping more complicated step size selection algorithms 
in favor of simple backtracking works well in practice. In contrast, leaving out backtracking all together and simply using $\alpha_k=1$ produces poor 
results according to the authors. Thus, it is essential that step sizes at the very least satisfy the first Wolfe condition.

\paragraph{Efficient Implementation.}
The QN solver lends itself to efficient implementation. Firstly, the contributions of each tetrahedral element to the evaluations of the objective function $g$ 
and its gradient $\nabla g$ can be computed independently and are easily parallelizable as a result. Secondly, the two-loop recursion (see Alg.\ 
\ref{alg:lbfgs-recursion}) can be performed at the cost of $\mathcal{O}(l)$ inner products and vector additions (lines 3-5 and 8-10) and solving an LSE with 
constant system matrix $\matm{S}$ (line 7). The total computational cost incurred by the inner products 
and vector additions is only $\mathcal{O}(lm)$, where $m$ is the number of particles. Solving the LSE can be sped up by precomputing and storing a matrix 
factorization of $\matm{S}$. Lastly, the LSE can be solved independently for $x$-, $y$- and $z$- coordinates since $\matm{t} \in \mathbb{R}^{m \times 3}$.

\paragraph{Choice of L-BFGS History Window Size.}
The user defined L-BFGS window size $l$ needs to be large enough to sufficiently capture local curvature information. On the other hand, L-BFGS performance can 
be negatively affected by taking into account distant iterates if $l$ is too large. Liu et al.\ \cite{liu2017} recommend a window size of $l = 5$. Additionally, the 
authors report that it may be useful to reduce the window size for simulations with frequent collisions.

\paragraph{Changing Constraint Sets.}
In PD, the system matrix $\matm{S}$ and its factorization need to be recomputed each time a constraint is added to or removed from the simulation. This is not the case 
for the initial Hessian approximation $\matm{B}_0$ used in the QN solver \cite{liu2017}. When a new constraint is added, it is accounted for by the contribution of its 
energy or energy gradient to the evalution of $g$ and $\nabla g$. Ignoring its contribution to the initial matrix approximation $\matm{B}_0$ can be interpreted as a more 
aggressive Hessian approximation that might negatively affect the convergence rate of the solver. However, with an an appropriate step size selection algorithm in place, 
the solver will still successfully decrease the objective function $g$. This suggests that it might be helpful to replace backtracking with a step size selection 
algorithm that ensures that the step size $\alpha_k$ satisfies both Wolfe conditions during simulations with rapidly changing constraint sets. This includes collision 
heavy simulations.

\paragraph{Hard Constraints.}
The challenges of implementing hard constraints with the QN solver are identical to those discussed for PD in Section \ref{ss:pd-properties}.

\section{ADMM}\label{s:admm}
\subsection{Properties of ADMM}\label{ss:admm-properties}
To the best of our knowledge, no method for determining the choice of $w_i$ for reliably fast convergence is available.
However, Overby et al.\ \cite{overby2017} state that setting the weight $w_i$ of strain constraint $C_i$ with stiffness $k$ to $w_i = \sqrt{k}$ is a good starting point, since 
ADMM is almost equivalent to PD with this choice of parameters. The authors provide experimental data that suggests 
that reducing $w_i$ can have beneficial effects on the convergence rate of ADMM, but that the algorithm may fail to converge if 
the weights are reduced too much. The first observation can be explained by taking a closer look at the $\vecm{z}$-update, which is restated here again 
for the convenience of the reader

\begin{equation}\label{eq:admm-z-update-copy}
    \vecm{z}_i^{n+1} = \argmin{\vecm{z}_i} \left (\psi_i(\vecm{z}_i) + \frac{1}{2}\norm{\matm{W}_i(\matm{D}_i\vecm{q}^{n+1} - \vecm{z}_i + \bar{\vecm{u}}^i_n)}^2_F \right ).
\end{equation}

\noindent According to Overby et al.\ \cite{overby2017}, the $\vecm{z}$-update can be interpreted as a proximal operator for $\psi_i$ and intuitively amounts to 
minimizing $\psi_i$ with a quadratic penalty for moving away from $\matm{D}_i\vecm{x}^{n+1}+ \bar{\vecm{u}}^i_n$. This penalty increases with the weights that make 
up the entries of $\matm{W}_i$. Thus, reducing the weights allows making faster progress towards a solution that minimizes the constraint during 
the $\vecm{z}$-update. Keeping in mind that $\matm{D}_i\vecm{q}^* = \vecm{z}^*$ for all constraints $C_i$ once ADMM converges, it is natural to assume that using smaller
weights is particularly helpful when the converged positions $\vecm{q}^*$ reduce the total constraint energy $\Psi$ significantly in comparison to the initial positions 
$\vecm{q}_0$. However, if $\Psi(\vecm{q}^*) \approx \Psi(\vecm{q}_0)$, it might be counterproductive to take large steps towards a solution that minimizes the constraint 
energies during the $\vecm{z}$-update. This effect might also be responsible for ADMM's failure to converge if inappropriately small weights are used.

\section{Results}
The theoretical analysis of the solvers provided in \textcolor{red}{ref somewhere} shows that XPBD and PD-style solvers pursue fundamentally different approaches to 
performing implicit Euler integration on the equations of motion. XPBD employs a local Gauss-Seidel-type solver that independently minimizes energies one-by-one by 
performing corresponding constraint projections. On the other hand, PD-style solvers treat implicit integration as an 
optimization problem and attempt to minimize the objective function of the variational form of implicit Euler integration (see Sec.\ \ref{ss:variational-implicit-euler}). 
In contrast to XPBD, all PD-style solvers contain a global optimization step that enables making compromises during the minimization of multiple 
competing energies or constraints. The goal of this section is to provide experimental data that highlights how the differences between the solvers manifest themselves 
in practice during the simulation of deformable 3-dimensional bodies. Starting from experiments using the simple strain material model, we extend our analysis to the more 
complex Neohookean material model and incompatible constraint sets. Here, we say that a set of constraints is incompatible if there are no particle positions 
$\vecm{q}$ that simultaneously minimize all constraints from the set.

The main tool for comparing solvers used in this report consists of setting up identical simulation states and analyzing the positions computed by the solvers during 
each of the iterations required for the simulation of a single time step. We provide a detailed description of the simulated scenarios in 
Section \ref{ss:experimental-setup} and discuss how insights on various solver properties can be gained from the positions achieved after each iteration in 
Section \ref{ss:analysis-solvers}. During our comparison of the solvers, we exclude PBD due to the fact that it is not derived from the equations of motion and does not produce 
physically accurate results (see Sec.\ \ref{ss:pbd-properties}). We provide experimental data to justify this decision in Section \ref{ss:physical-pbd}. Additionally, before a meaningful 
comparison of ADMM with other solvers is possible, suitable ADMM weights need to be determined (see Sec.\ \ref{s:admm}). We provide insights on choosing ADMM weights in Section \ref{ss:admm-weights}. 
We start our comparison between XPBD and PD-style solvers on simulations using only tetrahedral constraints for the strain material model (see Sec.\ \ref{ss:strain-material}) 
in Section \ref{ss:untwisting-beam-strain}. The effects of adding position constraints that are incompatible with the material constraints are analyzed in 
Section \ref{ss:twisting-beam-strain}. Finally, the experiments in Section \ref{ss:untwisting-beam-strain} are repeated for the simplified Neohookean material model (see 
Sec.\ \ref{ss:simplified-neohookean-material}) in Section \ref{ss:untwisting-beam-neohookean} to gain insights on the compatibility of the solvers with more complicated non-linear 
material models.

\subsection{Experimental Setup}\label{ss:experimental-setup}
Experiments start from the deformed configuration of a cuboid beam that has been twisted in opposite directions at both ends (see Fig. \ref{fig:twisting-beam-setup}, left).
This initial deformed configuration is determined by simulating the twisting motion of the beam using the QN solver with a large number 
of iterations. Twisting is achieved by in-plane rotation of the reference positions 
of position constraints acting on particles at the ends of the beam. 

Starting from this configuration, we investigate the behavior of the 
solvers during the next time step in two settings: In the first, the position constraints at the ends of the beam are released, causing the 
beam to untwist (see Fig. \ref{fig:twisting-beam-setup}, top right). In the second, the beam is twisted further in accordance with a fixed angular
velocity as described above (see Fig. \ref{fig:twisting-beam-setup}, bottom right). In both settings, the initial positions of the twisted beam 
need to be updated to adapt to the changes to the position constraints at the ends of the beam. In the untwisting beam experiments, all constraints are satisfied at the 
undeformed reference configuration of the beam $\vecm{q}_\text{ref}$. However, the position constraints causing the twisting motion in the twisting beam experiments are 
incompatible with the tetrahedral constraints derived from the material model of interest. 

Position constraints are modelled via springs with rest-length zero and finite stiffness for all solvers. In other words, only soft position constraints 
are used. This has two main advantages: Firstly, soft position constraints can easily be modelled using each of the solvers, while it is challenging (or impossible) to 
implement hard position constraints with PD and QN. Mixing soft and hard position constraints makes it impossible to compare solvers,
since they would converge towards distinct solutions. Secondly, soft position constraints have corresponding spring energies that are 
finite and continuously differentiable. This allows for the computation of common metrics of deformed configurations such as the constraint 
energy. 

The elastic properties of the beam are modelled via the strain material model and the simplified Neohookean 
material model (see Sec.\ \ref{ss:material-models}). The strain model is supported by all solvers, whereas the simplified Neohookean model is 
not supported by PD. The simplified Neohookean model is chosen over the original Neohookean model because the log term in the original 
Neohookean energy potential makes it incompatible with XPBD (see Sec.\ \ref{ss:xpbd-deformable-bodies}). The experiments are run for time steps 
\SI{1e-1}{\second}, \SI{1e-2}{\second}, \SI{1e-3}{\second} and \SI{1e-4}{\second}. For the strain and Neohookean constraints, both 
stiffness and Youngs modulus, respectively, are set to powers of ten ranging from \num{1e5} to \num{1e12}. The Poisson ratio is fixed 
at 0.45 for all experiments, since we put the focus of our evalution on material stiffness over incompressibility. A representative subset of both twisting and untwisting 
beam experiments using the strain material model are discussed in subsections \ref{ss:untwisting-beam-strain} and \ref{ss:twisting-beam-strain}, respectively. For the 
Neohookean material model, we focus on the untwisting beam experiment in order to isolate the effects caused by applying solvers to a more complicated non-linear material 
model from artifacts caused by incompatible constraints. A representative set of experiments is discussed in Section \ref{ss:untwisting-beam-neohookean}.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
    \node[inner sep=0pt] (twisted) at (0,-1.625)
        {\includegraphics[width=.40\textwidth]{figures/twisted_beam.png}};
    \node[inner sep=0pt] (untwisted) at (8, 0)
        {\includegraphics[width=.40\textwidth]{figures/untwisted_beam.png}};
    \node[inner sep=0pt] (further-twisted) at (8,-3.25)
        {\includegraphics[width=.40\textwidth]{figures/further_twisted_beam.png}};
    \draw[->,thick] (twisted.east) -- (untwisted.west)
        node[midway,fill=white] {untwist};
    \draw[->,thick] (twisted.east) -- (further-twisted.west)
        node[midway,fill=white] {twist further};
    \end{tikzpicture}
    \caption{Visualization of the experimental settings starting from a twisted beam. The beam is either untwisted by removing position constraints at the 
    ends of the beam (top) or twisted further by rotating the anchor positions of the position constraints in-plane (bottom).}
    \label{fig:twisting-beam-setup}
\end{figure}

\subsection{Analyzing Solver Properties}\label{ss:analysis-solvers}
In many cases, poor solver performance is immediately obvious from closer inspection of the computed geometry. However, sometimes solvers can produce geometries 
that pass the eye test, but are in violation of the equations of motion. This is particularly applicable to small time step sizes. Thus, additional metrics are 
required to reliably evaluate solver performance across a variety of different time step sizes and stiffnesses. 

\paragraph{Objective Function of the Variational Form of Implicit Euler Integration.}
With the exception of PBD, all solvers discussed in the context of this thesis are based on implicit Euler integration of the equations of 
motion (see Sec.\ \ref{ss:numerical-integration}) and aim to either approximate (XPBD) or compute exactly (PD, ADMM and QN) the implicit positions at the next time step. 
As discussed in Section \ref{ss:numerical-integration}, the implicit positions can be interpreted as the positions that minimize the objective function of the variational 
form of implicit Euler integration given in Equation \ref{eq:variational-implicit}. To gain initial insights into the convergence behavior of the solvers, we compute 
the objective function value, or simply objective for short, for the positions obtained after each iteration for each solver. The objective function is restated here 
for the convenience of the reader

\begin{equation}\label{eq:variational-implicit-copy}
    f_{\text{obj}}(\vecm{q}) \coloneqq \min_{\vecm{q}} \frac{1}{2h^2} \norm{\matm{M}^{\frac{1}{2}}(\vecm{q} - \tilde{\vecm{q}})}^2_F + \sum_j \psi_j(\vecm{q}).
\end{equation}

\noindent The solvers are expected to decrease the objective function with each iteration until a value close to the minimum obtained 
by the implicit positions is achieved. By comparing the objectives of the positions after the final iteration, the quality of the configurations different
solvers converge to can be analyzed. Further, by plotting the objectives over the iteration number and inspecting the slope of the graphs, information about
the convergence rates of the solvers can be inferred. During the discussion of the resulting figures, we consider a solver converged once the graph of its objective function 
value over the iterations is visually indistinguishable from a horizontal line. While not entirely rigorous, this is particularly appropriate for comparing solvers in the 
context of real-time applications where solver iterations that only make minor progress towards the true implicit solutions often cannot be afforded. Additionally, this 
allows setting the focus on the most important qualitative differences between solvers without getting lost in the details of when a solver can formally be considered converged.

As discussed in Section \ref{ss:variational-implicit-euler}, the constraint term of the objective function corresponds to the sum of the constraint energies, while the 
inertial term introduces a penalty for moving particles away from their inertial positions $\tilde{\vecm{q}}$. However, in the context of the untwisting and twisting beam 
experiments described in Section \ref{ss:experimental-setup}, the inertial term can also be interpreted as the kinetic energy of the beam. To see this, note that both the initial 
particle velocities $\vecm{v}_0$ and the external forces $\vecm{f}_{\text{ext}}$ acting on the simulated body are zero. Consequently, the inertial positions $\tilde{\vecm{q}}$ 
are equivalent to the initial positions $\vecm{q}_0$, as shown below

\[ 
    \tilde{\vecm{q}} = \vecm{q}_0 + h\vecm{v}_0 + h^2\matm{M}^{-1}\vecm{f}_{\text{ext}} = \vecm{q}_0.
\]

\noindent It follows that the inertial term at the positions achieved after $k$ solver iterations $\vecm{q}_k$ can be rewritten as

\[
    \frac{1}{2h^2} \norm{\matm{M}^{\frac{1}{2}}(\vecm{q}_k - \vecm{q}_0)}^2_F 
    = \frac{1}{2} \norm{\matm{M}^{\frac{1}{2}}\frac{\vecm{q}_k - \vecm{q}_0}{h}}^2_F
    = \frac{1}{2} \norm{\matm{M}^{\frac{1}{2}}\vecm{v}_k}^2_F,
\]

\noindent where $\vecm{v}_k$ are the particle velocities after $k$ iterations as computed via Verlet integration. The last term in the equation above is exactly the 
kinetic energy of the simulated body. As the sum of the elastic and kinetic energy, the objective function can be interpreted as the energy of the beam. According 
to Newton's laws, this energy should be conserved in the absence of external forces. However, implicit Euler integration typically introduces numerical 
damping which is expected to reduce the energy of the beam over time (see Sec.\ \ref{ss:numerical-integration}).

\paragraph{Linear and Angular Momentum.}
Since adding artificial linear and angular momentum to simulations manifests itself in ghost forces which act like external forces dragging and rotating the object, 
conserving global momenta is a hard requirement for achieving visually plausible simulations \cite{mueller2006}. If the elastic forces in the equations of motion are 
derived from rigid motion invariant energy potentials, the true positions resulting from implicit Euler integration 
conserve linear and angular momentum \cite{bouaziz2014}. However, there are many situations where we cannot expect solvers to converge to the true implicit positions. 
As an example, we have shown that XPBD cannot be said to solve the equations of motions exactly due to simplifying assumptions made during the derivation of the XPBD 
constraint projection (see Sec.\ \ref{ss:xpbd-properties}). Additionally, in the context of real-time applications, the number of solver iterations is often fixed to ensure 
that the physics simulation fits into the allotted time budget. In such situations, there is no guarantee that solvers converge in the available number of iterations. 
Thus, it is important to analyze whether solvers conserve global momenta at both the converged configuration and the intermediate configurations achieved after each 
solver iteration. The computation of the linear and angular momentum after solver iteration $k$ requires the computation of velocities $\vecm{v}_k$ from the current 
positions $\vecm{q}_k$. In our experiments, we compute velocities $\vecm{v}_k$ by performing a Verlet integration step given by

\begin{equation}\label{eq:velocities}
    \vecm{v}_k = \frac{\vecm{q}_k - \vecm{q}_0}{h},
\end{equation}

\noindent where $h$ is the time step size. Now, let $i$ denote a particle index and let $\vecm{q}$ and $\vecm{v}$ denote the current particle positions and velocities, 
respectively. Then, the global linear momentum is equal to 

\begin{equation}\label{eq:linear-momentum}
    \sum_i m_i \vecm{v}_i,
\end{equation}

\noindent and the angular momentum with respect to some point $\vecm{p} \in $ is given by 

\begin{equation}\label{eq:angular_momentum}
    \sum_i (\vecm{q}_i - \vecm{p}) \times (m_i \vecm{v}_i).
\end{equation}

\subsection{Physically-Based PBD}\label{ss:physical-pbd}
In contrast to XPBD and the PD-style solvers, PBD is not derived from the implicit integration of the equations of motion. As a result, the stiffness of materials 
simulated using PBD depends on the number of iterations and the chosen time step (see Sec.\ \ref{ss:pbd-properties}). Accordingly, in the limit of infinite iterations and zero 
time step size, the material becomes infinitely stiff. We demonstrate this effect by example of a single solve over time steps \SI{1e-2}{\second} and \SI{1e-3}{\second} in the 
untwisting beam setting (see Fig. \ref{fig:twisting-beam-setup}) using strain constraints with stiffness \num{1e8} in Figure \ref{fig:strain-pbd}. The experiment shows that the 
beam is untwisted entirely to its undeformed reference configuration when using the PBD solver, regardless of the chosen time step. On the other hand, the degree to which the 
beam is untwisted depends on the time step size when using the QN solver. In particular, the beam untwists further when the larger time step of \SI{1e-2}{\second} 
is used. Of course, the behavior of the PBD solver is not physically plausible. This observation and the fact that PBD can seamlessly be extended to XPBD at the cost of storing 
a single additional variable per constraint leads us to the decision to exclude PBD from the remaining experiments in this thesis and to focus on analyzing the properties of 
XPBD, ADMM, PD and the QN solver instead.

\begin{figure}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/strain_pbd_1e-2.png}
    \subcaption{time step \SI{1e-2}{\second}}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/strain_pbd_1e-3.png}
    \subcaption{time step \SI{1e-3}{\second}}
    \end{subfigure}
    \caption{Geometries of an untwisting beam with strain constraints (stiffness \num{1e8}) after 1000 iterations over a single time step of size \SI{1e-2}{\second} (left) 
    and \SI{1e-3}{\second} (right) using PBD (red) and QN (cyan).}
    \label{fig:strain-pbd}
\end{figure}


\subsection{ADMM Weights}\label{ss:admm-weights}
As stated in Section \ref{ss:admm-properties}, there is no generally valid method for determining ADMM weights that ensures acceptable convergence properties.
Thus, we need to manually fine-tune ADMM weights before comparing different solvers using the method described above. The convergence of the ADMM solver is evaluated via 
the objective function of the beam (see Sec.\ \ref{ss:analysis-solvers}). We focus on untwisting beam experiments using strain constraints. For 
each combination of time steps from \SI{1e-1} to \SI{1e-4} and stiffnesses $k$ from \num{1e5} to \num{1e12}, candidate weights around the recommended value $w_i = \sqrt{k}$ 
are generated and the weight that reduces the objective function the fastest is used as the ADMM weight for all following experiments. 
This process reveals that ADMM weights are in fact time step dependent.

To see this, consider the plots of the objectives over the number of ADMM iterations with different weights for time steps \SI{1e-2}{\second} and 
\SI{1e-3}{\second} with constraint stiffness \num{1e8} shown in Figure \ref{fig:strain-weights-admm}. When a time step 
of \SI{1e-2}{\second} is used (see Fig. \ref{fig:strain-weights-admm} a), the ADMM solver converges to the same objective for all of the weights, except for the 
lowest weight $w_i = 0.1\sqrt{k}$, where the value is increased compared to the initial objective. The fastest convergence is achieved by setting $w_i = 0.3\sqrt{k}$ and 
$w_i = 0.4\sqrt{k}$. When picking smaller weights, the objective is larger than the initial objective during the first 20 iterations. Setting the weights to 
higher values than $w_i = 0.4\sqrt{k}$ leads to a slower convergence rate. However, if the time step is decreased to \SI{1e-3}{\second} (see Fig. \ref{fig:strain-weights-admm} b), 
weights higher than $w_i = 0.4\sqrt{k}$ achieve a better convergence rate and converge to configurations with a lower objective than weights lower than 
or equal to $w_i = 0.4\sqrt{k}$. In particular, ADMM converges to a solution whose objective is higher than the initial objective when using $w_i = 0.2\sqrt{k}$ and 
$w_i = 0.3\sqrt{k}$. Thus, $w_i = 0.3\sqrt{k}$ is an excellent weight for time step \SI{1e-2}{\second}, while it is unsuitable for time step \SI{1e-3}{\second}. Overall, it 
can be seen that more aggressive reductions of the ADMM weights without jeopardizing convergence are possible when a larger time step is used. Qualitatively equivalent results 
can be observed for other stiffness values. 

In Section \ref{ss:admm-properties}, we hypothesized that it might be preferrable to use smaller ADMM weights if the constraint energy $\Psi$ is significantly smaller at the true 
implicit positions $\vecm{q}^*$ than at the initial positions $\vecm{q}_0$, whereas larger weights might be more appropriate when $\Psi(\vecm{q}^*) \approx \Psi(\vecm{q}_0)$.
The time step dependence of ADMM weights can be explained by combining this insight with the fact that the extent to which a single application of implicit Euler integration 
reduces the constraint energy of a deformed body generally grows with increasing time step size. Thus, for smaller time steps it is 
$\Psi(\vecm{q}^*) \approx \Psi(\vecm{q}_0)$, favoring the use of larger ADMM weights. Note that this time step dependence 
makes finding suitable ADMM weights incredibly tedious: For each material model, weights need to be manually fine-tuned for each combination of time step size and 
material stiffness. To save time, we reuse the ADMM weights determined for the untwisting beam experiments (see Sec.\ \ref{ss:untwisting-beam-strain}) in the twisting 
beam experiments (see Sec.\ \ref{ss:twisting-beam-strain}). However, it is not clear whether ADMM weights can be reused across different simulation scenarios, even if the time step 
size and the material stiffness remain unchanged.

\begin{figure}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_admm_weights_1e-2.pdf}
        \subcaption{Time step \SI{1e-2}{\second}}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_admm_weights_1e-3.pdf}
        \subcaption{Time step \SI{1e-3}{\second}}
    \end{subfigure}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the iterations of a single time 
        step of size \SI{1e-2}{\second} (a) and \SI{1e-3}{\second} (b) for an untwisting beam with strain constraints with stiffness \num{1e8} using ADMM with different weights.}
    \label{fig:strain-weights-admm}
\end{figure}

\subsection{Untwisting Beam Simulations - Strain Material}\label{ss:untwisting-beam-strain}
In the untwisting beam experiments using the strain material model, challenges due to incompatible constraint sets are avoided and the tetrahedral strain constraints are 
easy to minimize due to the fact that corresponding restorative elastic forces are proportional to the distance between the deformation and its closest rigid-body 
transform (see Sec.\ \ref{ss:strain-material}). Thus, we use them as a starting point for highlighting differences between the different solvers.

\paragraph{Convergence Properties.}
We start by analyzing the convergence properties of different solvers with time step size \SI{1e2}{\second} and stiffness \num{1e8} by plotting the objectives over the 
iteration number in Figure \ref{fig:strain-beam-untwist-objectives}. Note that the results are representative for a large range of time step sizes and stiffness 
values. The graph shows that each of the solvers indeed mostly decreases the objective from iteration to iteration until it converges towards a final configuration 
after a sufficient number of iterations. ADMM, PD and QN converge to configurations with roughly the same objective whereas the objective obtained after 1000 
XPBD iterations is still slightly larger. QN and ADMM converge after roughly 40 and 60 iterations, whereas PD and XPBD converge after upwards of 260 and 1000 iterations, 
respectively. To quantify the progress that other solvers achieve during the number of iterations it takes each of the solvers to converge, we compute relative errors after 
40 (QN), 60 (ADMM), 260 (PD) and 1000 (XPBD) iterations. The relative error is given by 

\begin{equation}\label{eq:rel-error}
    \frac{f_{\text{obj}}(\vecm{q}_k) - f_{\text{obj}}(\vecm{q}^*)}{f_{\text{obj}}(\vecm{q}_0) - f_{\text{obj}}(\vecm{q}^*)},
\end{equation}

\noindent where $\vecm{q}_k$ are the positions after iteration $k$ and $\vecm{q}^*$ are the positions with minimal objective function value
achieved by any of the solvers. The relative errors are shown in Figure \ref{fig:rel-errors}. Note that the relative error of ADMM is only 
0.4 \% by the time QN has converged, while the errors achieved by PD and XPBD are still substantial. Additionally, even after a 1000 iterations, XPBD's relative error 
is still at 1.8 \%.

\begin{table}[h]
\centering
\begin{tabular}{ |r||c|c|c|c| } 
 \hline
 & QN & ADMM & PD & XPBD\\
 \hline
 \hline
    40 iterations (QN) & 0.0 & 0.4 & 22.7 & 67.8 \\ 
    60 iterations (ADMM) & 0.0 & 0.0 & 12.6 & 47.8 \\
    260 iterations (PD) & 0.0 & 0.0 & 0.0 & 4.0 \\
    1000 iterations (XPBD) & 0.0 & 0.0 & 0.0 & 1.8 \\ 
 \hline
\end{tabular}
\caption{Relative errors (see Eq.\ \ref{eq:rel-error}) in \% achieved by solvers after 40, 60, 260 and 1000 iterations for the untwisting beam experiment from 
Figure \ref{fig:strain-beam-untwist-objectives}.}
\label{fig:rel-errors}
\end{table}

The data suggests that ADMM, PD and QN converge towards a solution that is closer to the true implicit positions at the next time step than XPBD. This is expected, 
as XPBD only approximates a solution to the implicit equations of motion due to the simplifying assumptions made during its derivation (see Sec.\ \ref{ss:xpbd-properties}).
Due to the second assumption (see Eq.\ \ref{eq:xpbd-assumption-2}) in particular, there is no penalty for moving vertex positions away from their inertial positions during 
the XPBD constraint projections (see Sec.\ \ref{ss:xpbd-properties}), even though it increases the objective function. Additionally,
it is not clear whether the Gauss-Seidel solver at the core of XPBD is able to minimize the constraint energies sufficiently via local constraint projections only.
Since constraints are projected independently one-by-one, later constraint projections can undo some of the work achieved by previous projections. Bouaziz et al.\ 
\cite{bouaziz2014} describe this phenomenon as an oscillation between different constraints. On the other hand ADMM, PD and QN aim to solve the implicit equations 
of motion exactly. The difference in the rate of convergence between ADMM and PD goes in line 
with experimental data provided by Overby et al.\ \cite{overby2017}. There, the authors show that ADMM with a weight of $\sqrt{k}$, where $k$ is the stiffness of the 
strain constraints, is almost equivalent to PD and that the convergence rate can often be improved by reducing the weight. As discussed in 
Section \ref{ss:admm-properties}, this is due to the fact that lower weights allow faster progress towards positions that reduce the constraint energy, which is particularly 
useful for simulations with larger timesteps. Similarly, the faster convergence rate of QN compared to PD is expected in light of the observation that PD is a quasi-Newton method 
with constant Hessian approximation (see \cite{liu2017}, Sec.\ \ref{ss:pd-quasi-newton}). The QN solver augments the PD solver with a line-search algorithm and LBFGS-updates to 
the constant Hessian approximation from PD that take into account curvature information from previous iterations to better approximate the true Hessian matrix. Both
of these measures help improve the convergence rate of QN in comparison to PD. Again, this is in line with results presented by Liu et al.\ \cite{liu2017}. The comparably
slow convergence rate of XPBD could again be explained by the simplifying assumptions made during the XPBD derivation and the aforementioned oscillations of Gauss-Seidel
solvers. 

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/strain_beam_untwist_objectives.pdf}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the iterations of a single time 
        step of size \SI{1e-2}{\second} for an untwisting beam using strain constraints with stiffness \num{1e8}.}
    \label{fig:strain-beam-untwist-objectives}
\end{figure}


To better understand the main factor for XPBD's unfavorable convergence properties, it is helpful to plot the inertial term and the constraint term of the objective 
function separately. The resulting plots are shown in Figure \ref{fig:strain-beam-untwist-objectives-split}. 
We focus on the first 500 iterations to gain clearer insights into the behavior of the solver during earlier iterations, since these are more relevant for 
real-time applications. First, it is evident that the constraint energy dominates the objective function value for each solver during most of the iterations before 
convergence is achieved. While each solver mostly decreases the constraint energy with an increasing number of iterations, the inertial term is mostly increased. 
The only exception is the ADMM solver between iterations 30 to 60, where the inertial term is decreased from its peak and the constraint energy is increased from its 
low point. ADMM, PD and QN converge to configurations with roughly the same inertial and constraint terms. However, at its final state, the constraint 
energy of the XPBD solver is higher than its counterparts from the PD-style solvers, whereas the opposite is observed for the inertial term. 

\begin{figure}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_untwist_constraintObjectives.pdf}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_untwist_inertialObjectives.pdf}
    \end{subfigure}
    \caption{Values of the constraint (top) and inertial (bottom) terms of the objective function of the variational form of implicit Euler integration 
        (see Eq.\ \ref{eq:variational-implicit}) over the iterations of single time step of size \SI{1e-2}{\second} for an untwisting beam with strain 
    constraints with stiffness \num{1e8}.}
    \label{fig:strain-beam-untwist-objectives-split}
\end{figure}

As discussed in Section \ref{ss:variational-implicit-euler}, the weighting between the inertial term and the constraint energy depends on the time step, the particle masses 
and the material stiffnesses. The results suggest that with a time step of \SI{1e-2}{\second} and a constraint stiffness of \num{1e8}, the constraint energy can be 
decreased significantly until the cost of moving particles away from their inertial positions becomes too high. Since the inertial term at the converged XPBD state 
is in fact lower than the inertial term achieved by PD-style solvers, it is evident that the reason for the 
higher objective function value of XPBD is that the constraint energy is not reduced sufficiently. It is natural to assume that this 
is in part a consequence of the oscillations resulting from the iterative Gauss-Seidel solver used in XPBD. However, it is worth pointing out again that XPBD does not 
solve the implicit equations of motion exactly due to the simplifying XPBD assumptions. Even if Equation \ref{eq:xpbd-simplified-lse} were to be solved with a global solver,
it is not clear whether the constraint energy would be decreased further than it is using the Gauss-Seidel solver. 

The fact that the constraint energy is higher for the final state of the XPBD solver is also perceptible when comparing its geometry with the final geometries computed 
by PD-style solvers. The geometries achieved after 1000 XPBD and QN iterations are shown in Figure \ref{fig:strain-beam-untwist-geometries} a. 
The corresponding geometries for PD and ADMM are ommitted since they are visually indistinguishable from the geometry computed by the QN solver. The image shows 
that the QN solver untwists the beam further towards its undeformed rest configuration than XPBD. Since the constraint energies obtain a minimum at the reference 
configuration, this is in line with the observation that QN is more successful than XPBD at reducing the constraint term of the objective function. We point out that 
the surface of the XPBD geometry is smooth. In the discussion of Figure \ref{fig:strain-beam-untwist-geometries} b and Figure \ref{fig:twisting-beam-xpbd-failure-geometry},
we suggest that oscillations of the Gauss-Seidel-type solver manifest themselves in noticable geometric artifacts on the beam surface. Thus, it is likely that 
the comparably large constraint term after 1000 XPBD iterations is caused by the simplifying assumptions during the XPBD derivation instead of the local nature of 
the XPBD solver.

Considering that the inertial positions do not appear in the update equations of XPBD (see Sec.\ \ref{ss:xpbd-properties}), it is surprising that the inertial term achieved 
by the converged state of the XPBD solver is smaller than the final inertial term of the other solvers. On the other hand, the only factor driving particles away from 
their inertial positions in the untwisting beam experiment are the elastic energies due to the deformation of the beam. One possible explanation for the low inertial 
term for XPBD might be that the particles do not move far away from their inertial positions simply because the XPBD constraint solver is not as successful at 
minimizing the constraint energies. Lastly, the penalty for moving particles from their inertial positions is quite low for PD-style solvers if a time step as large 
as \SI{1e-2}{\second} is used. However, the inertial term achieved by XPBD remains smaller than its counterparts, even if the timestep is decreased.

\paragraph{Conversion of Constraint Energy Into Kinetic Energy.}
In the light of the observation that the inertial term of the objective function of the variational form of implicit Euler integration can be interpreted as the kinetic 
energy of the beam (see Sec.\ \ref{ss:analysis-solvers}), the results in Figure \ref{fig:strain-beam-untwist-objectives-split} suggest that some of the 
constraint energy stored in the deformed beam is converted into kinetic energy during most solver iterations. Additionally, solvers with a 
faster convergence rate appear to be able to convert a larger share of the elastic energy into kinetic energy during a single iteration. Then, we can conclude that XPBD 
does not manage to convert as much of the constraint energy stored in the twisted beam into kinetic energy as the other solvers by the time convergence is acheived.

\paragraph{Effects of Early Termination.}
In the context of real-time applications, the number of solver iterations is often capped to ensure that the computations fit into the time budget allocated 
for the simulation of the next frame. A closer look at Figure \ref{fig:strain-beam-untwist-objectives-split} shows that all of the solvers are still in the process of 
converting the constraint energy stored in the twisted beam into kinetic energy after the first 10 iterations. Accordingly, none of the solvers have reduced the 
objective function to the minimum achieved by the PD-style solvers yet (see Fig. \ref{fig:strain-beam-untwist-objectives}). After 10 iterations, the QN solver has reduced 
the objective function the most, followed by ADMM, PD and XPBD. 

To gain a better understanding of the effects caused by terminating solvers before the objective function is minimized, we take a 
closer look at the geometries that the XPBD, PD and ADMM solvers arrive at after 10 solver iterations in Figure \ref{fig:strain-beam-untwist-geometries} b-d. The 
corresponding QN geometry is given as a reference in each panel. Figure \ref{fig:strain-beam-untwist-geometries} b-d shows that the solvers untwist the beam to 
different extents after the first 10 solver iterations. The QN geometry gets closest to the beam's reference configuration, again followed by ADMM, PD and, lastly, 
XPBD. Note that the degree to which solvers untwist the beam goes hand-in-hand with the extent to which they minimize the objective function and particularly its 
constraint energy. In summary, terminating the solvers after a small number of iterations can cause the motion of simulated bodies to appear slowed down. 
This effect is more noticable for solvers that have inferior convergence properties, such as PD and XPBD. Note that Bouaziz et al.\ \cite{bouaziz2014} report 
the same observation in the discussion of the PD solver and state that this is due to the fact that forces may not be able to fully propagate through the mesh 
if the optimization is not run long enough. 

\begin{figure}
    \centering
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/strain_beam_untwist_QN_vs_XPBD.png}
        \subcaption{QN and XPBD after 1000 iterations}
    \end{subfigure}
    \hspace{0.001\textwidth}
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth, trim={0 4.5cm 0 2.15cm}, clip]{figures/strain_beam_untwist_QN_vs_XPBD_10_iterations.png}
        \subcaption{QN and XPBD after 10 iterations}
    \end{subfigure}
    \par\medskip
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth, trim={0 4.5cm 0 2.15cm}, clip]{figures/strain_beam_untwist_QN_vs_PD_10_iterations.png}
        \subcaption{QN and PD after 10 iterations}
    \end{subfigure}
    \hspace{0.001\textwidth}
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth, trim={0 4.5cm 0 2.15cm}, clip]{figures/strain_beam_untwist_QN_vs_ADMM_10_iterations.png}
        \subcaption{QN and ADMM after 10 iterations}
    \end{subfigure}
    \caption{Geometries of an untwisting beam with strain constraints (stiffness \num{1e8}) after 10 and 1000 iterations over a single time step of size 
        \SI{1e-2}{\second} using XPBD (pink), PD (orange), ADMM (green) and QN (cyan).}
    \label{fig:strain-beam-untwist-geometries}
\end{figure}

Closer inspection of Figure \ref{fig:strain-beam-untwist-geometries} b shows that the XPBD geometry is noticably rugged compared to the geometries of the PD-type 
solvers, which 
appear mostly smooth at the surface. Thus, in contrast to the PD-style solvers, terminating the simulation early does not only manifest itself in slowing down 
the motion of the simulated body but also in visible geometric artifacts. This matches the observation that the constraint objective achieved after 10 XPBD iterations 
is larger than the initial constraint objective in Figure \ref{fig:strain-beam-untwist-objectives-split}. While it is difficult to verify, it is natural to assume that this 
effect is caused by oscillations of the Gauss-Seidel solver at the core of XPBD, since it does not appear for solvers that have a global optimization step. Then, the 
fact that the XPBD geometry does appear smooth after 1000 iterations (see Fig. \ref{fig:strain-beam-untwist-geometries}) would suggest that oscillations are particularly 
severe during earlier iterations where the constraint energies and their gradients are large.

\paragraph{Computational Cost.}
To take into account the computational cost of the iterations for different solvers, the objective function values are plotted again over the accumulated
iteration durations in Figure \ref{fig:strain-beam-untwist-objectives-time}. However, the provided iteration durations should be treated as a rough indication of the 
computational costs of different solvers since no effort has been put into profiling or speeding up the computations by providing a multithreaded 
implementation. While QN iterations appear to be almost twice as computationally expensive as the iterations 
for the other solvers, the costs associated with a single iteration are on average very similar. Note that 1000 iterations of XPBD, ADMM and PD 
take roughly 4 seconds each. Due to the similar computational costs per iteration, the conclusions that can be drawn from Figure \ref{fig:strain-beam-untwist-objectives-time}
are similar to what was discussed for Figure \ref{fig:strain-beam-untwist-objectives}: ADMM and QN converge in a shorter amount of time than XPBD and PD, but ADMM and PD
appear in a more favorable light compared to QN due to faster iterations.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/strain_beam_untwist_objectives_time.pdf}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the accumulated durations of 
        the iterations over a single time step of size \SI{1e-2}{\second} for an untwisting beam using strain constraints with stiffness \num{1e8}.}
    \label{fig:strain-beam-untwist-objectives-time}
\end{figure}

\paragraph{Convergence Properties With Large Time Steps and Stiffnesses.}
Figure \ref{fig:strain-beam-untwist-objectives} shows data for time step \SI{1e-2}{\second} and constraint stiffness \num{1e8}. While the results are qualitatively 
the same for a wide range of time steps and stiffness values, noticable differences arise when a combination of large time steps and large stiffness values is used.
Consider the corresponding plot with time step \SI{1e-1}{\second} and constraint stiffness \num{1e9} in Figure \ref{fig:strain-beam-untwist-objectives-large-ts}. Again,
QN makes the fastest progress towards decreasing the objective, followed by ADMM, PD and XPBD. However, from 680 iterations onwards the objective achieved by the XPBD 
solver is lower than the objective achieved by the PD solver. In this setting, QN, ADMM and XPBD converge to configurations that achieve roughly the same objective 
function value, while it is PD whose final objective is larger than the other solvers'. After 1000 iterations, PD has a relative error (see Eq.\ \ref{eq:rel-error}) 
of approx.\ 0.02 \%. While this appears negligible, it is worth noting that the minimal objective function value that PD arrives at is still approx.\ 2.3 
times larger than the minimal value achieved by the other solvers.


\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/strain_beam_untwist_objectives_large_ts.pdf}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the iterations of a single time 
        step of size \SI{1e-1}{\second} for an untwisting beam using strain constraints with stiffness \num{1e9}.}
    \label{fig:strain-beam-untwist-objectives-large-ts}
\end{figure}

As discussed in Section \ref{ss:pd-properties}, each PD iteration is guaranteed to weakly reduce the objective function. However, this only ensures that the objective function 
at the configuration PD converges to is never higher than the initial objective. There is no guarantee that 
PD converges to the true implicit positions. Thus, the observation that PD can fail at reducing the objective function all the way is not surprising. To gain a better 
understanding of why the convergence properties of the PD solver worsen when combining larger time steps and stiffness values, we again create separate plots for the 
inertial and constraint terms. This is analogous to the experiments conducted in Figure \ref{fig:strain-beam-untwist-objectives-split} to investigate 
the unfavorable convergence properties of XPBD observed in Figure \ref{fig:strain-beam-untwist-objectives}. 

\begin{figure}[t]
    \centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_untwist_constraintObjectives_large_ts.pdf}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_untwist_inertialObjectives_large_ts.pdf}
    \end{subfigure}
    \caption{Values of the constraint (top) and inertial (bottom) terms of the objective function of the variational form of implicit Euler integration 
        (see Eq.\ \ref{eq:variational-implicit}) over the iterations of a single time step of size \SI{1e-1}{\second} for an untwisting beam using strain constraints with 
    stiffness \num{1e9}.}
    \label{fig:strain-beam-untwist-objectives-split-large-ts}
\end{figure}

Again, Figure \ref{fig:strain-beam-untwist-objectives-split-large-ts} shows that the solvers mostly decrease the constraint objective and increase the inertial term during each 
iteration. QN, ADMM and PD are more successful at reducing the constraint energy than XPBD, even 
though PD converges to a constraint energy that is slightly larger than the one achieved by QN and ADMM this time. Each of the PD-style solvers manages to bring the 
constraint energy down to close to zero. This is significantly lower than the minimum achieved for a time step of \SI{1e-2}{\second} and stiffness \num{1e8} (see 
Fig. \ref{fig:strain-beam-untwist-objectives-split}). However, it is evident that XPBD has not fully converged yet as it still continues to decrease the constraint energy 
values. All in all, the results for the constraint energy are qualitatively the same as the ones observied for 
time step \SI{1e-2}{\second} and stiffness \num{1e8}. On the other hand, the plots for the inertial term differ quite significantly. With larger time step and stiffness,
QN, ADMM and XPBD converge to roughly the same inertial term, whereas the PD solver converges to a value that is more than twice as large. Already after 20 iterations, 
the inertial term achieved by PD is larger than the value that the other solvers converge to. Still, PD continues to increase the inertial term during the first 400 
iterations. Finally, each of the solvers converge to an inertial term that is significantly lower than the corresponding inertial term obtained with time step 
\SI{1e-2}{\second} and stiffness \num{1e8}.

Since the weight of the inertial term decreases with increasing time step size and the weight of the constraint term increases with increasing stiffness values, moving 
particles away from their inertial positions to reduce the constraint energy is encouraged in Figure \ref{fig:strain-beam-untwist-objectives-split-large-ts} compared to
Figure \ref{fig:strain-beam-untwist-objectives-split}. This is reflected in the fact that the solvers reduce the constraint energy to a lower value, even though a larger 
stiffness value is used. The results suggest that the PD solver is too aggressive with moving particles away from their inertial positions if the associated penalty 
is largely outweighed by the incentives for minimizing the constraint energies. This issue 
appears to be particularly serious during the first solver iterations, where the derivatives of the quadratic inertial penalty are small. 
Without further experiments, it is difficult to understand why this effect occurs when using the PD solver while the other solvers are unaffected.

\paragraph{Conservation of Global Linear and Angular Momentum With Large Time Steps and Stiffnesses.}
To gain further insights into the cause of the large inertial term at the converged configuration from PD, we repeat parts of the 
experiments in Figure \ref{fig:strain-beam-untwist-geometries} and take a closer look at the geometries that the solvers arrive at after 1000 
iterations. Figure \ref{fig:strain-beam-untwist-geometries-large-ts} a shows a comparison between the XPBD and QN geometries. Similar to the 
results in Figure \ref{fig:strain-beam-untwist-geometries} a, the XPBD solver does not untwist the beam as far as the QN solver. This is in 
line with the observation that the constraint term for XPBD is larger than the constraint term of PD-style solvers after 1000 iterations (see 
Figure \ref{fig:strain-beam-untwist-objectives-split-large-ts}). More interestingly, the comparison of the QN, ADMM and PD geometries in 
Figure \ref{fig:strain-beam-untwist-geometries-large-ts} b shows that all PD-style solvers succeed at untwisting the beam to its reference 
configuration. However, while the orientations of the beams appear the same between solvers, the positions of their centers of gravity 
are shifted with respect to each other. This shift is very apparent for PD, whereas the QN and ADMM geometries are almost overlapping.

The results in Figure \ref{fig:strain-beam-untwist-geometries-large-ts} suggest that the large inertial term observed for the PD solver in 
Figure \ref{fig:strain-beam-untwist-objectives-split-large-ts} is caused by undesired rigid-body motion introduced during the solver iterations. 
The shifted center of gravity of the beam is unexpected in light of the fact that the beam has zero global linear and angular momentum in 
its initial twisted configuration and no external forces are applied. At the true implicit positions that the PD solver attempts to converge to, global 
linear and angular momentum are preserved \cite{bouaziz2014}. However, the shifted center of gravity indicates that the global linear 
momentum of the beam is non-zero after 1000 PD iterations.

\begin{figure}
    \centering
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/strain_beam_untwist_QN_vs_XPBD_large_ts.png}
        \subcaption{QN and XPBD after 1000 iterations}
    \end{subfigure}
    \hspace{0.001\textwidth}
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth, trim={0 4.5cm 0 2.15cm}, clip]{figures/strain_beam_untwist_QN_vs_ADMM_vs_PD_large_ts.png}
        \subcaption{QN, PD and ADMM after 1000 iterations}
    \end{subfigure}
    \caption{Geometries of an untwisting beam with strain constraints (stiffness \num{1e9}) after 1000 iterations over a single time step of size 
    \SI{1e-1}{\second} using XPBD (pink), PD (orange), ADMM (green) and QN (cyan).}
    \label{fig:strain-beam-untwist-geometries-large-ts}
\end{figure}

To dig deeper, we plot the norms of the global linear and angular momentum of the beam over the solver iterations in 
Figure \ref{fig:strain-beam-untwist-momenta-large-ts}. First, the plots confirm that the initial linear and angular momenta are zero at the initial 
configuration. However, the QN solver is the only solver that succeeds at preserving both types of momentum. XPBD preserves linear momentum, 
but increases the angular momentum. PD and ADMM fail to preserve either type of momentum. The bulk of the 
increase in linear momentum observed for PD and ADMM happens during the first 20 iterations. The final linear momentum observed for the PD solver is 
significantly larger than the one observed for the other solvers. During the rest of the iterations, the linear momentum remains almost constant for all solvers. 
It is worth pointing out that the plot for the linear momentum is representative for the corresponding plots for almost all combinations of time step size and 
constraint stiffness. On the other hand, the plots for the angular momentum are more varied. The main commonality is that the angular momentum norms are much 
smaller than the linear momentum norms observed for PD and ADMM solvers. For these reasons, we focus our attention on linear momentum. 

First, the data provides insight into why the spike of the inertial term of the objective function after 20 PD iterations in 
Figure \ref{fig:strain-beam-untwist-objectives-split-large-ts} does not go along with a large decrease in the constraint term: The spike is caused by 
rigid-body motion, to which elastic energy potentials are invariant. Secondly, we discussed in Section \ref{ss:pd-quasi-newton} that PD can be considered 
a quasi-Newton method with constant Hessian approximation. The QN solver enhances the PD solver by integrating local curvature information into the Hessian 
approximation via an LBFGS update and adding a line search algorithm. Since the QN solver does not introduce any global linear momentum, it follows that
the reason for the PD solver's inability to preserve the linear momentum is the lack of one or both of these features of the QN solver. To find out which of 
these factors is more important, it might be interesting to remove the line search or the LBFGS-update from the QN solver and take another look at the momenta. 
Lastly, recall that ADMM and PD are almost identical for strain constraints if the ADMM weights $w_i$ are set to $\sqrt{k}$. For the experiments in 
Figure \ref{fig:strain-beam-untwist-momenta-large-ts}, $w_i \approx \frac{1}{2}\sqrt{k}$ is used. Thus, the smaller linear momentum observed for ADMM invites 
the hypothesis that lower ADMM weights can be beneficial for the preservation of linear momentum. However, more effort is required to verify this claim and 
to establish the causal justification. 

\begin{figure}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_untwist_momenta_large_ts.pdf}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_untwist_angular_momenta_large_ts.pdf}
    \end{subfigure}
    \caption{Norms of the global linear (top) and global angular (bottom) momenta in $\text{kg}\cdot\text{m}^2\cdot\text{s}^{-1}$ over the iterations 
    of a single time step of size \SI{1e-1}{\second} for an untwisting beam with strain constraints with stiffness \num{1e9}. The required velocities 
    $\vecm{v}_k$ at iteration $k$ are computed via Verlet integration (see Sec.\ \ref{ss:analysis-solvers}).
}
    \label{fig:strain-beam-untwist-momenta-large-ts}
\end{figure}

\subsection{Twisting Beam Simulations - Strain Material}\label{ss:twisting-beam-strain}
In the twisting beam experiment, the twisting motion of the beam is achieved by position constraints whose reference positions are rotated in-plane at the 
ends of the beam. These position constraints and the tetrahedral constraints for the strain material model are incompatible in the sense that there are no 
positions $\vecm{q}$ for which all constraint energies are minimized at the same time. Thus, the twisting beam experiments put the the solvers' abilities 
to make compromises between competing constraints to the test. The ADMM weights for the twisting beam experiments are reused from the parameter screens 
for the untwisting beam experiments.

\paragraph{Overview Over Convergence Properties.}
To gain insights into the convergence properties of the solvers in the twisting beam examples, we again start by plotting the objective function values over 
the solver iterations. The resulting graphs for a time step size of \SI{1e-1}{\second} and a stiffness value of \num{1e9} are shown in 
Figure \ref{fig:strain-beam-twist-typical-objectives}. While the results obtained for the QN and PD solvers are qualitatively the same for all time step 
sizes and stiffness values, the behavior of XPBD and ADMM can vary quite dramatically across different parameter settings. The plots in 
Figure \ref{fig:strain-beam-twist-typical-objectives} show that both QN and PD converge to a configuration with a lower objective function value than the initial 
objective within the first 20 iterations. Note that it takes a larger number of iterations to achieve convergence in the corresponding untwisting beam experiments 
(see Fig. \ref{fig:strain-beam-untwist-objectives-large-ts}). This is particularly noticable for the PD solver. Figure \ref{fig:strain-beam-twist-typical-objectives} 
shows that ADMM exhibits the same behavior as QN and PD for time step \SI{1e-1}{\second} and stiffness \num{1e9}. While this can be observed for a variety of 
different parameter settings, there are also many cases where ADMM either does not converge at all or converges to a solution whose objective function value is 
significantly lower than the objective achieved by the other PD-style solvers. Lastly, XPBD converges to a configuration with an objective function value that is 
significantly larger than the initial objective in Figure \ref{fig:strain-beam-twist-typical-objectives}. Again, this observation is repeated for a variety of 
different parameters. However, there are also combinations of time step sizes and stiffness values for which XPBD is successful at reducing the objective to 
below its initial value. Even in such settings, the minimal objective achieved by XPBD is almost always higher than the one achieved by QN and PD.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/strain_beam_twist_typical_objectives.pdf}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the iterations of 
        a single time step of size \SI{1e-1}{\second} for a twisting beam using strain constraints with stiffness \num{1e9}.}
    \label{fig:strain-beam-twist-typical-objectives}
\end{figure}

During the discussion of the untwisting beam experiments using large time steps and stiffness values (see Fig.\ \ref{fig:strain-beam-untwist-objectives-large-ts}),
we pointed out that the PD solver can fail to decrease the objective function value to the value achieved by the QN solver. This is caused by the introduction of 
undesired rigid-body motion during early PD iterations when the penalty for moving particles away from their inertial positions is largely outweighed by the incentives 
for minimizing constraint energies. Since the position constraints at the ends of the beam in the twisting beam experiments further disincentivize moving the beam's 
center of gravity, it is not surprising that this failure mode of the PD solver is not encountered. The fact that convergence is achieved after fewer iterations 
during the twisting beam experiments than during the unwisting beam experiments is expected considering that the initial particle positions are much closer to the true 
implicit positions that the solvers aim to converge. To see this, observe that the QN solver untwists the beam from its initial deformed configuration all the way to its 
undeformed reference configuration over a single time step in Figure \ref{fig:strain-beam-untwist-geometries-large-ts} b. In contrast, the beam is only twisted by a 
couple of degrees during the twisting beam experiments. As mentioned earlier, the results for XPBD and ADMM are more complex and merit a more detailed discussion below.

\paragraph{Convergence Properties of XPBD.}
During the untwisting beam experiments using the strain material model discussed earlier, each solver reduces 
the objective function value compared to the initial objective during the first 1000 iterations, irrespective of the chosen time step size 
and stiffness value. As indicated by the data in  Figure \ref{fig:strain-beam-twist-typical-objectives}, this is not always the case for the twisting beam experiments. 
For various combinations of time step sizes and stiffness values, the positions computed by XPBD after 1000 iterations yield a higher objective function 
value than the initial objective. We say that XPBD fails for such parameters. For each time step, the stiffness values for which XPBD fails are listed in 
Figure \ref{fig:strain-beam-twist-xpbd-failures}. Note that the results are identical when restricting to the constraint term of the objective function. 
In other words, the settings in which XPBD fails to decrease the objective are exactly those for which the solver iterations cause the constraint 
term to increase. Figure \ref{fig:strain-beam-twist-xpbd-failures} shows that XPBD fails in settings where large stiffness 
values are used. In particular, XPBD always fails once the stiffness is larger than some time step dependent threshold. This threshold 
increases with increasing time step size.

\begin{table}[h]
\centering
    \begin{tabular}{ |r||c|c|c|c| } 
     \hline
     time step in s & \num{1e-1} & \num{1e-2} & \num{1e-3} & \num{1e-4}\\ 
     \hline
     stiffness & $\geq$ \num{1e7} & $\geq$ \num{1e8} & $\geq$ \num{1e10} & $\geq$ \num{1e12}\\
     \hline
    \end{tabular}
    \caption{Combinations of time step sizes and stiffness values for which XPBD fails. For a stiffness value $k$, we write $\geq k$ to indicate that 
        XPBD fails for all tested stiffnesses $k^\prime$ such that $k^\prime > k$. Identical results are obtained when restricting to the constraint 
        term of the objective function.
    }
\label{fig:strain-beam-twist-xpbd-failures}
\end{table}

As discussed before, the large constraint terms that are observed when XPBD fails are most likely caused by a combination of the simplifying 
assumptions during the XPBD derivation and oscillations of the Gauss-Seidel-type solver at its core. We assess that the latter contributes 
more to XPBD failures in the twisting beam experiments for a variety of reasons. First, it is easy to see how mixing incompatible 
position and strain constraints could lead to more severe oscillations. Since there are no particle positions $\vecm{q}$ for which both the position constraints and the 
strain constraints are satisfied at the same time, individual constraint projections will continue to move particles back and forth over and over again. 
On the other hand, all strain constraints are satisfied in the reference configuration of the beam in the untwisting beam scenario. It is natural to 
assume that the former scenario is more challenging for Gauss-Seidel-type solvers. Secondly, the severity of the oscillations is expected to increase with both 
time step size and stiffness values since both factors enable larger position updates during individual constraint projections. This is in line with the 
data presented in Figure \ref{fig:strain-beam-twist-xpbd-failures}.

To get a feeling for the visual effects resulting from the large (constraint) objective achieved when XPBD fails, we take a closer look at the 
geometry of a twisting strain beam after 1000 XPBD iterations over a time step of \SI{1e2}{\second} with constraint stiffness \num{1e12} in 
Figure \ref{fig:twisting-beam-xpbd-failure-geometry}. The left panel shows that the surface of the XPBD geometry is noticably rugged. Recall that 
the same observation is made after 10 XPBD iterations in the untwisting beam setting (see Fig. \ref{fig:strain-beam-untwist-geometries}). The 
effect is particularly noticable at the ends of the beam, where individual tetrahedra protrude from the volume of the body. To highlight this, 
we zoom in on the geometry at one end of the beam in the right panel of Figure \ref{fig:twisting-beam-xpbd-failure-geometry}. The geometry that the QN solver 
converges to is given as a reference. While the QN geometry is flat at the end of the beam, the XPBD geometry is irregular. Additionally, it 
appears that the end of the beam is twisted further in the counterclockwise direction when using the XPBD solver.

\begin{figure}[h]
    \resizebox{\textwidth}{!}{
    \includegraphics[height=10cm, trim={0 5.0cm 0 2.5cm}, clip]{figures/twisted_beam_rugged_xpbd.png}
    \quad
    \includegraphics[height=10cm, trim={16.5cm 2.0cm 15.5cm 2.0cm}, clip]{figures/twisted_beam_sideview.png}
    }
    \caption{Geometries of a twisting beam with strain constraints (stiffness \num{1e12}) after 1000 XPBD iterations over a time step of size \SI{1e-2}{\second} 
    from different angles. In the right panel, the converged QN geometry is shown as a reference.}
    \label{fig:twisting-beam-xpbd-failure-geometry}
\end{figure}

Again, the observed rugged surface fits with our hypothesis that the failures of the XPBD solver in the twisting beam scenario are due to 
oscillations of the Gauss-Seidel-type solver at the core of XPBD. The protrusions at the end of the beam are most likely caused by oscillations 
between the incompatible position constraints and local strain constraints. Together, our results from Figure \ref{fig:strain-beam-untwist-geometries} and 
Figure \ref{fig:twisting-beam-xpbd-failure-geometry} suggest that oscillations can cause noticable geometric artifacts if an insufficiently low number of 
XPBD iterations is used or if subsets of constraints are fundamentally incompatible. The observation that the beam is twisted further from its 
initial configuration for XPBD than for QN is expected considering that the XPBD solver has no explicit penalty for moving particles away from their inertial 
positions (see Sec.\ \ref{ss:xpbd-properties}). Thus, XPBD has more freedom to update particle positions in such a way that the position constraints 
that cause the beam to twist are satisfied. On the other hand, moving particles away from their inertial positions is associated with a penalty that is 
quadratic in the inverse of the time step size when using the QN solver. As a result, the final QN positions at the end of the beam are further 
away from the reference positions of the position constraints. While the behavior of the QN solver is physically accurate, it 
also highlights one of its weaknesses: Due to the penalty incurred for moving particles away from their inertial positions and the fact that 
position constraints can only be modelled via stiff springs, exerting exact control over a set of particle positions is challenging. Note that even the 
large stiffness value of \num{1e12} used for the position constraints in Figure \ref{fig:twisting-beam-xpbd-failure-geometry} is insufficient for moving particles 
to their reference positions when using the QN solver.

\begin{table}[h]
\centering
    \begin{tabular}{ |r||c|c|c|c| } 
     \hline
     time step in s & \num{1e-1} & \num{1e-2} & \num{1e-3} & \num{1e-4}\\ 
     \hline
     stiffness & -- & $\geq$ \num{1e5} & $\geq$ \num{1e5} & $\geq$ \num{1e7}\\
     \hline
    \end{tabular}
\caption{Combinations of time step sizes and stiffness values for which the inertial term of XPBD is larger than the inertial term of the QN solver after 
1000 iterations.}
\label{fig:strain-beam-twist-xpbd-large-inertial-terms}
\end{table}

The fact that the XPBD solver is more liberal with moving particles at the ends of the beam towards the reference positions of the position constraints 
should be reflected in a larger inertial term compared to the QN solver. In Figure \ref{fig:strain-beam-twist-xpbd-large-inertial-terms}, we list combinations 
of time step sizes and stiffness values for which the inertial term after 1000 XPBD iterations is larger than the inertial term achieved at the converged 
QN configuration. The results show that XPBD's inertial term is always smaller when a time step of \SI{1e-1}{\second} is used, but almost always larger for 
time step sizes larger than or equal to \SI{1e-2}{\second}. The only exception occurs for small stiffness values when a time step of \SI{1e-4}{\second} is 
used.

The results are in line with the observations from the previous experiments. In particular, Figure \ref{fig:strain-beam-twist-xpbd-large-inertial-terms} shows 
that the inertial term achieved by XPBD is larger than the inertial term achieved by QN for the parameters used in 
Figure \ref{fig:twisting-beam-xpbd-failure-geometry} (time step \SI{1e-2}{\second}, stiffness \num{1e12}). The observation that the inertial term achieved by 
the QN solver is larger for the large time step \SI{1e-1}{\second} matches that the inertial penalty taken into account by the QN solver 
is quadratic in the inverse of the time step size. As this penalty is not reflected in the XPBD update equations, it is expected 
that XPBD's inertial term becomes larger than QN's inertial term when the time step is reduced. 

In our discussion of Figure \ref{fig:strain-beam-untwist-objectives-split}, we mentioned that the inertial term achieved by 
XPBD is almost always lower than the inertial term achieved by PD-style solvers in the untwisting beam experiment. We suggested that this is due to the 
fact that the tetrahedral strain constraints simply do not provide enough incentive to move particles away from their inertial positions and that XPBD is 
less successful at minimizing the constraint energies of the tetrahedral elements than PD-style solvers. On the other hand, the position constraints at 
the end of the twisting beam are associated with quadratic spring energies that are simple to optimize and do encourage moving particles 
away from their inertial positions. In this setting, the lack of an explicit penalty term in the XPBD update equations becomes evident.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/strain_beam_twist_objectives.pdf}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the iterations of 
        a single time step of size \SI{1e-2}{\second} for a twisting beam using strain constraints with stiffness \num{1e10}.}
    \label{fig:strain-beam-twist-objectives}
\end{figure}

\paragraph{Convergence Properties of ADMM.}
For some parameters, we observe that ADMM converges to a configuration for which the objective function value is significantly lower than the objectives 
achieved by all other solvers during the twisting beam experiments. As an example, we plot the objective function values over the iterations for a time step of 
\SI{1e-2}{\second} and stiffness \num{1e10} in Figure \ref{fig:strain-beam-twist-objectives}. After increasing the objective function value during the first 40 
iterations, the ADMM solver arrives at a lower objective function value than the initial objective after 60 iterations. Finally, ADMM 
converges to a configuration where the objective function value is almost an order of magnitude lower than the minimal objective achieved by PD and QN after 
80 iterations.

\begin{figure}[t]
    \centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_twist_constraintObjective.pdf}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\linewidth]{figures/strain_beam_twist_inertialObjective.pdf}
    \end{subfigure}
    \caption{Values of the constraint (top) and inertial (bottom) terms of the objective function of the variational form of implicit Euler integration 
        (see Eq.\ \ref{eq:variational-implicit}) over the iterations of a single time step of size \SI{1e-1}{\second} for an untwisting beam with strain 
    constraints with stiffness \num{1e9}.}
    \label{fig:strain-beam-twist-objectives-split}
\end{figure}

Again, we create separate plots for the constraint and inertial terms of the objective function in Figure \ref{fig:strain-beam-twist-objectives-split}. The graph for the 
constraint term looks almost identical to the graph for the entire objective function in Figure \ref{fig:strain-beam-twist-objectives}. During the first 40 iterations, the 
constraint term achieved by ADMM is larger than the constraint term that QN and PD converge to. After 80 ADMM iterations, the constraint term converges to a value that is 
significantly lower than the one achieved by the other PD-style solvers. The most dramatic decrease in the constraint term occurs between 40 and 60 ADMM iterations. At the 
same time, ADMM's inertial term increases dramatically. The final inertial term achieved by ADMM is significantly higher than the inertial terms achieved by all other solvers, 
including XPBD.

The results suggest that ADMM is able to find particle positions that yield much lower constraint energies than the other solvers. The fact that the decrease in the 
constraint term between 40 and 60 iterations goes along with a sharp increase in the inertial term indicates that these particle positions differ significantly from the 
initial twisted configuration. This is surprising, since the reference positions of the position constraints at the ends of the beam that initiate the twisting motion 
are only rotated by a couple of degrees. Thus, we would expect the optimal configuration to have a small inertial term, as is observed for the configurations that 
QN and PD converge to. One possible explanation is that QN and PD converge to a local minimum of the objective function, whereas ADMM converges to a global solution. This 
hypothesis is supported by the observation that ADMM increases the objective during the first 20 iterations (see Fig. \ref{fig:strain-beam-twist-objectives}). Informally, this 
suggests that the ADMM solver spends the early solver iterations escaping the valley containing the local minimum that QN and PD converge to so that the global minimum 
can be achieved during later iterations.

\begin{figure}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/twisted_beam_bad_state_admm.png}
    \subcaption{20 iterations ADMM}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/twisted_beam_artificial_state_admm.png}
    \subcaption{1000 iterations ADMM}
    \end{subfigure}
    \centering
    \par\medskip
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth, trim={0 5.0cm 0 2.5cm}, clip]{figures/twisted_beam_qn.png}
    \subcaption{QN after convergence}
    \end{subfigure}
    \caption{Geometries of a twisting beam with strain constraints (stiffness \num{1e10}) after 20 (a) and 1000 (b) ADMM iterations over a time step of size 
        \SI{1e-2}{\second}. The converged QN geometry (c) is given as a reference.}
    \label{fig:strain-beam-twist-admm-geometries}
\end{figure}

To gain more insights, we take a closer look at the ADMM geometries after 20 and 1000 iterations in Figure \ref{fig:strain-beam-twist-admm-geometries}. After 20 ADMM iterations, 
the beam appears overtwisted at two locations at roughly one third and two thirds of the beam width. In the vicinity of these overtwisted locations, the surface of the 
beam is highly irregular. In contrast, the surface of the beam appears smooth at the converged ADMM geometry. At the configuration ADMM converges to, the beam is 
significantly closer to its reference configuration than at the geometry computed by the QN solver. Additionally, the converged ADMM and QN geometries are twisted in 
opposite directions.

The results in Figure \ref{fig:strain-beam-twist-admm-geometries} support the hypothesis that ADMM converges to a global minimum of the objective function, whereas QN and PD 
converge to a local minimum. By overtwisting the beam at two locations, the ADMM solver is eventually able to arrive at a configuration where most of the twist from the 
initial deformed configuration is removed without violating the position constraints at the end of the beam. Recall that the value of the objective function can be 
interpreted as the energy of the beam at a configuration (see Sec.\ \ref{ss:analysis-solvers}). Then, it is obvious that the overtwisting motion required to achieve this 
global minimum is not phyiscally plausible, since the energy of the beam is increased to a larger value than the energy at the initial deformed state in the process.
However, without external forces, the energy of the beam should be conserved according to Newton's laws of motion. For the experiments above, ADMM weights of 
$w_i = 0.3\sqrt{k}$ were used, where $k$ is the strain constraint stiffness. The fact that PD does not converge to the global minimum even though it is almost 
identical to ADMM with weights $w_i = \sqrt{k}$ is in line with our observation that lower ADMM weights encourage more aggressive optimization of the constraint 
energies (see Sec.\ \ref{ss:admm-weights}). Finally, Figure \ref{fig:strain-beam-twist-objectives} and Figure \ref{fig:strain-beam-twist-admm-geometries} highlight the ramifications
of terminating the ADMM solver before convergence is achieved: Early termination can increase the beam energy and cause visual geometric artifacts on the surface of the beam.

\begin{table}[h]
\centering
\begin{tabular}{ |r||c|c|c|c| } 
     \hline
     time step in s & \num{1e-1} & \num{1e-2} & \num{1e-3} & \num{1e-4}\\ 
     \hline
     stiffness & \num{1e6} & \num{1e10} & \num{1e10} & \num{1e12} \\
     & \num{1e8}  &  &  \num{1e12} &  \\
     & \num{1e11} &  &  &\\
     \hline
    \end{tabular}
\caption{Combinations of time step sizes and stiffness values for which the ADMM solver converges to the global minimum during the twisting beam experiments using 
the strain material model.}
\label{fig:strain-beam-twist-admm-artificial}
\end{table}

For each time step size, we list the stiffness values for which ADMM converges to the global minimum in the twisting beam experiments in 
Figure \ref{fig:strain-beam-twist-admm-artificial}. For the large time step \SI{1e-1}{\second}, the ADMM solver converges to the global minimum for stiffness values as 
low as \num{1e6}. As the time step size is decreased, larger stiffness values are required. Since achieving the global minimum requires moving particles far away 
from their inertial positions, it is expected that such aggressive minimizations of the constraint energies are favored by large stiffness values and large time steps
(see Sec.\ \ref{ss:variational-implicit-euler}). Still, it is likely that the choice of the ADMM weights has a strong impact on whether the ADMM solver converges to the 
the global minimum or not.

Lastly, we show that there are time step sizes and stiffness values for which ADMM does not converge at all in the twisting beam scenario. Conside the plot of the 
objective function values over the iterations for a time step of \SI{1e-2}{\second} and a stiffness value of \num{1e8} in 
Figure \ref{fig:strain-beam-twist-objectives-admm-failure}. The graphs show that ADMM oscillates between configurations with objective function values that are larger 
than the initial objective and objective function values that are smaller than the minimal objectives achieved by QN and PD. Similar results are observed for 
time step size \SI{1e-1}{\second} and stiffness \num{1e10} and timestep size \SI{1e-2} and stiffness values \num{1e8} and \num{1e10}.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/strain_beam_twist_objectives_admm_failure.pdf}
    \caption{Values of the objective function of the variational form of implicit Euler integration (see Eq.\ \ref{eq:variational-implicit}) over the iterations of 
        a single time step of size \SI{1e-2}{\second} for a twisting beam using strain constraints with stiffness \num{1e8}.}
    \label{fig:strain-beam-twist-objectives-admm-failure}
\end{figure}

Together with the results discussed above, the data from Figure \ref{fig:strain-beam-twist-objectives-admm-failure} suggests that ADMM drives particle 
positions towards the global minimum of the objective function, but eventually undoes its progress once the particle positions get too close. It is not clear why 
this failure to converge occurs for the parameters listed above, but not for the parameters in Figure \ref{fig:strain-beam-twist-admm-artificial}. Again, the choice 
of the ADMM weights most likely plays an important role here. Recall that ADMM weights used during the twisting beam experiments were adopted from the corresponding 
parameter screens for the untwisting beam experiments (see Sec.\ \ref{ss:admm-weights}). In light of the similarities between PD and ADMM with weights $w_i = \sqrt{k}$, 
it is reasonable to assume that convergence could be achieved with more appropriate ADMM weights. As a result, it might be necessary to fine-tune ADMM weights for 
individual simulation scenarios. Of course, this is highly impractical.

\subsection{Untwisting Beam Simulations - Neohookean Material}\label{ss:untwisting-beam-neohookean}

% TODO:
% - ADMM weights for neohookean model
% - XPBD formulations for neohookean model (incompressibility, stability)
% - Iteration times XPBD solvers
