\chapter{Method}\label{ch:method}

\section{Time-Integration of Physical Systems}\label{s:physical-integration}
In most approaches for the simulation of physical systems, the motion of the system is assumed to be in accordance with Newton's laws of
motion. Due to Newton's second law, it is possible to derive accelerations from forces acting on the system. The motion of the system
can then be described in terms of an ordinary differential equation (ODE) which is integrated over time in order to arrive at the 
configuration of the system at the next time step. Usually, this is achieved via numerical integration schemes. In particular, both
xPBD (\cref{ss:xpbd-constraint-projection}) and PD (\cref{ss:pd-solver}) are based on a numerical integration technique called implicit 
Euler integration. The ODE is introduced in \cref{s:newton-ode}. 
Common approaches for numerical integration are briefly reviewed in \cref{s:numerical-integration}.

\subsection{Newton's Ordinary Differential Equation}\label{s:newton-ode}

The motion of a spatially discretized system with $m$ particles evolving in time according to Newton's laws of motion can be modeled via 
the following ODE called Newton's ODE

\begin{align}
    \begin{split}\label{eq:newton-ode}
        \bm{q}(t)\prime &= \bm{v}(t) \\
        \bm{v}(t)\prime &= \bm{M}^{-1}\bm{f}(\bm{q}(t), \bm{v}(t)),
    \end{split}
\end{align}

\noindent where $\bm{q}(t)$, $\bm{v}(t)$, $\bm{f}(\bm{q}(t), \bm{v}(t))$ are the particle positions, particle velocities and forces acting on each particle
at time $t$, respectively, and $\bm{M}$ is a diagonal matrix with the particle masses as diagonal entries. Depending on the context, either 
$\bm{q}(t), \bm{v}(t), \bm{f}(\bm{q}(t), \bm{v}(t)) \in \mathbb{R}^{m \times 3}$ and $\bm{M} \in \mathbb{R}^{m \times m}$ or $\bm{q}(t), 
\bm{v}(t), \bm{f}(\bm{q}(t), \bm{v}(t)) \in \mathbb{R}^{3m}$ and $\bm{M} \in \mathbb{R}^{3m \times 3m}$. $\bm{q}(t)\prime$ and $\bm{v}(t)\prime$ are short 
for $\frac{d\bm{q}}{dt}(t)$ and
$\frac{d\bm{v}}{dt}(t)$, respectively. From now on, we write $\bm{q}$ and $\dot{\bm{q}}$ instead of $\bm{q}(t)$ and $\bm{q}(t)\prime$ for 
time-dependent quantities for the sake of brevity.

The positions $\bm{q}$ and velocities $\bm{v}$ of the system at time $t$ can be determind by solving this ODE. For general nonlinear forces,
analytical solutions to Newton's ODE are usually not available. Thus the ODE needs to be solved numerically.

\subsection{Numerical Integration of Newton's Ordinary Differential Equation}\label{s:numerical-integration}
The simplest approach to numerical integration is the explict Euler integration \cite{chapra2005}. When applied to Newton's ODE, 
the positions and velocities are computed at discrete timesteps via the following update formulas:

\begin{align*}
    \bm{q}_{n+1} &= \bm{q}_n + h\bm{v}_n\\
    \bm{v}_{n+1} &= \bm{v}_n + h\bm{M}^{-1}\bm{f}(\bm{q}_n, \bm{p}_n)
\end{align*}

\noindent Here, $h$ is the time step. The idea is to simplify the integration of the functions $\bm{\dot{q}}, \bm{\dot{v}}$ over the timestep by 
using constant approximations. 
Then, time integration is as simple as multiplying this constant function value with the timestep. In the explicit Euler method, we 
approximate $\bm{\dot{q}}, \bm{\dot{v}}$ by their function values $\bm{\dot{q}}(t_n), \bm{\dot{v}}(t_n)$ at the beginning of the timestep.
While simple, the explicit Euler method is not stable for stiff systems, i.e. systems with accelerations of large magnitude 
\cite{chapra2005}. It can be shown that the explicit Euler amplifies the energy of the simulated system \cite{stern2006}. For example, the 
amplititude of a swinging pendulum increases with time if integrated via the explicit Euler method, even if small time steps are used. 
Using the explicit Euler method with larger time steps often manifests itself in exploding simulations. 

A variation of the explicit Euler method applied to Newton's ODE, called the symplectic Euler method, arises when the new velocities 
$\bm{v}_{n+1}$ instead of the old velocities $\bm{v}_n$ are used in the position update \cite{stern2006}. This leads to the following 
update formula:

\begin{align}
    \begin{split}\label{eq:symplectic-euler}
        \bm{q}_{n+1} &= \bm{q}_n + h\bm{v}_{n+1}\\
        \bm{v}_{n+1} &= \bm{v}_n + h\bm{M}^{-1}\bm{f}(\bm{q}_n, \bm{p}_n)
    \end{split}
\end{align}

\noindent Even though the symplectic Euler method has the same computational cost as the explicit Euler method, while it still does not conserve
the system's energy exactly, it conserves a quadratic form that is close \cite{servin2006}. In contrast to the explicit Euler method, the 
symplectic Euler method preserves the amplitude of a swinging pendulum with appropriate time steps \cite{stern2006}. Its main drawback 
is that it also becomes unstable for stiff simulations unless the time step is kept prohibitively small \cite{servin2006}. 

Another popular integration scheme for tackling Newton's ODE is implicit Euler integration, resulting in the update formula

\begin{align}
    \begin{split}\label{eq:implicit-euler}
        \bm{q}_{n+1} &= \bm{q}_n + h\bm{v}_{n+1}\\
        \bm{v}_{n+1} &= \bm{v}_n + h\bm{M}^{-1}\bm{f}(\bm{q}_{n+1}, \bm{p}_{n+1}).
    \end{split}
\end{align}

\noindent Note how $\bm{q}_{n+1}$ and $\bm{v}_{n+1}$ appear on both sides of the equations. Consequently, performing implicit 
Euler integration includes solving a set of nonlinear algebraic equations. Despite the added complexity compared to the explicit and
symplectic Euler integration schemes implicit Euler integration is popular since it can be shown to be unconditionally stable and first-order
accurate \cite{chapra2005}. This allows dramatically increasing the size of the time steps. The additional cost of a single implicit Euler 
step compared to the previously mentioned integration schemes is offset by the fact that fewer steps are required to drive the 
simulation forward the same amount of time in a stable manner. However, implicit Euler integration is known to exhibit numerical 
damping \cite{stern2006}. This manifests itself in a loss of energy in the simulated system. For example, the amplitude of a swinging 
pendulum decreases if integrated using the implicit Euler method.

By rewriting the first line of \cref{eq:implicit-euler} as

\[
    \bm{v}_{n+1} = \frac{1}{h}(\bm{q}_{n+1} - \bm{q}_n)
\]

\noindent and substituting into the velocity update of \cref{eq:implicit-euler} the following equation can be derived

\begin{equation}\label{eq:implicit-positional}
    \bm{M}(\bm{q}_{n+1} - \bm{q}_n - h\bm{v}_n) = h^2(\bm{f}(\bm{q}_{n+1}, \bm{v}_{n+1})).
\end{equation}

\noindent We separate forces $\bm{f}(\bm{q}, \bm{v})$ into internal forces $\bm{f}_{\text{int}}(\bm{q}, \bm{p}) = \sum_{i \in \mathcal{I}_{\text{int}}} 
\bm{f}^i_{\text{int}}
(\bm{q}, \bm{p})$ and external forces $\bm{f}_{\text{ext}}(\bm{q}, \bm{p}) = \sum_{i \in \mathcal{I}_{\text{ext}}} \bm{f}^i_{\text{ext}}(\bm{q}, 
\bm{p})$ with index sets $\mathcal{I}_{\text{int}}$ and $\mathcal{I}_{\text{ext}}$. We consider all external forces to be constant. Internal forces 
are conservative and defined in terms of scalar potential energy functions 
$\psi_j$ via $\bm{f}^j_{\text{int}}(\bm{q}) = -\nabla \psi_j(\bm{q})$. Together, we have $\bm{f}(\bm{q}, \bm{v}) = \bm{f} (\bm{q}) 
= \bm{f}_{\text{int}} (\bm{q}) + \bm{f}_{\text{ext}} = -\sum_j \nabla \psi_j(\bm{q}) + \bm{f}_{\text{ext}}$. Plugging into 
\cref{eq:implicit-positional}, it is

\begin{equation}\label{eq:implicit-positional-detailed}
    \bm{M}(\bm{q}_{n+1} - \bm{q}_n - h\bm{v}_n) = h^2(\bm{f_\text{ext}} - \sum_j \nabla \psi_j(\bm{q}_{n+1})).
\end{equation}

\noindent By computing first-order optimality conditions, it is easily verified that the above system of equations is equivalent to the optimization 
problem

\begin{equation}\label{eq:variational-implicit}
    \min_{\bm{q}_{n+1}} \frac{1}{2h^2} \norm{\bm{q}_{n+1} - \bm{s}_n}^2_F + \sum_j \psi_j(\bm{q}_{n+1}).
\end{equation}

\noindent where $\bm{s}_n = \bm{q}_n + h\bm{v}_n + h^2\bm{M}^{-1}\bm{f}_{\text{ext}}$. This minimization problem whose solution corresponds to the next
iteration of the state of the implicit Euler integration is called the variational form of implicit Euler integration \cite{bouaziz2014}. 
The first and second term of the objective function are called the momentum potential and the elastic potential, respectively. Thus, the 
minimization problem requires that the solution minimizes the elastic deformation as best as possible while ensuring that the solution is 
close to following its momentum plus external forces. The weighting between the momentum potential and the elastic potential depends on the 
particle masses $\bm{M}$, the timestep $h$ and the material stiffness of the elastic potentials $\psi_j$. According to Noether's theorem, 
the solution preserves linear and angular momentum as long as the elastic potentials are rigid motion invariant.

Approaching implicit Euler integration in its variational form can often be advantageous. That is because the objective function of 
\cref{eq:variational-implicit} presents a natural merit function that can be employed to improve the step size along the search direction 
that arises in common unconstrained optimization algorithms \cite{nocedal2006}. As an example, the objective function is used in many step 
length selection algorithms to ensure that step sizes satisfy the Wolfe conditions (\cref{sss:step-length-selection}). In fact, many algorithms 
for solving non-linear systems of equations construct approximate merit functions if the objective function from an equivalent optimization
problem is not available \cite{nocedal2006}.

\section{Unconstrained Optimization}\label{s:unconstrained-optimization}
The goal of unconstrained optimization is to find the global minimizer of smooth, but generally nonlinear functions of the form $f \colon 
\mathbb{R}^n \to \mathbb{R}, n \in \mathbb{N}$, or formally

\[
    \min_{\bm{x}} f(\bm{x}).
\]

\noindent Here, $f$ is called the objective function. 

Most algorithms are incapable of finding global minimizers of general nonlinear functions. 
Instead, these algorithms begin their search at a starting point $\bm{x}_0$ and then iteratively improve this initial guess until a local 
minimizer is found \cite{nocedal2006}. A local minimizer is a point $\bm{x}^*$ such that there is a neighborhood $\mathcal{N}$ of 
$\bm{x}^*$ such that $f(\bm{x}^*) \leq f(\bm{x})$ for all $\bm{x} \in \mathcal{N}$. If the initial guess $\bm{x}^*$ is close enough 
to the global minimizer the local minimizer that the algorithm converges to can often coincide with a global minimizer. 

\subsection{Line Search Methods}\label{ss:line-search}
It can be shown that $\nabla f(\bm{x}^*) = 0$ if $\bm{x}^*$ is a local minimizer and f is continuously differentiable in an open neighborhood
of $\bm{x}^*$ \cite{nocedal2006}. The proof is by contradiction and establishes that if $\nabla f(\bm{x}^*) \neq 0$, then it is possible to pick a descent 
direction along which it is possible to decrease the value of the objective function if the step size is picked sufficiently small. This 
observation gives rise to the idea of a family of optimization algorithms called line search algorithms \cite{nocedal2006}: Given the current 
iterate $\bm{x}_k$, pick a descent direction $\bm{p}_k$ and search along this direction for a new iterate $\bm{x}_{k+1}$ with $\bm{x}_{k+1} = 
\bm{x}_k + \alpha_k \bm{p}_k$. This process is repeated until $\nabla f(\bm{x}_k)$ is sufficiently close to zero. It is important to note that 
$\nabla f(\bm{x}) = 0$ does not imply that $\bm{x}$ is a local minimizer. Instead, $\bm{x}$ is only guaranteed to be a local minimizer if 
the second-order 
optimality conditions are satisfied, which additionally require $\nabla^2 f(\bm{x})$ to be positive semidefinite \cite{nocedal2006}.

Ideally, $\alpha_k$ is picked such that it is the minimizer of the one-dimensional optimization problem

\[
    \min_{\alpha_k > 0} f(\bm{x}_k + \alpha_k \bm{p}_k).
\]

\noindent In most cases, it is infeasible to compute $\alpha_k$ exactly. Instead, the idea is to compute an approximation of $\alpha_k$ such that 
the objective function decreases sufficiently and that $\alpha_k$ is close enough to the true minimizer. Formally, these requirements
are captured in the strong Wolfe conditions for step lengths $\alpha_k$ \cite{nocedal2006}:

\begin{align}
    f(\bm{x}_k + \alpha_k \bm{p}_k) &\leq f(\bm{x}_k) + c_1 \alpha_k \nabla f(\bm{x}_k)^T \bm{p}_k \label{eq:wolfe1} \\
    \abs{\nabla f(\bm{x}_k + \alpha_k \bm{p}_k)^T \bm{p}_k} &\leq c_2 \abs{\nabla f(\bm{x}_k)^T \bm{p}_k} \label{eq:wolfe2}
\end{align}

\noindent for some constants $c_1 \in (0, 1), c_2 \in (c_1, 1)$. \cref{eq:wolfe1} is called the sufficient decrease or the Armijo condition 
and states that the reduction in $f$ should be proportional to both the step length $\alpha_k$ and the directional derivative 
$\nabla f(\bm{x}_k)^T \bm{p}_k$. Informally, the second condition (\cref{eq:wolfe2}), known as the curvature condition, ensures that there 
is no more fast 
progress to be made along the search direction $\bm{p}_k$, indicated by the fact that $\abs{\nabla f(\bm{x}_k + \alpha_k \bm{p}_k)^T
\bm{p}_k}$ is already rather small. 

Step sizes satisfying the strong Wolfe conditions have the following properties under mild assumptions \cite{nocedal2006}. Firstly, 
if $\bm{p}_k$ is a descent direction, it is possible to find a step size that satisfies the strong Wolfe conditions. In particular,
the Armijo condition is always satisfied once $\alpha_k$ is sufficiently close to zero. Secondly, it 
can be shown that line search methods where $\alpha_k$ satisfies the strong Wolfe conditions for all $k$ converge to a stationary
point $\bm{x}^*$ with $\nabla f(\bm{x}^*) = 0$ if the search direction $\bm{p}_k$ is sufficiently far from orthogonal to the steepest
descent direction $\nabla f(\bm{x}_k)$ for all $k$. Such line search algorithms are called globally convergent.

The general structure of line search methods is given in \cref{alg:line-search}.

\begin{algorithm}
\caption{Line Search Methods}\label{alg:line-search}
\begin{algorithmic}
\State \textbf{require } $\epsilon > 0$
\Procedure{lineSearchMethod}{$\bm{x}_0$, $\epsilon$}
\State $\bm{x}_k = \bm{x}_0$
\While{$\norm{\nabla f(\bm{x}_k)} > \epsilon$}
\State compute a descent direction $\bm{p}_k$
\State compute $\alpha_k$ that satisfies the strong Wolfe conditions
\State $\bm{x}_k = \bm{x}_k + \alpha_k \bm{p}_k$
\EndWhile
\State \textbf{return with result } $\bm{x}_k$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsubsection{Steepest Descent}\label{sss:steepest-descent}
The most obvious choice for the search direction $\bm{p}_k$ at iteration $k$ is the negative gradient at the current iterate given by 
\[
    \bm{p}_k = -\nabla f(\bm{x}_k).
\]

\noindent This search direction is called the steepest descent direction. Using the steepest descent direction in \cref{alg:line-search} 
is called the steepest descent method. While simple, steepest descent exhibits poor performance, even for simple problems \cite{nocedal2006}. 
Its convergence rate is only linear and depends on the eigenvalue distribution of the Hessian $\nabla^2 f(\bm{x}^*)$ at the local minimizer
$\bm{x}^*$. If the eigenvalue distribution is wide, steepest descent often requires an unacceptably large number of iterations to find a 
stationary point.

\subsubsection{Newton Method}\label{sss:newton-method}
It can be shown that any search direction $\bm{p}_k$ that makes an angle of strictly less than $\pi/2$ radians with the steepest descent
direction $\nabla f(\bm{x}_k)$ is a descent direction as well \cite{nocedal2006}. As long as $\bm{p}_k$ does not get arbitrarily close to 
orthogonal to $\nabla f(\bm{x}_k)$, any such $\bm{p}_k$ can be used in the line search framework. The so called Newton direction $\bm{p}^N_k$ 
is a popular choice. It is derived from the second-order Taylor series approximation to $f(\bm{x}_k + \bm{p})$ which is given by

\begin{equation}\label{eq:newton-model}
    f(\bm{x}_k + \bm{p}) \approx f(\bm{x}_k) + \bm{p}^T \nabla f(\bm{x}_k) + \frac{1}{2}\bm{p}^T \nabla^2 f(\bm{x}_k) \bm{p} \eqqcolon 
    m_k(\bm{p}).
\end{equation}

\noindent The model function $m_k$ has a unique minimizer if $\nabla^2 f(\bm{x}_k)$ is positive definite. In this case, the Newton direction 
is defined
as the unique minimizer $\bm{p}^N_k$ of $m_k$, which can be found by setting the derivative of $m_k(\bm{p})$ to zero:

\begin{equation}\label{eq:newton-diretion}
    \bm{p}^N_k = - (\nabla^2 f(\bm{x}_k))^{-1} \nabla f(\bm{x_k}).
\end{equation}

\noindent The better the quadratic model function $m_k(\bm{p})$ approximates $f(\bm{x}_k + \bm{p})$ around $\bm{x}_k$, the more reliable is the 
Newton direction. 

It is easy to show that $\bm{p}^N_k$ is a descent direction, given that $\nabla^2 f(\bm{x}_k)$ is positive definite \cite{nocedal2006}. 
Otherwise, the Newton direction is not guaranteed to exist, or to be a descent direction if it does. In such cases, the Newton direction cannot 
be used without modification. Thus, in its naive form, the Newton method is not globally convergent. However, if $\nabla^2 f(\bm{x}^*)$ is positive
definite at a local solution $\bm{x}^*$ and $f$ is twice differentiable, then $\nabla^2 f(\bm{x})$ is also positive definite for $\bm{x} \in 
\mathcal{N}$ for some neighborhood $\mathcal{N}$ of $\bm{x}^*$. If we have $\bm{x}_0 \in \mathcal{N}$ for the starting point of $\bm{x}_0$
of Newton's method and $\bm{x}_0$ is sufficiently close to the solution $\bm{x}^*$ it can be shown that Newton's method with step length
$\alpha_k = 1$ converges to $\bm{x}^*$ with a quadratic rate of convergence under mild conditions \cite{nocedal2006}. Thus, Newton's method 
has satisfactory convergence properties close to the solution $\bm{x}^*$ and the Newton direction $\bm{p}^N_k$ has a natural step size 
$\alpha_k = 1$ associated with it. Since $\alpha_k = 1$ often does not satisfy the Wolfe conditions when the current iterate $\bm{x}_k$ is still 
far away from the solution $\bm{x}^*$, line searches are still necessary in Newton's method. However, it is recommended to use $\alpha_k = 1$ as the
initial guess as $\alpha_k = 1$ guarantees quadratic convergence once $\bm{x}_k$ gets sufficiently close to $\bm{x}^*$.

A general overview over Newton's method is given in \cref{alg:newton-method}. Note that practical implementations of Newton's method might deviate
from the outlined algorithm. As an example, it is possible to apply positive definiteness fixes to the Hessian matrix $\nabla^2 f(\bm{x}_k)$
while computing its matrix factorization. 

\begin{algorithm}
\caption{Newton's Method}\label{alg:newton-method}
\begin{algorithmic}
\State \textbf{require } $\epsilon > 0$
\Procedure{newtonMethod}{$\bm{x}_0$, $\epsilon$}
\State $\bm{x}_k = \bm{x}_0$
\While{$\norm{\nabla f(\bm{x}_k)} > \epsilon$}
\State compute $\nabla^2 f(\bm{x}_k)$
\If{$\nabla^2 f(\bm{x}_k)$ is not positive definite}
\State apply positive definiteness fix to $\nabla^2 f(\bm{x}_k)$
\EndIf
\State $\bm{p}_k = -(\nabla^2 f(\bm{x}_k))^{-1} \nabla f(\bm{x}_k)$
\State $\alpha_k = 1$
\If{$\alpha_k$ does not satisfy the strong Wolfe conditions}
\State compute $\alpha_k$ that satisfies the strong Wolfe conditions
\EndIf
\State $\bm{x}_k = \bm{x}_k + \alpha_k \bm{p}_k$
\EndWhile
\State \textbf{return with result } $\bm{x}_k$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Despite its favorable convergence properties, Newton's method comes with a couple of disadvantages. Firstly, computing the Hessian matrix
$\nabla^2 f(\bm{x}_k)$ is expensive and error prone. Additionally, a new system 

\[
    \nabla^2 f(\bm{x}_k) \bm{p}^N_k = - \nabla f(\bm{x_k})
\]

\noindent needs to be solved at every iteration as the Hessian matrix changes with the current iterate $\bm{x}_k$.
If the Hessian $\nabla^2 f(\bm{x}_k)$ is sparse, its factorization can be computed via sparse elimination techniques. However, there is no
guarantee for the matrix factorization of a sparse matrix to be sparse itself in the general case.
For these reasons, while a single
Newton iteration often makes quite a lot of progress towards the solution, it takes a significant amount of time to compute. If $\bm{x}_k
\in \mathbb{R}^n$ for some large $n \in \mathbb{N}$, computing the exact Newton iteration can become infeasible, especially for real-time
applications. Concomitantly, the memory required to store the Hessian matrix of size $\mathcal{O}(n^2)$ becomes prohibitive.

\subsubsection{Quasi-Newton Methods}\label{sss:quasi-newton}
Due to the shortcomings of Newton's method mentioned in \cref{sss:quasi-newton}, it can be favorable to simply approximate the Newton 
direction
in order to find an effective search direction while keeping the cost of a single iteration low. Effective Newton approximations can be 
computed without the need to compute the Hessian $\nabla^2 f(\bm{x}_k)$ during each iteration \cite{nocedal2006}. Often, multiple Quasi-Newton 
iterations fit into the same time budget as a single Newton iteration. As a result, Quasi-Newton methods can converge to a solution in a 
shorter amount of time than the Newton method, even though their search directions are not as effective as the exact Newton direction.

In Quasi-Newton methods, search directions of the following form are used

\begin{equation}\label{eq:quasi-newton-direction}
    \bm{p}_k = -\bm{B}^{-1}_k \nabla f(\bm{x}_k),
\end{equation}

\noindent where $\bm{B}_k \in \mathbb{R}^{n \times n}$ is positive definite \cite{nocedal2006}. Note that the Newton direction is a special 
case of 
\cref{eq:quasi-newton-direction} with $\bm{B}_k = \nabla^2 f(\bm{x}_k)$. Just like for the Newton direction $\bm{p}^N_k$ in
\cref{eq:newton-model}, a model function $m_k$ 
that attains its minimum at $\bm{p}_k  = -\bm{B}^{-1}_k \nabla f(\bm{x}_k)$ can be defined via

\begin{equation}\label{eq:quasi-newton-model}
    m_k(\bm{p}) = f(\bm{x}_k)  + \nabla f(\bm{x}_k)^T \bm{p} + \frac{1}{2} \bm{p}^T\bm{B}_k\bm{p}.
\end{equation}

\noindent As $\bm{B}_k \neq \nabla^2 f(\bm{x}_k)$, $m_k$ does not correspond to a second-order Taylor approximation of $f$ around 
$\bm{x}_k$ anymore. Instead, $\bm{B}_k$ is picked such that the gradient of $m_k$ matches the gradient of $f$ at the last two iterates 
$\bm{x}_k$ and $\bm{x}_{k-1}$.
Since $\nabla m_{k}(\bm{0}) = \nabla f(\bm{x}_k)$, the first condition is true independent of $\bm{B}_k$. The 
second condition yields

\[
    \nabla m_{k}(-\alpha_{k-1}\bm{p}_{k-1}) = \nabla f(\bm{x}_k) - \alpha_{k-1}\bm{B}_{k}\bm{p}_{k-1} = \nabla f(\bm{x}_{k-1}).
\]

\noindent Rearranging gives

\begin{equation}\label{eq:secant-equation}
    \bm{B}_k \bm{s}_{k-1} = \bm{y}_{k-1},
\end{equation}

\noindent where $\bm{s}_{k-1} = \bm{x}_k - \bm{x}_{k-1} = \alpha_{k-1}\bm{p}_{k-1}$. This is called the secant equation. 
Multiplying both sides from the left with $\bm{s}_{k-1}^T$ yields the curvature condition given by

\begin{equation}\label{eq:curvature-condition}
    \bm{s}_{k-1}^T \bm{y}_{k-1} > 0,
\end{equation}

\noindent since $\bm{B}_k$ is positive definite. Note that the curvature condition is not satisfied for arbitrary $\bm{x}_k, \bm{x}_{k-1}$ 
if $f$ is 
not convex. However, it can be shown that the curvature condition always holds when the step size $\alpha_{k-1}$ satisfies the strong Wolfe 
conditions \cite{nocedal2006}. Thus, a proper line search strategy is vital for the viability of Quasi-Newton methods.

Since $\bm{B}_k$ is positive definite, the secant equation can be written in terms of the inverse $\bm{H}_k \coloneqq \bm{B}^{-1}_k$ as

\[
    \bm{H}_k \bm{y}_{k-1} = \bm{s}_{k-1}
\]

\noindent and the formula for the new search direction becomes $-\bm{H}_k \nabla f(\bm{x}_k)$. The secant equation is not enough to uniquely determine
the entries of $\bm{H}_k$, even if $\bm{H}_k$ is required to be symmetric positive definite. Thus, the additional requirement that $\bm{H}_k$
is closest to $\bm{H}_{k-1}$ according to some norm is imposed. In summary, $\bm{H}_k$ is picked such that it solves the following constrained
minimization problem

\begin{align*}
    \min_{H} \norm{\bm{H} - \bm{H}_{k-1}} \text{, subject to } \bm{H} = \bm{H}^T \text{ and } \bm{H}\bm{y}_{k-1} = \bm{s}_{k-1}.
\end{align*}

Using a scale-invariant version of the weighted Frobenius norm gives rise to the popular Broyden- Fletcher-Goldfarb-Shanno (BFGS) algorithm.
It is defined via the following update formula for $\bm{H}_k$

\begin{equation}\label{eq:bfgs-update}
    \bm{H}_k = (I - \rho_{k-1}\bm{s}_{k-1}\bm{y}^T_{k-1})\bm{H}_{k-1}(I - \rho_{k-1}\bm{s}_{k-1}\bm{y}^T_{k-1}) + \rho_{k-1}\bm{s}_{k-1}\bm{s}^T_{k-1},
\end{equation}

\noindent where $\rho_{k-1} = 1 / (\bm{s}^T_{k-1}\bm{y}_{k-1})$. Is is possible to give a similar update formula in terms of $\bm{B}_k$.
Generally, using the formulation in terms of the inverse matrices $\bm{H}_k$ is preferrable since the computation of the new descent 
direction can
be achieved by simple matrix-vector multiplication instead of solving a linear system if $\bm{B}_k$ is maintained instead. An overview over the
algorithm is given in \cref{alg:bfgs}.

\begin{algorithm}
\caption{BFGS method}\label{alg:bfgs}
\begin{algorithmic}
\State \textbf{require } $\bm{H}_0$ symmetric positive definite, $\epsilon > 0$
\Procedure{BFGS}{$\bm{x}_0$, $\bm{H}_0$, $\epsilon$}
\State $\bm{x}_k, \bm{x}_{k-1} = \bm{x}_0, \bm{H}_k = \bm{H}_0 $
\While{$\norm{\nabla f(\bm{x}_k)} > \epsilon$}
\State $\bm{s} = \bm{x}_k - \bm{x}_{k-1}, \bm{y} = \nabla f(\bm{x}_k) - \nabla f(\bm{x}_{k-1}), \rho = 1 / (\bm{s}^T \bm{y})$
\State $\bm{H}_k = (I - \rho \bm{s} \bm{y}^T) \bm{H}(I - \rho \bm{s} \bm{y}^T) + \rho\bm{s}\bm{s}^T$
\State $\bm{p}_k = -\bm{H}_k \nabla f(\bm{x}_k)$
\State $\alpha_k = 1$
\If{$\alpha_k$ does not satisfy the strong Wolfe conditions}
\State compute $\alpha_k$ that satisfies the strong Wolfe conditions
\EndIf
\State $\bm{x}_{k-1} = \bm{x_k}$
\State $\bm{x}_k = \bm{x}_k + \alpha_k \bm{p}_k$
\EndWhile
\State \textbf{return with result } $\bm{x}_k$
\EndProcedure
\end{algorithmic}
\end{algorithm}

While global convergence of the BFGS method cannot be established for general nonlinear smooth functions, it is possible to show that it converges 
superlinearly if the initial guess $\bm{x}_0$ is close to the solution $\bm{x}^*$ and $\alpha_k = 1$ for sufficiently large $k$ \cite{nocedal2006}
under mild conditions. Thus, just like the Newton method (\cref{sss:newton-method}), the BFGS method has a natural step length $\alpha=1$,
which should be the initial guess for all line search algorithms. Typically, the BFGS method dramatically outperforms steepest 
descent and performs comparably to Newton's method on many practical problems. 

The behavior of the BFGS method depends on the choice of the initial inverse matrix $\bm{H}_0$. One obvious choice is $\bm{H}_0 = \nabla^2 
f(\bm{x}_0)$. However, there is no guarantee that $\nabla^2 f(\bm{x}_0)$ is positive definite. Additionally, computing even a single inverse
matrix can be prohibitively expensive for large problems. Thus, scaled versions of the identity matrix $\gamma I, \gamma \in \mathbb{R}^+$ are
often used instead. There is no good general strategy for choosing $\gamma$, even though heuristic appraoches are popular. \textcolor{red}{Maybe
explain one heuristic, if necessary down the line}.

Even though BFGS iterations are typically faster to compute than Newton iterations, the BFGS method is still not suitable for large problems 
in its naive form. Just like in Newton's method, either $\bm{H}_k$ or $\bm{B}_k$ needs to be stored explicitly, which can be infeasible for 
large-scale problems. While the BFGS update formula using the inverse matrices $\bm{H}_k$ replaces the need for a matrix factorization with a simple 
matrix-vector multiplication, $\bm{H}_k$ and $\bm{B}_k$ are generally dense, even if $\nabla^2 f(\bm{x}_k)$ is sparse. This removes the possibility
of alleviating storage requirements and speeding up computations via sparse matrix techniques when using the naive BFGS method.

\subsubsection{Limited-Memory Quasi-Newton Methods}\label{sss:limited-memory-quasi-newton}
As discussed in \cref{sss:quasi-newton}, the BFGS method is unsuitable for large-scale problems due to the storage requirements of the 
typically dense inverse Hessian approximation $\bm{H}_k$. This highlights the need for effective Hessian approximations that are not only
cheap to compute, but also cheap to store. Just like Quasi-Newton methods use approximations of the Newton direction in order to keep 
the computational cost of a single iteration low, limited-memory Quasi-Newton methods approximate Quasi-Newton directions with 
the goal of reducing the memory footprint of a single iteration. This comes at the prize of inferior convergence properties. On the upside,
limited-memory Quasi-Newton directions can sometimes be computed by using only a couple of vectors of size $n$, without the need to 
explicitly form the inverse Hessian approximation $\bm{H}_k$. This can drop the space complexity of a single iteration to $\mathcal{O}(n)$ 
compared to $\mathcal{O}(n^2)$ for the BFGS method.

A popular limited-memory method called L-BFGS can be derived from the BFGS update formula for the inverse Hessian approximation 
$\bm{H}_k$ (\cref{eq:bfgs-update}) \cite{nocedal2006}. Note that the BFGS update in iteration $k$ is specified entirely 
by the vector 
pair $(\bm{s}_n, \bm{y}_n) \in \mathbb{R}^n$. Consequently, $\bm{H}_k$ can be constructed from the initial matrix $\bm{H}_0$ and the familiy 
of vector pairs $((\bm{s}_i, \bm{y}_i))_{i \in [0, k-1]}$ by simply performing $k$ update steps according to $\cref{eq:bfgs-update}$.
The idea of L-BFGS is to only keep track of the most recent $m$ vector pairs and generate a modified version of the inverse Hessian 
approximation from the BFGS method by applying the $m$ updates defined by $((\bm{s}_i, \bm{y}_i))_{i \in [k-m, k-1]}$ to the 
initial matrix $\bm{H}_0$ at each iteration $k$.

It is important to note that its not the L-BFGS Hessian approximation $\bm{H}_k$ itself, but the search direction $\bm{p}_k = -\bm{H}_k 
\nabla f(\bm{x}_k)$ that is of interest. It turns out that the L-BFGS search direction $\bm{p}_k$ can be computed without explicitly 
constructing $\bm{H}_k$ using an algorithm called the L-BFGS two-loop recursion (\cref{alg:lbfgs-recursion}) \cite{nocedal2006}. This
algorithm can be specified in terms of the initial Hessian approximation $\bm{B}_0$ with minor changes, as indicated by line 6. To 
simplify the notation, the entire history of $\bm{s} = (\bm{s}_i)_{i \in [0, k]}, \bm{y} = (\bm{y}_i)_{i \in [0, k]}, \rho = 
(\rho_i)_{i \in [0, k]}$
is passed to \textsc{twoLoopRecursion}, even though at most the $m$ most recent values are needed.

\begin{algorithm}
\caption{L-BFGS two-loop Recursion}\label{alg:lbfgs-recursion}
\begin{algorithmic}[1]
\State \textbf{require } $\bm{H}_0$ or $\bm{B}_0$ symmetric positive definite
\Procedure{twoLoopRecursion}{$\bm{H}_0 \text{ or } \bm{B}_0$, $\bm{x}_k$, $\bm{s}$, $\bm{y}$, $\rho$, $m$, $k$}
\State $m^* = \min(m, k), \bm{t} = -\nabla f(\bm{x}_k)$
\For{$i = k-1, k-2, \ldots, k-m^*$}
\State $\alpha_i = \rho_i \bm{s}^T_i \bm{t}$
\State $\bm{t} = \bm{t} - \alpha_i \bm{y}_i$
\EndFor
\State $\bm{r} = \bm{H}_0 \bm{t}$ or solve $\bm{B}_0 \bm{r} = \bm{t}$
\For{$i = k-m^*, k-m^*+1, \ldots, k-1$}
\State $\beta = \rho_i \bm{y}^T_i \bm{r}$
\State $\bm{r} = \bm{r} + \bm{s}_i(\alpha_i - \beta)$
\EndFor
\State \textbf{return with result } -$\bm{H}_k \nabla f(\bm{x}_k) = \bm{r}$.
\EndProcedure
\end{algorithmic}
\end{algorithm}

Excluding the matrix-vector multiplication $\bm{H}_0 \bm{t}$, the two-loop recursion scheme has time complexity $\mathcal{O}(nm)
= \mathcal{O}(n)$ since $m << n$. Thus,
if $\bm{H}_0$ is chosen to be diagonal, the entire L-BFGS iteration can be computed in $\mathcal{O}(n)$. Similarly, the space complexity
of the L-BFGS iteration is $\mathcal{O}(n)$ if $\bm{H}_0$ is diagonal. Even if $\bm{H}_0$ is not diagonal, but sparse, the two-loop
recursion can be significantly faster and more space efficient than a BFGS update where matrix-vector multiplication with a dense matrix
is required in general. Note that the same is not necessarily true if $\bm{B}_0$ is sparse, but not diagonal. In this case, a factorization
of $\bm{B}_k$ needs to be computed which is not guaranteed to stay sparse.

An overview over the entire L-BFGS algorithm is given in \cref{alg:lbfgs}, where the details of maintaining the history
of $\bm{s}, \bm{y}, \rho$ are omitted for the sake of clarity.

\begin{algorithm}
\caption{L-BFGS method}\label{alg:lbfgs}
\begin{algorithmic}
\State \textbf{require } $\bm{H}_0$ symmetric positive definite, $\epsilon > 0$
\Procedure{LBFGS}{$\bm{x}_0$, $\bm{H}_0$, $m$, $\epsilon$}
\State $\bm{x}_k = \bm{x}_0, \bm{H}_k = \bm{H}_0, k=0$
\While{$\norm{\nabla f(\bm{x}_k)} > \epsilon$}
\State $\bm{s_k} = \bm{x}_k - \bm{x}_{k-1}, \bm{y}_k = \nabla f(\bm{x}_k) - \nabla f(\bm{x}_{k-1}), \rho_k = 1 / (\bm{s}^T_k \bm{y}_k)$
\State $\bm{p}_k = \text{\textsc{twoLoopRecursion}}(\bm{H}_0, \bm{x_k}, \bm{s}, \bm{y}, \bm{\rho}, m, k)$   (\cref{alg:lbfgs-recursion})
\State $\alpha_k = 1$
\If{$\alpha_k$ does not satisfy the strong Wolfe conditions}
\State compute $\alpha_k$ that satisfies the strong Wolfe conditions
\EndIf
\State $\bm{x}_k = \bm{x}_k + \alpha_k \bm{p}_k, k = k + 1$
\EndWhile
\State \textbf{return with result } $\bm{x}_k$
\EndProcedure
\end{algorithmic}
\end{algorithm}

L-BFGS shares many properties with the BFGS method discussed in \cref{sss:quasi-newton}. The performance of the L-BFGS method depends 
on the choice of the initial matrix $\bm{H}_0$, with scaled diagonal matrices being popular choices. Again, there is no generally viable
strategy for picking the scaling factor $\gamma \in \mathbb{R}$. Similarly, the initial guess for the step size $\alpha_k=1$ should be used.
The window size $m$ is a parameter that needs to be tuned on a per-problem basis \cite{nocedal2006}. While the L-BFGS algorithm is 
generally less robust if
$m$ is small, making $m$ arbitrarily large increases the amount of time required to perform the two-loop recursion. If the matrix-vector
multiplication in \cref{alg:lbfgs-recursion} is expensive to compute, the additional computational cost incurred by increasing $m$ is 
usually overshadowed by the matrix-vector multiplication. Still, larger values of $m$ do not necessarily lead to better performance. 
\cite{liu2017} suggest that curvature information from vector pairs $(\bm{s}_i, \bm{y}_i)$ from iterations i with $i << k$ can become 
out of date, making moderately large values of $m$ more beneficial. The main weakness of the L-BFGS method is its slow convergence on 
problems where the true Hessian matrices $\nabla^2 f(\bm{x})_k$ are ill-conditioned \cite{nocedal2006}.

\subsubsection{Step Length Selection Algorithms}\label{sss:step-length-selection}
In \cref{ss:line-search}, the need for step lengths $\alpha_k$ that satisfy the strong Wolfe conditions (\cref{eq:wolfe1}, \cref{eq:wolfe2})
for the convergence of line search methods was discussed. Appropriate step lengths are determined via step length selection algorithms. 
These algorithms are typically
split into two phases \cite{nocedal2006}. The bracketing phase determines an interval $[\alpha_{\text{min}}, \alpha_{\text{min}}]$ that is 
guaranteed to contain suitable step lengths. The selection phase is an iterative process that interpolates function values and gradients 
from previous iterations in order to shrink the interval and eventually pick the final step length. For more details, the reader is 
referred to Chapter 3 of \cite{nocedal2006}. As step length algorithms are a common source of bugs, Nocedal and Wright \cite{nocedal2006}
recommend using publically available implementations.

To avoid the complexities of correct step length algorithms, the insight that the Armijo condition (\cref{eq:wolfe1}) is always satisfied 
once $\alpha$ is sufficiently close to zero (\cref{ss:line-search}) can be exploited (\cite{nocedal2006}): If a good first estimate $\alpha = 
\tilde{\alpha}$ is available,
we check whether it satisfies the Armijo condition. Otherwise, $\alpha$ is gradually decreased until sufficient decrease is satisfied or until
it falls below a predefined threshold. The idea is that the resulting step length will often satisfy the second Wolfe condition automatically 
as long as the initial estimate $\tilde{\alpha}$ is a well-informed guess and step lengths are not decreased too rapidly. For Newton's method
and Quasi-Newton methods, usually $\tilde{\alpha} = 1$ is used for the best results. This approach is known
as backtracking and is outlined in \cref{alg:backtracking}. Here, $c_1$ is the constant factor from the Armijo condition.

\begin{algorithm}
\caption{Backtracking}\label{alg:backtracking}
\begin{algorithmic}
\State \textbf{require } $\tilde{\alpha} > 0, c_1 \in (0, 1), \beta \in (0, 1), t \in (0, \tilde{\alpha})$
\Procedure{backtrack}{$\bm{x}_k$, $\bm{p}_k$, $\tilde{\alpha}$, $\beta$, $t$}
\State $\alpha = \tilde{\alpha}$
\While{$f(\bm{x}_k + \alpha \bm{p}_k) \leq f(\bm{x}_k) + c_1 \alpha \nabla f(\bm{x}_k)^T \bm{p}_k$ and $\alpha > t$}
\State $\alpha = \beta \alpha$
\EndWhile
\State \textbf{return with } $\alpha_k = \alpha$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Backtracking is much simpler to implement than correct step length algorithms. Additionally, each iteration of the backtracking algorithm
only requires the computation of a single function evaluation. Thus, if function evaluations are cheaper than gradient evaluations 
backtracking is also more efficient. However, backtracking does not provide a guarantee that the final step length satisfies the curvature
condition. If the search direction $\bm{p}_k$ is effective, e.g.\ when Newton's method is used, this tradeoff is often justifiable 
\cite{nocedal2006}. For less effective search directions, including search directions from most Quasi-Newton methods, backtracking might
be less suitable.

\section{Dynamic Simulation}\label{s:dynamic-simulation}
\begin{itemize}
    \item Write a paragraph that gives an overview
    \item Use $\bm{q}$ instead of $\bm{x}$ everywhere
    \item Rewrite this entire section from scratch. Make sure that the notation is unified. At the end of each method,
        point out what its issues are. When the next method is introduced that solves some of these issues, highlight
        how with a couple of sentences.
\end{itemize}

\subsection{Stiff Springs}\label{ss:stiff-springs}
Common effects in elasticity-based simulations such as attaching one body to another or maintaining fixed distance between two 
particles can approximated via stiff springs. Consider a spring between 

% TODO: First describe, then show issues. Remove as much detail as possible. Refer to section on Newton's ODE where applicable to save space.
% Mention that explicit / sympletic Euler methods obviously won't work without tiny time steps and refer to section on integration. Show
% how the implicit integration looks like with stiff springs. Show where the numerical issues arise.

High stiffness values lead to large forces which in turn cause numerical issues in the solver. 

We demonstrate these issues based on the example of maintaining a desired distance between two points using a stiff 
spring \cite{tournier2015}. Let $\bm{x_1, x_2}$ be the positions, $\bm{v_1, v_2}$ the velocities and $\bm{a_1, a_2}$
be the accelerations of the two particles. Let $\overline{l}$ be the rest length and $l = \lVert \bm{x_1} - \bm{x_2} \rVert$ 
be the current length of the spring with stiffness $k$. It can be shown that the force that the spring applies at each particle
is equal to $\bm{f_1} = -\bm{f_2} = \lambda\bm{u}$, where $\bm{u} = (\bm{x_1} - \bm{x_2}) / l$
and $\lambda = -\frac{\delta V}{\delta l} = k(\overline{l} - l)$. 

Once the forces, accelerations, velocities and positions are combined into vectors $\bm{f}, \bm{a}, \bm{v}, \bm{x}$, 
respectively, the motions of the system can be modeled via Newton's Ordinary Differential Equation (ODE) $\bm{f} = \bm{Ma}$,
where $\bm{M}$ is a $n_d \times n_d$ diagonal matrix and $n_d$ is the total number of independent degrees of freedom for the 
particles. \textcolor{red}{Explain Newton's ODE elsewhere and refer to it here.}

This system can be integrated via the symplectic Euler method as follows \textcolor{red}{(I believe this should be moved into
the section on numerical integration...)}:

\begin{align*}
    \bm{v_{n+1}} &= \bm{v_n} + h\bm{a_n} \\
    \bm{x_{n+1}} &= \bm{x_n} + h\bm{v_{n+1}}
\end{align*}

As the stiffness $k$ of the spring increases, so does the magnitude of the acceleration $\bm{a}$. Consequently, the integration
diverges unless the timestep is prohibitively small. The stability issues are often addressed by switching to an implicit 
integration scheme, such as the backward Euler method \cite{baraff1998} \textcolor{red}{(refer to the section on numerical 
integration here)}. Replacing current accelerations with future accelerations requires the solution of the following linear 
system of equations (LSE):

\[
    (\bm{M} - h^2\bm{K})\bm{v_{n+1}} = \bm{p} + h\bm{f}
\]

where $\bm{p} = \bm{Mv_n}$ is the momentum, and $\bm{K} = \frac{\delta \bm{f}}{\delta \bm{x}}$ is the stiffness matrix. Note that 
$\bm{K}$ is typically non-singular since elastic forces are invariant under rigid body transforms. When using large stiffness 
$k$ for springs, the entries of $\bm{K}$ are large (due to large restorative forces for stiff springs) and dominate the entries 
of the system matrix 

\begin{equation}\label{eq:system-H}
    \bm{H} = \bm{M} - h^2\bm{K}.
\end{equation}

In these cases, $\bm{H}$ will be almost non-singular as well, leading to numerical issues and poor convergence for many solvers. 
Additionally, implicit integration introduces noticable numerical damping \cite{servin2006}.

\textcolor{blue}{This system results from performing the implicit integration and solving the non-linear system via linearization
using the Taylor expansion. Positions can be expressed in terms of velocities and eliminated from the system.}

\subsection{Penalty Forces}\label{ss:penalty-forces}
In \cref{ss:stiff-springs}, the energy was derived from Hooke's Law for springs. However, it is also possible to derive energies from 
geometric displacement functions $\bm{\phi(x)}$ which vanish in the rest configuration. From the displacement functions, quadratic 
potential energies of the form $U(\bm{x}) = \Sigma_i (k / 2) \bm{\phi^2(x)}$, where $k$ is a positive stiffness parameter, are 
constructed \cite{terz1987}. The potential energy $U(\bm{x})$ is zero if the displacement function is satisfied, and greater than 
zero otherwise. The resulting forces are called penalty forces. \textcolor{red}{Make sure to be consistent with naming of potentials
across the thesis.}

Using the geometric displacement function $\bm{\phi_{\text{spring}}(x)} = (\lVert \bm{x_i} - \bm{x_j} \rVert) - l$ with $k_{\text{spring}}$ 
recovers the behavior of a spring with stiffness $k_{\text{spring}}$ (\cref{ss:stiff-springs}). Its displacement function 
$\bm{\phi_{\text{spring}}(x)}$ is satisfied when the distance of the particles $\bm{x_i}, \bm{x_j}$ is equal to a desired rest length $l$. 
By constructing different geometric displacement functions, various properties such as the bending angle between triangles and in-plane 
shearing of triangles can be controlled via the corresponding quadratic energy potentials \cite{baraff1998}. Geometric displacement 
functions with the desired effect are often intuitive and simple to define. However, as the corresponding energy potentials are not physically 
derived, choosing stiffness parameters that correspond to measurable physical properties of the simulated material and orchestrating 
multiple constraints becomes challenging \cite{servin2006, nealen2006}. Additionally, the generated penalty forces do not converge in the 
limit of infinite stiffess, leading to oscillations unless the timestep is reduced significantly \cite{rubin1957}.

\textcolor{blue}{Maybe explain the challenges with penalty forces a bit better! Also read \cite{terz1987, nealen2006, rubin1957}. 
I just skimmed over \cite{terz1987} for now, but want to make sure that I am citing this correctly. The term penalty forces is not used
in the paper, I am just following the trail from \cite{servin2006}. \cite{nealen2006} is a review that might be intersting to read.
\cite{rubin1957} would be really interesting to read for once, just to understand why strong penalty forces oscillate. Is this a
general problem with penalty forces, or is it an issue with the solver?}

\subsection{Hard Constraints}\label{ss:hard-constraints}
The problem of maintaining hard distance constraints between particles can be formulated as a Differential Algebraic Equation (DAE)
\cite{ascher1995, baraff1996}. In this framework, Newton's ODE \textcolor{red}{(reference somewhere)} is handled together with 
algebraic equations that model the constraints on the positions of the system. Distance constraints are typically implemented using 
holonomic constraints 
of the form $\bm{\phi(x)} = 0$. Note that the distance constraint $\bm{\phi}(x)$ is formulated in terms of the particle positions, 
whereas the ODE works on accelerations or velocities. Consequently, the constraints need to be differentiated with respect to time
once or twice so that they can be 
combined with the ODE in terms of velocties or accelerations, respectively. \textcolor{blue}{In xPBD, we go the other way! The ODE
is tanslated so that it is in terms of positions, so that it can be handled together with the constraints. Is there a reason nobody 
bothered to
do this before? What are the challenges here? Is this exactly what xPBD is? Is there a way to view the simplifications made in 
terms of the other frameworks?}. Using $\bm{J} = \frac{\delta \bm{\phi}}{\delta \bm{x}}$, where $\bm{J}$ is a $n_c \times n_d$ matrix
and $n_c$ is the number of scalar constraints, this leads to the following constraint formulations:

\begin{align*}
    \bm{Jv} &= 0 \\
    \bm{Ja} &= \bm{c(v)}
\end{align*}

for some $\bm{c(v)}$. \textcolor{red}{If you check \cite{ascher1995}, see that $c(v)$ also depends on the positions $q$. That should 
be indicated!} 
Additionally, constraint forces \textcolor{red}{(use internal forces, more general and will be used throughout the thesis)} are 
required in order to link the algebraic constraint equations with the ODE describing the motion of 
the system. It can be shown that the constraint forces $\bm{f_c}$ applied to the particles have to be in the following form in order to 
avoid adding linear and angular momentum to the system \cite{baraff1996}:

\begin{equation}\label{eq:constraint-forces}
    \bm{f_c} = \bm{J^T \lambda}
\end{equation}

where the $\lambda$ are the Lagrange multipliers of the constraints. With external forces $\bm{f}_{\text{ext}}$, the DAE can now be 
expressed as follows 
\cite{ascher1995}:

\[
    \begin{pmatrix}
        \bm{M} & \bm{-J^T} \\
        \bm{J} & 0
    \end{pmatrix}
    \begin{pmatrix}
        \bm{a} \\
        \bm{\lambda}
    \end{pmatrix}
    =
    \begin{pmatrix}
        \bm{f_e} \\
        \bm{c(v)}
    \end{pmatrix}
\]

Note that the lower block-row of the system drives towards accelerations that satisfy the constraints imposed by $\bm{\phi(x)}$ (or, striclty 
speaking, the differentiations thereof) exactly. This is indicated by the lower-right zero block in the system matrix in either formulation. 
Thus, the system does not have a solution if constraints are contradictory. \textcolor{blue}{Aren't $\dot{q} = v$ and $\dot{v} = a$ 
also part of the differential equation? Because $c(v)$ and $f_e$ also depend on $q$!}

In \cite{ascher1995}, the DAE is approached by eliminating the $\lambda$ from the system entirely and constructing an ODE in terms of positions
and velocities. In \cite{tournier2015}, the authors suggest applying implicit integration schemes to the system directly by constructing the 
following Karush-Kuhn-Tucker (KKT) equation system:

\[
\begin{pmatrix}
    \bm{M} & \bm{-J^T} \\
    \bm{J} & 0
\end{pmatrix}
\begin{pmatrix}
    \bm{v_{n+1}} \\
    \bm{\mu_{n+1}}
\end{pmatrix}
=
\begin{pmatrix}
    \bm{p} + h\bm{f_e} \\
    0
\end{pmatrix}
\]

Here, the external forces $\bm{f}_{\text{ext}}$ and the constraint gradients $\bm{J}$ are considered constant across the timestep 
and $\bm{J(x_{n+1})}$ 
is not approximated using the Taylor expansion like it is in \cite{baraff1998}. If internal forces are taken into account, the upper-left 
matrix $\bm{M}$ is replaced by the matrix $\bm{H}$ from \cref{eq:system-H}.

\textcolor{blue}{Reverse-engineering how the authors arrived at this system is quite enlightening. Start out from the equations of motion 
\cite{ascher1995}
    \begin{align*}
        \dot{\bm{v}} &= \bm{M^{-1}(f - J^T) \lambda}
    \end{align*}
    and perform implicit integration:
    \begin{align*}
        \bm{v_{n+1}} &= \bm{v_n} + h\bm{M^{-1}(f_e(x_{n+1})} - \bm{J^T(x_{n+1})\lambda(x_{n+1}))} \\
        \bm{Mv_{n+1}} &= \bm{p} + h\bm{f_e(x_{n+1})} - h\bm{J^T(x_{n+1})\lambda(x_{n+1})} \\ 
        \bm{Mv_{n+1}} + h\bm{J^T(x_{n+1})\lambda(x_{n+1})} &= \bm{p} + h\bm{f_e(x_{n+1})} \\ 
        \bm{Mv_{n+1}} + \bm{J^T(x_{n+1}) \mu(x_{n+1})} &= \bm{p} + h\bm{f_e(x_{n+1})}
    \end{align*}
}
\textcolor{red}{If we assume that $\bm{f_e}$ and the constraint gradients $\bm{J}$ are constant across the time step, we arrive at the 
formulation from the paper. For the external forces, which are usually only comprised of gravitational forces, this is not a big 
deal. For the constraint gradients, I am not sure what the ramifications are. In \cite{baraff1998}, the Taylor expansion is performed
which requires the compution of second derivatives over the constraint functions. This is not happening here at all! Is this what 
authors mean when they say that the constraints are effectively linearized during one solve, e.g. second page 
of \cite{mueller2020}? Technically, speaking, even if the Taylor expansion is performed, the constraints are linearized, if I 
understand correctly.}

Note that the system matrix is sparse, which can be exploited by sparse-matrix solvers in order to solve the system efficiently
\cite{baraff1996}. Alternatively, the Schur complement can be constructed since the mass matrix in the upper left block is invertible.
This leads to a smaller, albeit less sparse system \cite{tournier2015}:

\[
    \bm{JM^{-1}J^T \mu} = \bm{-JM^{-1}(p + } h \bm{f_e)}
\]

If the constraints are not redundant, $\bm{JM^{-1}J^T}$ is non-singular and symmetric positive definite \cite{baraff1996}, which are desirable
properties for many solvers. According to \cite{servin2006}, the common approaches for linearizing the constraint forces and stabilizing 
the constraints $\bm{\phi(x)} = 0$ are notoriously unstable \textcolor{red}{(I need to look this up again. I do not understand what exactly 
this means anymore)}. Additionally, instabilities in the traverse direction of the constraints occur when the tensile force with respect to 
particle masses is large when using hard constraints \cite{tournier2015}.

\subsection{Compliant Constraints}\label{ss:compliant-constraints}
By combining ideas from hard constraints (\cref{ss:hard-constraints}) and penalty forces (\cref{ss:penalty-forces}), it is possible to 
formulate the system matrix for hard constraints such that constraints do not have to be enforced exactly. In this approach, called compliant 
constraints, the constraints are combined with Newton's ODE (\cref{eq:newton-ode}) in a way that allows relaxation of constraints in a 
physically meaningful manner \cite{servin2006}. The key insight is that constraints 
of the form $C_j(\bm{q})$ are the physical limit of strong forces from potentials of the form $\frac{k_j}{2}C_j(\bm{q})^2$ with 
high stiffness values $k_j$ \textcolor{red}{(Not sure whether I have to repeat again which shape all the quantities have. For now, I don't think 
it is necessary since I refer to \cref{ss:hard-constraints} and \cref{ss:penalty-forces}, where the relevant quantities should have been 
introduced)}. However, 
using large, but finite, stiffness values has adverse affects on the numerical properties of the system matrix 
(\cref{ss:stiff-springs}). Thus, the equations of motion are rewritten in terms of the inverse stiffness. Let $\bm{C} = [C_i, \ldots, C_r]^T$ be 
the vector function whose entries consist of the individual constraint functions $C_j$. The potential energy for $\bm{C}$ is then defined as:

\begin{equation}\label{eq:compliant-potential}
    \psi(\bm{q}) = \frac{1}{2}\bm{C}(\bm{q})^T \bm{\alpha}^{-1}\bm{C}(\bm{q})
\end{equation}

\noindent where $\bm{\alpha}$ is a symmetric, positive definite matrix of dimension $n_c \times n_c$ \textcolor{red}{(If I recall correctly, 
$\alpha$ can only
ever be a matrix if we are dealing with constraints that map to vectors. This will never be the case in this thesis, so the formulation should
be adapted so that $\bm{\alpha}$ is simply a scalar)}. The correspondence to the penalty terms \textcolor{red}{(refer to the appropriate equation)} 
above is the case where $\bm{\alpha}^{-1}$ is a diagonal 
matrix with diagonal entries $\frac{1}{k_j}$ for the stiffness $k_j$ of constraint $C_j(\bm{q})$. The resulting forces are given by 

\begin{equation}\label{eq:compliant-force}
    \bm{f_c} = \nabla \psi(\bm{q}) = -\nabla \bm{C}(\bm{q})^T\bm{\alpha}^{-1} \bm{C}(\bm{q}).
\end{equation}

\noindent In order to replace the large parameters $\bm{\alpha}^{-1}$ with the small 
$\bm{\alpha}$ in the equations of motion, artificial variables $\bm{\lambda} = -\bm{\alpha}^{-1}\bm{C}$ are introduced, yielding 

\begin{equation}\label{eq:compliant-force-lambda}
    \bm{f}_c = \nabla \bm{C}(\bm{q})^T\bm{\lambda}
\end{equation}

\noindent This leads to the following DAE:

\begin{equation}\label{eq:compliant-dae}
\begin{split}
    \bm{\dot{q}} &= \bm{v} \\
    \bm{M\dot{v}} &= \bm{f}_{e} + \nabla \bm{C}(\bm{q})^T\bm{\lambda} \\
    \bm{\alpha}\bm{\lambda}(\bm{q}) &= -\bm{C}(\bm{q})
\end{split}
\end{equation}

\noindent Note, that in the limit of infinite stiffness, the formulation from hard constraints is recovered. 

Usually, the DAE is solved by employing some
numerical integration scheme (\cref{s:numerical-integration}) which eventually requires the solution of a linear system of equations. Here, 
the goal is to arrive at a formulation where the system matrix of the resulting LSE only contains references to the small compliance 
$\bm{\alpha}$ 
instead of the large stiffness $\bm{\alpha}^{-1}$, improving the condition matrix of the system matrix. This is achieved by treating 
$\bm{\lambda} = -\bm{\alpha}^{-1}\bm{C}(\bm{q})$ as an unknown, pulling it out of the system matrix and hiding
all occurrences of the large $\bm{\alpha}^{-1}$ in there. To this end, it is often necessary to make simplifying assumptions suitable for the problem
at hand. As an example, if the DAE is solved via backward differentiation, making the assumption that $\nabla \bm{C}$ is constant across 
the timestep allows pulling $\bm{\lambda}$ out of the system matrix entirely \cite{tournier2015}. The entries of the resulting system matrix 
are small, since they do not depend on the large stiffness terms. Backwards differentiation while assuming that $\nabla \bm{C}$ is 
constant across the time step yields

\[
    -\bm{\alpha\lambda}_{n+1} = \bm{C}(\bm{q}_n)\frac{\bm{\mu}_{n+1}}{h} = -\bm{C}(\bm{q}_{n+1}) \approx -\bm{C}(\bm{q}_n) - h\nabla 
    \bm{C}(\bm{q}_n) \bm{v}_{n+1},
\]

\noindent leading to the following LSE \cite{tournier2015}

\[
\begin{pmatrix}
    \bm{M} & -\nabla \bm{C}(\bm{q}_n)^T \\
    \nabla \bm{C}(\bm{q}_n) & \frac{1}{h^2}\bm{\alpha}
\end{pmatrix}
\begin{pmatrix}
    \bm{v}_{n+1} \\
    \bm{\mu}_{n+1}
\end{pmatrix}
=
\begin{pmatrix}
    \bm{p} + h\bm{f}_e \\
    - \frac{1}{h}\bm{C}(\bm{q}_n)
\end{pmatrix},
\]

\noindent where $\bm{\mu} = h\bm{\lambda}$.

\textcolor{red}{Regarding the backwards differentiation above, this does not perform the Taylor approximation again. It should be something
like:
\begin{align*}
    C+ \approx C + h\dot{C+} &= C + hJ_+v_+ \\
                                        &\approx C + h(J + h\dot{J})v_+ \\
                                        &= C + h(J + h\frac{\delta J}{\delta x}\frac{\delta x}{\delta t})v_+ \\
                                        &= C + h(J + h\frac{\delta J}{\delta x}v)v_+
\end{align*}
Now, we need second derivatives of the constraints. This can be seen in \cite{baraff1998} and is also mentioned in \cite{servin2006}.
}

This formulation comes with a couple of advantages. Firstly, relaxing the constraints by keeping a finite but large penalty parameter helps
counteracting numerical problems in the presence of over defined or degenerate constraints. Secondly, in the limit of $\bm{\alpha} = \bm{0}$ 
the behavior of hard constraints is recovered in an elegant fashion. Lastly, in comparison to penalty forces, 
entries of large magnitudes in the system matrix due to high stiffness terms are exchanged for small entries in terms of inverse stiffness, 
which improves the condition number of the matrix. 

\textcolor{red}{
    All these concepts from numerics are a bit unclear to me. I might have to go back to some textbook and do some reading to improve my understanding. 
    I might have to go back to some textbook and do some reading to improve my understanding. Not sure the last part is entirely true.}

\textcolor{red}{
    In \cite{servin2006}, a solver based on symplectic Euler which does not require second derivatives is derived. I do not understand some of the
    estimations made in that derivation. In particular the mean of a function $f$ over and interval $(a, b)$ is defined as $\frac{1}{b-a}
    \int_a^b f(x) dx$, so what they are saying does not make a lot of sense.}

\section{Position Based Dynamics}\label{s:pbd}
As discussed in \cref{s:newton-ode}, classical approaches for dynamics simulation are force-based. Forces are accumulated and resulting accelerations
are computed based on Newton's second law. These accelerations are then integrated over time, typically using one of various numerical integration
schemes. If successful, this strategy yields physically accurate results. However, designing integration schemes that are robust and stable,
particularly in the presence of stiff forces, is challenging. Corresponding issues often manifest themselves in the context of contact and collision 
handling. In real-time applications, physically accurate results are often not required. Thus, algorithms that yield visually
plausible simulations in a robust and stable manner are preferred. Position Based Dynamics (PBD) \cite{mueller2006} addresses these needs by 
manipulating positions directly on a per-constraint basis without integrating accelerations or velocities. This way, collisions can simply be handled 
one-by-one by projecting particles to valid locations instead of by integrating accelerations from stiff forces, leading to improved robustness and 
controllability. 

The main drawback of PBD is that constraints become arbitrarily stiff when the iteration count is increased or when the timestep is decreased.
Macklin et al.\ \cite{macklin2016} devise an extension of PBD called extended Position Based Dynamics (xPBD) that is derived from the implicit
integration of Newton's ODE with constraint potentials based on PBD constraints. The overall structure of the PBD algorithms is preserved with 
minor changes to the projection of individual constraints. xPBD reduces the coupling of stiffness to iteration count and time step and relates 
constraints to corresponding, well-defined constraint forces. According to Macklin et al.\ , xPBD and PBD are equiivalent in the limit of infinite
stiffness. 

Since PBD and xPBD only differ in the way individual constraints are projected, we give a general overview over PBD-style algorithms 
in \cref{ss:pbd-framework}. 
The details of individual constraint projection in PBD and xPBD are covered in \cref{ss:pbd-constraint-projection} and 
\cref{ss:xpbd-constraint-projection}, respectively.

\subsection{Overview Over the PBD Framework}\label{ss:pbd-framework}
Both PBD and xPBD share the same algorithmic structure. Let a dynamic object be defined by a set of $m$ 
vertices with inverse masses $w_i$, positions $\bm{q}_i$ and velocities $\bm{v}_i$. Additionally, the motion of the object is governed by 
$r \in \mathbb{N}$ constraints of the form 

\[
C \colon \mathbb{R}^{3m} \to \mathbb{R}, \bm{q} \mapsto C(\bm{q})
\]

\noindent where $j$ is the constraint index. Note how constraints are defined solely in terms of particle positions. Equality and inequality constraints 
are satisfied if $C(\bm{q}) = 0$ and $C(\bm{q}) \geq 0$, respectively. In PBD, each constraint has an additional stiffness parameter $k_j \in [0,1]$. 
Each constraint has a cardinality $n_j \in \mathbb{N}$ and particle indices $i_1, \ldots, i_{n_j}$ of particles that actively contribute to the 
constraint value. In other words, for $l \in [1, \ldots, r]$ with $l \notin \{i_1, \ldots, i_{n_j}\}$ it is $\nabla_{\bm{p}_l}C_j(\bm{q}) = \bm{0}$.

An overview over the PBD framework is given in \cref{alg:pbd} \cite{mueller2006}. PBD and xPBD work by moving the particles according to their current 
velocities and the external forces acting on them and using the resulting positions as a starting point for constraint projection. This is achieved by 
performing symplectic Euler integration (lines 3-4). The resulting positions 
are projected onto the constraint manifolds of the constraints (line 5). Projecting a constraint means changing the positions of involved particles 
such that the constraint is satisfied and linear and angular momentum are preserved. The projected positions are used to carry out an implicit 
velocity update (line 7) and eventually passed on to the next time step (line 8) in correspondence with a Verlet integration step. Note that the only
difference between PBD and xPBD is the constraint projection in \textsc{projectConstraints} (line 5).

For general, non-linear constraints, moving the initial estimates from the symplectic Euler integration to positions that satisfy the constraints
requires solving a non-linear system of equations. Solving this system of equations is further complicated by the presence of inequality constraints, which
need to be added or removed depending on whether they are satisfied during the current iteration. Thus, Mller et al.\ \cite{mueller2006} opt for a 
non-linear adaptation of the Gauss-Seidel solver in their original PBD solver. Macklin et al.\ \cite{macklin2016} adapt this approach in xPBD. 
Just like the original Gauss-Seidel algorithm, which is only suitable for linear systems of equations, 
constraints are solved independently one after another. During each constraint solve, only the particles that contribute to the current constraint are
moved while all the other particle positions remain untouched. Additionally, position updates from the projection of a constraint are immediately 
visible during the projection of the constraints following thereafter. Inequality constraints that are already satisfied are simply skipped. 
During each solver iteration, all constraints are cycled through once.

\begin{algorithm}
\caption{Position Based Dynamics Framework}\label{alg:pbd}
\begin{algorithmic}[1]
\Procedure{solvePBD}{$\bm{q}_n$, $\bm{v}_n$, $f_{\text{ext}}$, $h$}
\State $\bm{q} = \bm{q}_n, \bm{v} = \bm{v}_n$
\State \textbf{for} all vertices $i$ \textbf{do} $\bm{v}_i = \bm{v}_i + hw_i\bm{f}_{\text{ext}}(\bm{x}_i)$
\State \textbf{for} all vertices $i$ \textbf{do} $\bm{p}_i = \bm{q}_i + h\bm{v}_i$
\State $\textsc{projectConstraints}(C_1, \ldots, C_r, \bm{p}_1, \ldots, \bm{p}_m)$ (\cref{alg:pbd-solver} for PBD, 
\StatexIndent[2] \cref{alg:xpbd-solver} for xPBD)
\For{all vertices $i$}
\State $\bm{v}_i = (\bm{p}_i - \bm{q}_i) / h$
\State $\bm{q}_i = \bm{p}_i$
\EndFor
\State \textbf{return with } $\bm{q}_{n+1} = \bm{q}, \bm{v}_{n+1} = \bm{v}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Due to the fact that PBD is a geometrical method that is not derived from Newton's laws of motion (\cref{ss:pbd-constraint-projection}) and that 
constraints are solved locally one after each 
other, Mller et al.\ \cite{mueller2006} take great care that projections for internal constraints, i.e.\ constraints that are independent of rigid-body 
motion, preserve linear and angular momentum. Otherwise, internal constraints may introduce ghost forces which manifest themselves in artificial 
rigid-body motion \cite{mueller2006}. Of course, non-internal constraints such as collision or 
attachment constraints may have global effects on an object. For internal constraints, it is easy to show that both momenta are automatically preserved 
if the PBD position updates are performed in the direction of the the mass-weighted constraint gradient \cite{mueller2006}. Even though xPBD -- unlike 
PBD -- is in fact derived from Newton's second law, Macklin et al.\ \cite{macklin2016} arrive at position updates that are multiples of the mass-weighted 
constraint gradient as well after a couple of simplifying assumptions (\cref{ss:xpbd-constraint-projection}). Thus PBD and xPBD projections 
are performed along the same direction and only differ in their scaling factors. The update formulas for a single constraint update in PBD and xPBD are 
derived in \cref{ss:pbd-constraint-projection} and \cref{ss:xpbd-constraint-projection} and the resulting algorithms for projecting all constraints 
acting on simulated bodies are given in \cref{alg:pbd-solver} and \cref{alg:xpbd-solver}, respectively.

\subsection{PBD Constraint Projection}\label{ss:pbd-constraint-projection}

Mueller et al.\ \cite{mueller2006} derive the projection of a single constraint in PBD as follows. Let $C$ be a constraint of cardinality $n_c$ 
acting on particles $i_1, \ldots, i_{n_c}$ with predicted positions $\bm{p}_{i_1}, \ldots, \bm{p}_{i_{n_c}}$. Let $k_c$ be the constraint 
stiffness. The goal is to find a position update $\Delta \bm{p}$ such that 

\begin{equation}\label{eq:pbd-delta}
    C(\bm{p} + \Delta \bm{p}) = 0.
\end{equation}

\noindent In order to preserve linear and angular momenta, $\Delta \bm{p}$ is required to be in the direction of the mass-weighted constraint 
gradient, or formally

\begin{equation}\label{eq:pbd-update-general}
    \Delta \bm{p} = \lambda \bm{W} \nabla C(\bm{p})
\end{equation}

\noindent for some $\lambda \in \mathbb{R}$ and $\bm{W} = diag(w_1, w_1, w_1, \ldots, w_m, w_m, w_m)$. 
Plugging into $\cref{eq:pbd-delta}$ and approximating by first-order Taylor expansion yields

\[
    C(\bm{p} + \lambda \bm{W} \nabla C(\bm{p})) \approx C(\bm{p}) + \nabla C(\bm{p})^T \lambda \bm{W}
    \nabla C(\bm{p}) = 0.
\]

\noindent Solving for $\lambda$ yields

\begin{equation}\label{eq:pbd-lambda}
    \lambda = -\frac{C(\bm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\bm{p}_i}C(\bm{p}) \vert^2 }.
\end{equation}

\noindent Plugging $\lambda$ into \cref{eq:pbd-update-general} results in the final position update

\begin{equation}\label{eq:pbd-update}
    \Delta \bm{p} = -\frac{C(\bm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\bm{p}_i}C(\bm{p}) \vert^2 } 
    \bm{W}\nabla C(\bm{p}).
\end{equation}

\noindent For the position of a single point $\bm{p}_i$, this gives the update

\begin{equation}\label{eq:pbd-update-individual}
    \Delta \bm{p}_i = -\frac{C(\bm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\bm{p}_i}C(\bm{p}) \vert^2 } 
    w_i \nabla_{\bm{p}_i} C(\bm{p})
\end{equation}

Finally, the stiffness $k_c$ of the constraint needs to be taken into account. The simplest way is to simply multiply the projection update
$\Delta \bm{p}$ by $k_c$. However, after multiple iterations of the solver, the effect of the stiffness on the update is non-linear. Consider
a distance constraint with rest length 0 acting on predictions $\bm{p}_{i_1}, \bm{p}_{i_2}$ given by

\begin{equation}\label{eq:pbd-distance}
    C_{\text{dist}}(\bm{p}) = \vert \bm{p}_{i_1} - \bm{p}_{i_2} \vert.
\end{equation}

\noindent Then, after $n_s$ solver iterations the remaning error is going to be $\vert \bm{p}_{i_1} - \bm{p}_{i_2} \vert (1-k)^{n_s}$. Mller et al.\ 
suggest establishing a linear relationship by multiplying corrections by $k\prime = 1 - (1-k)^{1/n_s}$. This way, the error becomes
$\vert \bm{p}_{i_1} - \bm{p}_{i_2} \vert (1-k)$ after $n_s$ solver iterations. A summary of the constraint solver is given in \cref{alg:pbd-solver}.

\begin{algorithm}
\caption{PBD Constraint Solver}\label{alg:pbd-solver}
\begin{algorithmic}[1]
\Procedure{projectConstraints}{$C_1, \ldots, C_r, \bm{p}_1, \ldots, \bm{p}_m$}
\For{all iterations $n_s$}
\ForNoDo{all constraints $C_j$ with cardinality $n_j$, } 
\StatexIndent[3] particle indices $i_1, \ldots, i_{n_j}$ \algorithmicdo
\If{$C_j$ is an inequality constraint and $C_j(\bm{p}_j) \geq 0$}
\State \textbf{continue} to next constraint
\EndIf
\For{all particles $i \in \{ i_1, \ldots, i_{n_j} \}$}
\State $\Delta \bm{p}_i = -\frac{C_j(\bm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_j} \}} w_i \vert \nabla_{\bm{p}_i}
C_j(\bm{p}) \vert^2 } w_i \nabla_{\bm{p}_i} C_j(\bm{p})$
\State $\bm{p}_i = \bm{p}_i + k \Delta \bm{p}_i$ or $\bm{p}_i = \bm{p}_i + (1-(1-k)^{1/n_s}) \Delta \bm{p}_i$
\EndFor
\EndFor
\EndFor
\State \textbf{return with result } $\bm{p}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Properties of PBD}\label{ss:pbd-properties}
Due to its simplicity and controllability, PBD is a popular choice for real-time simulations where visually plausible results are sufficient. 
At the core of the PBD algorithm is the non-linear Gauss-Seidel type solver for constraint projections. Immediately making position
updates from one constraint projection visible in the following constraint projections enables faster propagation of 
constraints through the simulated body \cite{mueller2006}. However, the same property makes parallelization of the constraint projections 
in lines 8-9 of \cref{alg:pbd-solver}
more challenging. Synchronization is required to make sure that constraints that involve the same particle do not run into race conditions. 
Alternatively, graph coloring algorithms where constraints of different colors are guaranteed to work on separate sets of particles can be employed
\textcolor{red}{(citation needed!)}. Due to the fact that constraints are handled individually, the solver is incapable of finding a 
compromise between contradicting constraints \cite{mueller2006, bouaziz2014}. In fact, oscillations can occur in over-constrainted situations. 
The exact result depends on the order in which constraints are handled.

The position update due to a single constraint $C$ in \cref{eq:pbd-update} is related to the Newton-Raphson method for finding roots of non-linear 
functions $f \colon \mathbb{R} \to \mathbb{R}$ \cite{mueller2006}. There, the current guess $x_i \in \mathbb{R}$ for a root of $f$ is refined 
using the following update formula \textcolor{red}{(Citation needed? Falls into the curriculum of a B.Sc.\ )}

\begin{equation}\label{eq:newton-raphson}
    x_{i+1} = x_i - \frac{f(x_i)}{f\prime(x_0)}.
\end{equation}

\noindent Indeed, applying the Newton-Raphson update to 

\begin{equation}\label{eq:newton-raphson-f}
    f \colon \mathbb{R} \to \mathbb{R}, \lambda \mapsto C(\bm{p} + \lambda \bm{W} \nabla C(\bm{p}))
\end{equation}

\noindent yields

\[
    \lambda_{i+1} = \lambda_i - \frac{C(\bm{p} + \lambda_i \bm{W} \nabla C(\bm{p}))}
    {\nabla C(\bm{p} + \lambda_i \nabla C(\bm{p}))^T \bm{W} \nabla C(\bm{p})}.
\]

\noindent and with $\lambda_0 = 0$ we arrive at 

\[
    \lambda_1 = -\frac{C(\bm{p})}{\nabla^T C(\bm{p}) \bm{W} \nabla C(\bm{p})}
    = - \frac{C(\bm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_c} \}} w_i \vert \nabla_{\bm{p}_i} C(\bm{p}) \vert^2}.
\]

\noindent Note that this is exactly the same as the $\lambda$ used in the constraint solver given in \cref{eq:pbd-lambda}. Thus, a single 
constraint projection corresponds to the first iteration of the Newton-Raphson method applied to \cref{eq:newton-raphson-f} with 
$\lambda_0 = 0$. The correspondence breaks down if $\lambda_0 \neq 0$ or if multiple position updates are performed consecutively for the 
same constraint.

Mller et al.\ \cite{mueller2006} claim that PBD is unconditionally stable since the projected positions $\bm{p}_i$ computed by the constraint 
solver are physically valid in the sense that all constraints are satisfied and no extrapolation into the future takes place in lines 7-8 of
\cref{alg:pbd}. They further state that the only source of instabilities is the constraint solver itself, which is based on the Newton-Raphson 
method. The position updates in \cref{eq:pbd-update-individual} are independent of the time step and solely depend on the shape of the
constraints. At this point, it is worth taking into consideration that the constraint solver does not always succeed at moving particles to 
physically valid
positions as implied. As mentioned above, oscillations can occur if there are contradictory constraints and constraint projections that are 
performed towards the end might undo progress achieved by previous projections. Additionally, we have shown above that a single constraint 
projection corresponds to the first iteration of a Newton-Raphson method with initial guess $\lambda_0 = 0$. For highly non-linear constraints, 
it cannot be expected that the positions are moved onto or even close to the constraint manifold of interest after a single linearization. 
Lastly, for general non-linear constraints, it is the shape of the constraint at the current configuration that matters for the stability of 
the position update. Whether a Newton-Raphson iteration is effective or not cannot be answered for a function -- or in this case for a 
constraint -- in its entirety, but in the proximity of specific values.

The main disadvantage of PBD is the fact that the stiffness depends on the iteration count and the chosen timestep \cite{mueller2006}. Again, 
we take a look at
a distance constraint with rest length 0 (\cref{eq:pbd-distance}). As discussed in \cref{ss:pbd-constraint-projection}, the remaining error after
$n_s$ solver iterations is simply $\vert \bm{p}_{i_1} - \bm{p}_{i-2} \vert (1-k)^{n_s}$. In the limit of infinite iterations

\[
    \lim_{n_s \to \infty} (\vert \bm{p}_{i_1} - \bm{p}_{i-2} \vert (1-k)^{n_s}) = 0,
\]

\noindent meaning that the distance constraint becomes infinitely stiff, regardless of the exact value of $k_c$. If instead $k\prime 
= 1 - (1-k)^{1/n_s}$ is used, then the error after $n_s$ solver iterations becomes $\vert \bm{p}_{i_1} - \bm{p}_{i_2} \vert (1-k)$. Thus,
infinite stiffness due to large iteration counts is prevented in this setting. However, the perceived stiffness still depends on the time
step. In the limit of infinitely short time steps, the material is going to appear infinitely stiff. 

While the simulated object's global linear and angular momentum are preserved, the linear momentums of individual particles are at risk of 
being washed out by the PBD constraint solver \cite{bouaziz2014}. This is because even though the structure of the position updates 
preserves global momentum, there is no punishment for moving individual particles away from their intertial positions. Generally, the 
penalty for moving particles away from their inertial positions should increase with growing particle masses. However, in the PBD
position update in \cref{eq:pbd-update-individual} it is only the ratio of the particle masses that matters. This can be seen by multiplying
all inverse masses $w_i$ in \cref{eq:pbd-update-individual} with a constant factor $a \in \mathbb{R}^+$:

\begin{align*}
    \Delta \bm{p}_i 
    &= -\frac{C(\bm{p})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} aw_j \vert \nabla_{\bm{p}_j}C(\bm{p}) \vert^2 } aw_i \nabla_{\bm{p}_i} C(\bm{p}) \\
    &= -\frac{C(\bm{p})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} \frac{aw_j}{aw_i} \vert \nabla_{\bm{p}_j}C(\bm{p}) \vert^2 } \nabla_{\bm{p}_i} C(\bm{p}) \\
    &= -\frac{C(\bm{p})}{\sum_{j \in \{ i_1, \ldots, i_{n_c} \}} \frac{w_j}{w_i} \vert \nabla_{\bm{p}_j}C(\bm{p}) \vert^2 } \nabla_{\bm{p}_i} C(\bm{p})
\end{align*}

\noindent Note that the factor $a$ gets cancelled out, meaning that increasing or decreasing the weights of all particles in the simulation by a constant
factor does not affect position updates. Washing out of individual momentums also becomes evident in the limit of infinite iterations while multiplying 
with the stiffness $k_c$ directly, or in the limit of infinitely short time steps. In both cases, the simulated material will appear infinitely stiff, 
meaning that momentums of individual particles are not necessarily preserved.

\subsection{xPBD Constraint Projection}\label{ss:xpbd-constraint-projection}
The derivation of xPBD \cite{macklin2016} starts from an implicit position-level time discretization of Newton's ODE 
(\cref{eq:implicit-positional-detailed}), which is restated here again for the sake of convenience

\begin{equation}\label{eq:implicit-positional-detailed-2}
    \bm{M}(\bm{q}_{n+1} - \bm{q}_n - h\bm{v}_n) = h^2(\bm{f_\text{ext}} - \sum_j \nabla \psi_j(\bm{q}_{n+1})).
\end{equation}

\noindent Let $m$ be the number of particles in the simulated body and $r$ be the number of conservative potentials $\psi_j$ with $j \in [1, r]$.
In the context of xPBD, $\bm{q}, \bm{v}, \bm{f}_{\text{ext}} \in \mathbb{R}^{3m}$ and $\psi_j \colon \mathbb{R}^{3m} \to \mathbb{R}$. Simple 
manipulation of \cref{eq:implicit-positional-detailed-2} yields

\begin{equation}\label{eq:implicit-positional-detailed-3}
    \bm{M} \left( \bm{q}_{n+1} - \bm{\tilde{q}} \right) = - h^2 \sum_j \nabla \psi_j(\bm{q}_{n+1}),
\end{equation}

\noindent where $\bm{\tilde{q}} = \bm{q}_n + h\bm{v}_n + h^2 \bm{M}^{-1} \bm{f}_{\text{ext}}$ is the predicted, inertial position. XPBD builds on
top of the compliant constraint formulation discussed in \cref{ss:compliant-constraints}. The key results relevant to the derivation are restated
here again. In the compliant constraint framework each $\psi_j$ can be written in terms of some positional constraint function $C_j$ 

\begin{equation}\label{eq:xpbd-potential-j}
    \psi_j(\bm{q}) = \frac{1}{2} \alpha^{-1}_j C_j(\bm{q})^2,
\end{equation}

\noindent where $\alpha_j$ is the inverse stiffness of the constraint. If the constraint functions are grouped into a vector-valued function
$\bm{C}$ with $\bm{C}(\bm{q}) = [C_1(\bm{q}), \ldots, C_r(\bm{q})]^T$ and the inverse stiffnesses are aggregrated into the diagonal matrix
$\bm{\alpha} = \text{diag}(\alpha_1, \ldots, \alpha_r)$, then

\begin{equation}\label{eq:xpbd-potential}
    \psi(\bm{q}) \coloneq \sum_j \psi_j(\bm{q}) = \frac{1}{2}\bm{C}(\bm{q})^T \bm{\alpha}^{-1} \bm{C}(\bm{q}).
\end{equation}

\noindent where $\psi$ is the combined internal energy potential. The force from the internal potential is given by

\begin{equation}\label{eq:xpbd-internal-force}
    \bm{f}_{\text{int}} = -\nabla \psi(\bm{q}) = -\nabla \bm{C}(\bm{q})^T \bm{\alpha}^{-1} \bm{C}(\bm{q}).
\end{equation}

\noindent Plugging the internal force $\bm{f}_{\text{int}}$ into \cref{eq:implicit-positional-detailed-3} and pulling $h^2$ into the 
compliance matrix $\bm{\alpha}$ results in

\[
    \bm{M}(\bm{q}_{n+1} - \bm{\tilde{q}}) = - \nabla C(\bm{q}_{n+1})^T \bm{\tilde{\alpha}}^{-1} \bm{C}(\bm{q}_{n+1}),
\]

\noindent where $\bm{\tilde{\alpha}} = \frac{\bm{\alpha}}{h^2}$. Now, the internal force $\bm{f}_{\text{int}}$ is split into a directional 
and a scalar component by introducing the Lagrange multiplier

\begin{equation}\label{eq:lagrange-multiplier}
    \bm{\lambda} = -\bm{\tilde{\alpha}\bm{C}(\bm{q})}
\end{equation}

\noindent according to the compliant constraint formulation by Servin et al.\ \cite{servin2006}. This leads to the following non-linear system
of equations in terms of $\bm{q}_{n+1}$ and $\bm{\lambda}_{n+1}$:

\begin{align}
    \bm{M}(\bm{q}_{n+1} - \bm{\tilde{q}}) - \nabla (\bm{q}_{n+1})^T \bm{\lambda}_{n+1} &= \bm{0} \label{eq:xpbd-g} \\
    \bm{C}(\bm{q}_{n+1}) + \bm{\tilde{\alpha}}\bm{\lambda}_{n+1} &= \bm{0} \label{eq:xpbd-h}.
\end{align}

\noindent The left-hand side of \cref{eq:xpbd-g} and \cref{eq:xpbd-h} are referred to as $\bm{g}$ and $\bm{h}$, respectively. The non-linear 
system of equations is solved using a fixed-point iteration based on Newton's method. We replace the index $(n+1)$ indicating the current
time step by the index of the current guess in the fixed-point iteration indicated by $(i+1)$ for the sake of clarity. During each iteration, 
guesses $\bm{q}_i, \bm{\lambda}_i$ for a solution of the non-linear system are improved by updates $\Delta \bm{q}, \Delta \bm{\lambda}$ to 
yield new iterates $\bm{q}_{i+1}, \bm{\lambda}_{i+1}$. The updates are determined by solving the following linear system of equations, 
which arises from the linearization of \cref{eq:xpbd-g} and \cref{eq:xpbd-h}:

\begin{equation}\label{eq:xpbd-lse}
    \begin{pmatrix}
        \bm{K} & \bm{-\nabla\bm{C}^T(\bm{q}_i)} \\
        \bm{\nabla \bm{C}(\bm{q}_i)} & \bm{\tilde{\alpha}}
    \end{pmatrix}
    \begin{pmatrix}
        \bm{\Delta \bm{p}} \\
        \bm{\Delta \bm{\lambda}}
    \end{pmatrix}
    = -
    \begin{pmatrix}
    \bm{g}(\bm{q}_i, \bm{\lambda}_i) \\
    \bm{h}(\bm{q}_i, \bm{\lambda}_i)
    \end{pmatrix},
\end{equation}

\noindent Here, $\bm{K} = \frac{\delta \bm{g}}{\delta \bm{q}}(\bm{q}_i)$. At this point, two simplifying assumptions are made.

\textbf{Assumption 1:} Computing $K$ requires evaluating second derivatives of the constraint functions
$C_j$, which is expensive and error-prone. In order to simplify and to re-establish a connection to PBD (\cref{ss:pbd-constraint-projection}), 
Macklin et al.\ \cite{macklin2016} drop geometric stiffness and constraint Hessians by approximating $\bm{K} \approx \bm{M}$. 
According to the authors, this
simplification does not affect the solution that the fixed-point iteration converges to. However, altering the system matrix decreases the 
convergence rate akin to a Quasi-Newton method for solving non-linear systems of equations.

\textbf{Assumption 2:} Macklin et al.\ \cite{macklin2016} further assume that $\bm{g}(\bm{q}_i, \bm{\lambda}_i) = \bm{0}$. If initial guesses
$\bm{q}_0 = \bm{\tilde{q}}$ and $\bm{\lambda}_0 = \bm{0}$ are used, plugging into \cref{eq:xpbd-g} shows that this assumption is trivially
satisfied during the first iteration. To understand the justification for further iterations, it is helpful to take a look at the simplified
version of \cref{eq:xpbd-lse} with both assumptions in place:

\begin{equation}\label{eq:xpbd-simplified-lse}
    \begin{pmatrix}
        \bm{M} & \bm{-\nabla\bm{C}^T(\bm{q}_i)} \\
        \bm{\nabla \bm{C}(\bm{q}_i)} & \bm{\tilde{\alpha}}
    \end{pmatrix}
    \begin{pmatrix}
        \bm{\Delta \bm{p}} \\
        \bm{\Delta \bm{\lambda}}
    \end{pmatrix}
    = -
    \begin{pmatrix}
    \bm{0} \\
    \bm{h}(\bm{q}_i, \bm{\lambda}_i)
    \end{pmatrix}.
\end{equation}

\noindent After the first iteration, the upper row of \cref{eq:xpbd-simplified-lse} is satisfied. Thus, after the first iteration with 
$\bm{q}_0 = \bm{\tilde{q}}$ and $\bm{\lambda}_0 = \bm{0}$, it is

\begin{equation*}
\begin{split}
    \bm{0} = \bm{M}\Delta\bm{q} - \nabla \bm{C}(\bm{q}_0)^T \Delta \bm{\lambda} &= \bm{M}(\bm{q}_1 - \bm{q}_0) - \nabla \bm{C}(\bm{q}_0)^T 
    (\bm{\lambda}_1 - \bm{\lambda}_0) \\
    &= \bm{M}(\bm{q}_1 - \bm{\tilde{q}}) - \nabla \bm{C}(\bm{q}_0)^T \bm{\lambda}_1.
\end{split}
\end{equation*}

\noindent Note how the last term is almost identical to $\bm{g}(\bm{q}_1, \bm{\lambda}_1) = \bm{M}(\bm{q}_1 - \bm{\tilde{q}}) - \nabla 
\bm{C}(\bm{q}_1)^T \bm{\lambda}_1$, the only difference being that $\nabla \bm{C}(\bm{q}_0)^T$ is replaced by $\nabla \bm{C}(\bm{q}_1)^T$. Thus, 
Macklin et al.\ \cite{macklin2016} argue that $\bm{g}(\bm{q}_1, \bm{\lambda}_1) \approx \bm{0}$ as well, as long as $\nabla \bm{C}(\bm{q})$ 
does not change too quickly.

Since the mass matrix $\bm{M}$ in the upper-left block of the system matrix of \cref{eq:xpbd-simplified-lse} is invertible by design, it is possible
to take the Schur complement with respect to $\bm{M}$ to obtain a reduced system in terms of $\Delta \bm{\lambda}$:

\begin{equation}\label{eq:xpbd-schur}
    (\nabla \bm{C}(\bm{q}_i) \bm{M}^{-1} \nabla \bm{C}(\bm{q}_i)^T + \bm{\tilde{\alpha}}) \Delta \bm{\lambda} = -\bm{C}(\bm{q}_i) - 
    \bm{\tilde{\alpha}}\bm{\lambda}_i
\end{equation}

\noindent The position update $\Delta \bm{q}$ can be derived from $\Delta \bm{\lambda}$ via the formula

\begin{equation}\label{eq:xpbd-position-update}
    \Delta \bm{q} = \bm{M}^{-1} \nabla \bm{C}(\bm{q}_i)^T \Delta \bm{\lambda}.
\end{equation}

Up until here, all constraints were handled together during each iteration. In order to make a connection to PBD and to return to the framework of a
non-linear Gauss-Seidel solver \cref{ss:pbd-framework}, it is necessary to specify how to solve a single constraint. To that end we rewrite 
\cref{eq:xpbd-schur} for a single constraint $C_j$ and get the update for its scalar Lagrange multiplier $\lambda_j$ by computing

\begin{equation}\label{eq:xpbd-lambda-j}
    \Delta \lambda_j = \frac{-C_j(\bm{q}_i) - \tilde{\alpha}_j \lambda_{ji}}{\nabla C_j(\bm{q}_i) \bm{M}^{-1} \nabla C_j(\bm{q}_i)^T + \tilde{\alpha}_j}.
\end{equation}

\noindent Here, $\lambda_{ji}$ is the value of the Lagrange multiplier of the $j$-th constraint after the $i$-th solver iteration. The position update for 
a single particle with index $l$ contributing to $C_j$ becomes

\begin{equation}\label{eq:xpbd-position-update-i}
    \Delta \bm{q}_l = w_l \nabla_{\bm{q}_l} \bm{C}_j(\bm{q}_i)^T \Delta \bm{\lambda}_j.
\end{equation}

\noindent The position update remains unchanged from \cref{eq:xpbd-position-update}, but note that $\Delta \bm{\lambda}$ is a scalar once only a single constraint 
$C_j$ is considered. Thus, the position update is a multiple of the mass-weighted gradient, just like in PBD (\cref{eq:pbd-update-individual}).

In summary, we simply compute $\Delta \lambda_j$ via \cref{eq:xpbd-lambda-j} and use it to 
update $\lambda_{j+1} = \lambda_j + \Delta \lambda$ and to determine $\Delta \bm{q}$ via \cref{eq:xpbd-position-update} while solving the $j$-th constraint. 
This leads to a natural extension of the PBD algorithm, where the general structure in \cref{alg:pbd} is preserved. The only changes occur in the 
computation of the scaling factor for the 
mass-weighted constraint gradient in \textsc{projectConstraints} in line 5. The xPBD version of \textsc{projectConstraints} is given in 
\cref{alg:xpbd-solver}. Note that \cref{alg:xpbd-solver} is specified in terms of the projection points $\bm{p}$ or $\bm{p}_i$ instead of the 
positions $\bm{q}$ or $\bm{q}_i$ used in \cref{eq:xpbd-position-update} and \cref{eq:xpbd-lambda-j} in order to maintain notational consistency with the
PBD solver in \cref{alg:pbd-solver}.

\begin{algorithm}
\caption{xPBD Constraint Solver}\label{alg:xpbd-solver}
\begin{algorithmic}[1]
\Procedure{projectConstraints}{$C_1, \ldots, C_r, \bm{p}_1, \ldots, \bm{p}_m$}
\State \textbf{for} all constraints $C_j$ \textbf{do} $\lambda_j = 0$
\For{all iterations $n_s$}
\ForNoDo{all constraints $C_j$ with cardinality $n_j$, particle indices $i_1, \ldots, i_{n_j}$,}
\StatexIndent[3] Lagrange multiplier $\lambda_j$ \algorithmicdo
\If{$C_j$ is an inequality constraint and $C_j(\bm{p}) \geq 0$}
\State \textbf{continue} to next constraint
\EndIf
\State $\Delta \lambda_j = \frac{-C_j(\bm{p}) - \tilde{\alpha}_j \lambda_{j}}{\nabla C_j(\bm{p}) \bm{M}^{-1} \nabla C_j(\bm{p})^T + \tilde{\alpha}_j}$
\State $\lambda_{j} = \lambda_{j} + \Delta \lambda_j$
\For{all particles $i \in \{ i_1, \ldots, i_{n_j} \}$}
\State $\Delta \bm{p}_i = -\frac{C_j(\bm{p})}{\sum_{i \in \{ i_1, \ldots, i_{n_j} \}} w_i \vert \nabla_{\bm{p}_i}C_j(\bm{p}) \vert^2 } w_i 
\nabla_{\bm{p}_i} C_j(\bm{p})$
\State $\bm{p}_i = \bm{p}_i + \Delta \bm{p}_i$
\EndFor
\EndFor
\EndFor
\State \textbf{return with result } $\bm{p}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Properties of xPBD}\label{ss:xpbd-properties}
xPBD is a natural extension of PBD that addresses some of PBD's shortcoming while maintaining the simplicity of the original algorithm. Due to
the similarity of both algorithms, PBD implementations can readily be extended to xPBD at the minor cost of storing an additional variable per 
constraint. 

The derivation of the xPBD constraint projection builds on the concept of compliant constraints developed by Servin et al.\ 
\cite{servin2006}. As discussed in \cref{ss:compliant-constraints}, the compliant constraint formulation often allows handling infinite stiffness by
setting $\bm{\alpha} = \bm{0}$. Indeed, a closer look at the PBD update formula \cref{eq:pbd-update-individual} and the xPBD update formulas
in \cref{eq:xpbd-lambda-j}, \cref{eq:xpbd-position-update-i} reveals that xPBD and PBD are equivalent if the compliance term $\tilde{\alpha}_j$ of 
constraint $C_j$ is zero. This matches with the observation that bodies simulated by PBD are infinitely stiff in the limit of infinite iterations 
(\cref{ss:pbd-properties}). If $\tilde{\alpha}_j \neq 0$, the compliance terms in \cref{eq:xpbd-lambda-j} regularize the constraint in such a 
way that the constraint force is limited and corresponds to the constraint potential \cite{macklin2016}. This addresses the issue of coupling
between iteration count and stiffness in the original PBD algorithm (\cref{ss:pbd-properties}). Since the time step is also baked into 
$\tilde{\alpha}_j$, coupling between time step size and stiffness is also reduced.

Another advantage of the compliant constraint 
formulation is that large stiffness values can be often be hidden inside of the Lagrange multipliers $\bm{\lambda}$ (\cref{eq:lagrange-multiplier}), 
which are then pulled out of the system matrix of resulting LSEs by treating $\bm{\lambda}$ as an unknown. This is also exploited in the xPBD
derivation in \cref{eq:xpbd-lse}. Note how the lower-right block of the system matrix only contains the 
small compliance term $\bm{\tilde{\alpha}}$. Additionally, $\nabla \bm{C}(\bm{q}_i)$ in the lower-left and upper-right blocks should not have 
any large entries since the large stiffness values are pulled out of the constraints in $\cref{eq:xpbd-potential-j}$. However, the upper-left 
block of the system matrix $\bm{K}$ given by 

\begin{equation}\label{eq:xpbd-K}
    \bm{K} = \frac{\delta \bm{g}}{\delta \bm{q}}(\bm{q}_i) = \bm{M} - \frac{\delta \nabla \bm{C}(\bm{q_i})^T \bm{\lambda_i}}{\delta \bm{q}_i}
\end{equation}

\noindent still contains references to $\bm{\lambda}$ which contains the potentially large constraint stiffnesses. Due to the first assumption $\bm{K} 
\approx \bm{M}$, these occurrences of $\bm{\lambda}$ are also removed and the system matrix of the simplified LSE in 
\cref{eq:xpbd-simplified-lse} is specified in terms of small compliances only. As a result, the simplified LSE has favorable numerical properties 
(\cref{ss:compliant-constraints}).

The discussion above highlights the importance of pulling large stiffness values out of the constraints in \cref{eq:xpbd-potential-j}. The potential
$\psi_j(\bm{q}) = \frac{1}{2} \alpha^{-1}_j C_j(\bm{q})^2$ could also be written as $\psi_j(\bm{q}) = \frac{1}{2} C^{\prime}_j(\bm{q})^2$ in terms of 
the alternative constraint function $C^{\prime}_j$ given by

\[
    C^{\prime}_j(\bm{q}) = \alpha^{-1/2}C(\bm{q}).
\]

\noindent However, this would result in large constraint gradients $\nabla \bm{C}^{\prime}(\bm{q}_i)$, meaning that even the system matrix of the simplified LSE
(\cref{eq:xpbd-simplified-lse}) would have large entries.

\begin{itemize}
    \item Discuss the justifications for the assumptions
        \begin{itemize}
            \item Convergence properties of Quasi-Newton methods for NLSE. Hessian approximation eventually needs to be close to the Hessian at the solution
                to guarantee convergence. Whether $\bm{K} \approx \bm{M}$ is difficult to say, but it is clear that pulling out large stiffness terms helps
                with keeping the magnitudes of the entries of $\bm{K}$ small, that the error from the first approximation is kept smaller as well. Either way,
                these convergence properties are for Newton's method where the LSE is solved directly. 
            \item I believe that assumption 1 simply assumes that $\nabla C$ is constant across the time step
            \item Even though constraint gradients don't change too drastically if large stiffness values are pulled out, they appear in a product with 
                $\lambda$, which usually end up being pretty large for constraint gradients. Thus, it is likely that the value of $\bm{g}$ is sensitive
                even to small changes in the constraint gradients (or alternatively small constraint Hessians).
            \item The justification of the second assumption is based on the choice $\bm{q}_0 = \bm{\tilde{q}}, \bm{\lambda} = \bm{0}$. It seems quite obvious
                that $\bm{\lambda} = \bm{0}$ is not a particularly good initial guess if \cref{eq:lagrange-multiplier} is taken into account.
            \item Due to the fact that we assume $\bm{g}(\bm{q}_i, \bm{\lambda}_i) = 0$, all occurrences of $\bm{\tilde{q}}$ are removed from the update
                equations of xPBD. $\bm{\tilde{q}}$ is only used as the initial guess. Due to the compliance terms in the update formulas, the degree to
                which individual momenta can be washed out is reduced. My notes show that increasing masses by a constant factor actually does decrease the
                size of the position updates taken, but the effect is hard to quantify. Still, the masses only affect how mobile a particle is in general,
                without taking directionality into account. Moving towards the initial position should be rewarded, moving away from it should be punished.
                This is not possible if $\bm{\tilde{q}}$ does not appear in the update formulas.
        \end{itemize}
    \item Derivation is based on implicit Euler integration, numerical damping is introduced and depends on the chosen time step. In that sense, the 
        stiffness does stil depend on the time step.
    \item $\lambda$ only correspond to force magnitudes if there the constraint gradients are unit vectors. Tempted to think that if only one type of
        constraints is used, $\lambda$ can still be picked to represent the force magnitude, but this would only be true if the norm of the constraint
        gradients would be constant across the entire domain, which is generally not the case.
    \item General properties of Gauss-Seidel solver apply here again.
\end{itemize}

\section{Projective Dynamics}\label{s:pd}

In the approaches to physical simulations via implicit time integration that we have encountered so far, a new linear system needs to be solved
at every timestep. If the linear system is solved directly, this can quickly become prohibitively expensive for large simulations since 
a new matrix factorization needs to be computed every time a new sytem needs to be solved. In xPBD, this issue is dealt with by using an iterative 
solver. In Projective Dynamics (\emph{PD}\index{PD}), a different approach is used. Energy potentials are restricted to a specific structure which allow for 
efficient implicit time integration via alternating steps of local and global optimization \cite{bouaziz2014}. The local optimization 
steps are comprised of 
per-constraint projections of particle positions onto constraint manifolds. The global optimization step combines the results from the individual 
local projection steps while taking into consideration global effects including inertia and external forces. This is achieved by solving a 
linear system of equations whose system matrix is constant across timesteps. Since the local steps can be carried out in parallel and the 
factorization for the system matrix of the global step can be precomputed and reused, physical simulations that are restricted to energy potentials 
from the PD framework can be solved efficienty.

\subsection{Energy Potentials}\label{ss:pd-potentials}

Let the positions of $m$ particles in a mesh be stored in a matrix $\bm{q} \in \mathbb{R}^{m \times 3}$ with deformation gradient $\bm{F} 
\coloneqq \bm{F(\bm{q})} \in \mathbb{R}^{3 \times 3}$. Then, energy potentials of the general form $\psi(\bm{E}(\bm{F}))$, where 
$\bm{E}(\bm{F})$ is a strain measure that depends on the deformation gradient of a discrete element, are frequently used in nonlinear 
continuum mechanics. If $\bm{E}$ is Green's strain measure $\bm{E_{\text{Green}}}$ defined by 

\[
\bm{E_{\text{Green}}}(\bm{F}) = \frac{1}{2}(\bm{F^TF} - \bm{I})
\]

\noindent then $\bm{E_{\text{Green}}}(\bm{F}) = 0$ is equivalent to $\bm{F^TF} = \bm{I}$. Thus, $\bm{E_{\text{Green}}}(\bm{F}) = 0$ defines a constraint
manifold that accepts deformations whose deformation gradients $\bm{F}$ are rotation matrices. These deformations are exactly the rigid-body 
transforms, i.e. transforms that alter the body's position and orientation but keep the body's volume undeformed. Assuming that $\psi(\bm{0}) 
= \rho$ for some $\rho \in \mathbb{R}$ and that $\psi$ reaches its minimum at the undeformed configuration, then 

\[
    d(\bm{E_{\text{Green}}}(\bm{F})) = \psi(\bm{E_{\text{Green}}}(\bm{F})) - \rho
\]

\noindent can be considered a distance measure of how far the configuration is away from the constraint manifold defined by the undeformed 
configurations. 

The energy potentials in PD are designed to fit into this framework \cite{bouaziz2014}: Energy potentials are defined by a constraint 
manifold $\bm{C}$ -- which 
can be different from $\bm{E_{\text{Green}}(\bm{F})} = 0$ -- and a distance measure $d$ of the body's current configuration to that constraint 
manifold. Formally, this leads to energy potentials which of the 
following form:

\[
    \psi({\bm{q}}) = \min_{\bm{p}} d(\bm{q}, \bm{p}) + \delta_{\bm{C}}(\bm{p}).
\]

\noindent Here, $\bm{p} \in \mathbb{R}^{r \times 3}, r \in \mathbb{N}$ are auxiliary projection variables and $\delta_{\bm{C}}(\bm{p})$ is an indicator function with 

\[
    \delta_{\bm{C}}(\bm{p})= 
\begin{cases}
0,& \text{if } \bm{p} \text{ lies on the constraint manifold } \bm{C}\\
\infty,& \text{otherwise.}
\end{cases}
\]

\noindent Define $\bm{p_{\bm{q}}}$ such that $\psi({\bm{q}}) = d(\bm{q}, \bm{p_{\bm{q}}}) + \delta_{\bm{C}}(\bm{p_{\bm{q}}})$. Then obviously 
$\delta_{\bm{C}}(\bm{p_{\bm{q}}}) = 0$, meaning that $\bm{p_{\bm{q}}}$ lies on $\bm{C}$. Together, $\bm{p_{\bm{q}}}$ is the 
configuration on the constraint manifold $\bm{C}$ with minimal distance $d(\bm{q}, \bm{p_{\bm{q}}})$ to current configuration $\bm{q}$.
Consequently, $\psi(\bm{q})$ measures the distance of $\bm{q}$ to the constraint manifold $\bm{C}$.

The authors claim that since the constraint manifolds already capture nonlinearities the need for complicated distance functions $d$
can be relaxed while still achieving visually plausible simulations \cite{bouaziz2014}. In PD, distance measures $d$ are restricted to 
quadratic functions of the form

\begin{equation}\label{eq:pd-distance-measures}
    d(\bm{q}) = \frac{w}{2} \norm{\bm{Gq} - \bm{p}}^2_F,
\end{equation}

\noindent where $\bm{G} \in \mathbb{R}^{r \times m}$ for some $r \in \mathbb{N}$ and $w$ is the constraint stiffness. In summary, PD 
energy potentials have the following form:

\begin{equation}\label{eq:pd-potentials}
    \psi({\bm{q}}) = \min_{\bm{p}} \frac{w}{2} \norm{\bm{Gq} - \bm{p}}^2_F + \delta_{\bm{C}}(\bm{p}).
\end{equation}

\subsubsection{Example: Strain Energies}\label{sss:pd-strain}
As an elucidating example, we briefly recap how to formulate strain energies in terms of PD energy potentials 
(\cref{eq:pd-potentials}) according to Bouaziz et al.\ \cite{bouaziz2014}. Strain energies measure the change of local variation between 
the deformed and undeformed state. If the simulated body is a 3-manifold simplicial complex, the continuous strain energy can be 
discretized across the tetrahedra according to \textcolor{red}{(refer to appropriate section)}. The energy for a single tetrahedradron
can be approximated in terms of PD energy potentials (\cref{eq:pd-potentials}) by setting $\bm{G} \in \mathbb{R}^{3 \times m}$ to the 
matrix $\bm{A}_i$ that maps $\bm{q}$ to the transpose of the deformation gradient of the tetrahedron $\bm{F}^T$ and $\bm{C}$ to the 
set of rotational matrices SO(3). Typically, the weight $w = kV$, where $V$ is the volume of the undeformed tetrahedron and $k$ is a 
user-defined stiffness value. This yields the following energy potential, which we also call PD strain potential from now on:

\begin{equation}\label{eq:pd-strain}
    \psi({\bm{q}}) = \min_{\bm{p}} \frac{w}{2} \norm{\bm{Aq} - \bm{p}}^2_F + \delta_{\text{SO}(3)}(\bm{p})
    = \min_{\bm{p}} \frac{w}{2} \norm{\bm{F}^T - \bm{p}}^2_F + \delta_{\text{SO}(3)}(\bm{p}).
\end{equation}

\noindent It is easy to show that this energy is zero if and only if $\bm{F}$ itself is a rotational matrix and grows as the 
singular values of $\bm{F}$ move away from 1 \cite{bouaziz2014}. Informally, the energy increases the more the tetrahedron gets 
stretched or squashed. The projection $\bm{p}$ can be computed 
as $\bm{p} = \bm{UIV}^T$ where $\bm{F}^T = \bm{U \Sigma V}^T$ is the singular value decomposition of the inverse deformation 
gradient $\bm{F}^T$.

\subsection{Projective Implicit Euler Solver}\label{ss:pd-solver}
We start by substituting the PD energy potentials (\cref{eq:pd-potentials}) into the variatonal form of implicit Euler integration
(\cref{eq:variational-implicit}). With abuse of notation, let $\bm{p}_j$ denote the auxiliary variable of the $j$-th constraint or 
the family of auxiliary variables $(\bm{p}_j)_{j \in \mathcal{J}}$, where $\mathcal{J}$ is the index set of the 
constraints. This yields the following joint optimization problem over the positions $\bm{q}$ and auxiliary variables $\bm{p}_j$ 

\begin{equation}\label{eq:pd-minimization}
    \min_{\bm{q}, \bm{p}_j} \tilde{g}(\bm{q}, \bm{p}_j) = 
    \min_{\bm{q}, \bm{p}_j} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_j \frac{w_j}{2} \norm{\bm{G}_j\bm{q}
    - \bm{p}_j}^2_F + \delta_{\bm{C}_j}(\bm{p}_j).
\end{equation}

\noindent This optimization problem is optimized using a local/global alternating minimization technique. Local and global steps 
are carried out sequentially for a fixed number of iterations during each timestep. 

The local step consists of minimizing the objective function \cref{eq:pd-minimization} over 
the auxiliary variables $\bm{p}_j$ while keeping the positions $\bm{q}$ fixed. This corresponds to finding the projection points of 
the current positions onto the constraint manifolds used to define the PD energy potentials. Each constraint has its own 
set of auxiliary variables, meaning that the projection steps can be carried out independently. For each energy potential, we solve the 
following minimization problem

\begin{equation}\label{eq:pd-local-minimization}
    \min_{\bm{p}_j} \tilde{g}(\bm{q}, \bm{p}_j) =
    \min_{\bm{p}_j} \frac{w_j}{2}\norm{\bm{G}_j\bm{q} - \bm{p}_j}^2_F + \delta_{\bm{C}_j}(\bm{p}_j).
\end{equation}

In the global step, the minimization problem \cref{eq:pd-minimization} is optimized over the positions $\bm{q}$ while keeping the auxiliary 
variables $\bm{p}_j$ fixed.
This corresponds to moving the positions $\bm{q}$ according to their momentum and external forces while trying to maintain short distances
to the projections points as defined by the distance measures of the PD energy potentials. The optimization problem for the global solve is 
given by

\begin{equation}\label{eq:pd-global-minimization}
    \min_{\bm{q}} \tilde{g}(\bm{q}, \bm{p}_j) =
    \min_{\bm{q}} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_j \frac{w_j}{2} \norm{\bm{G}_j\bm{q} - \bm{p_j}}^2_F.
\end{equation}

\noindent The gradient of the objective function with respect to the positions $\nabla_{\bm{q}} 
\tilde{g}(\bm{q}, \bm{p}_j)$ is given by 

\begin{equation}\label{eq:pd-gradient-q}
    \nabla_{\bm{q}}\tilde{g}(\bm{q}, \bm{p}_j) = \frac{\bm{M}}{h^2}(\bm{q} - \bm{s}_n) + \sum_j w_j \bm{G}^T_j \bm{G}_j \bm{q}
    + \sum_j w_j \bm{G}^T_j \bm{p}_j.
\end{equation}

\noindent By design of the PD energy potentials, the objective function of the global optimization problem is quadratic in the positions 
$\bm{q}$. Consequently, the minimization can be carried out in a single step by picking $\bm{q}$ such that the first-order optimality 
conditions are satisfied \cite{nocedal2006}. This leads to the following system of equations

\begin{equation}\label{eq:pd-global-system}
    (\frac{\bm{M}}{h^2} + \sum_j w_j \bm{G}_j^T \bm{G}_j)\bm{q} = \frac{\bm{M}}{h^2}\bm{s}_n + \sum_j w_j \bm{G}_j^T \bm{p}_j.
\end{equation}

\noindent In the rest of \cref{s:pd} we refer to the system matrix of the global system by 
$\bm{S} \coloneqq \frac{\bm{M}}{h^2} + \sum_j w_j \bm{G}_j^T \bm{G}_j$.

Note that $\bm{S}$ is constant as long as the constraint set remains unchanged. The right side needs to be recomputed in every 
iteration as the projections $\bm{p}_j$ change during the local optimization steps.  An overview over the algorithm is given in \cref{alg:pd}.

\begin{algorithm}
\caption{Projective Implicit Euler Solver}\label{alg:pd}
\begin{algorithmic}
\Procedure{solvePD}{$\bm{q}_n$, $\bm{v}_n$, $f_{\text{ext}}$, $h$}
\State $\bm{s}_n = \bm{q}_n + h\bm{v}_n + h^2\bm{M}^{-1}\bm{f}_{\text{ext}}$
\State $\bm{q}_k = \bm{s}_n$
\For{all iterations}
\For{constraints $j$}
\State $\bm{p}_j = \min_{\bm{p}_j} \frac{w_j}{2}\norm{\bm{G}_j\bm{q_k} - \bm{p}_j}^2_F + \delta_{\bm{C}_j}(\bm{p}_j)$
\EndFor
\State $\bm{q}_{k} \gets$ solution of $\bm{S}\bm{q} = \frac{\bm{M}}{h^2}\bm{s}_n + \sum_j w_j \bm{G}_j^T \bm{p}_j$.
\EndFor
\State \textbf{return with } $\bm{q}_{n+1} = \bm{q}_k, \bm{v}_{n+1} = (\bm{q}_{n+1} - \bm{q}_n) / h$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Properties of Projective Dynamics}\label{ss:pd-properties}
The structure of the PD energy potentials allows for \cref{alg:pd} to be implemented efficiently. Since the constraint projections
in \cref{eq:pd-local-minimization} can be carried out independently, the local optimization step lends itself to massive parallelization. 
Further, because the system matrix $\bm{S}$ is constant its prefactorization can be computed at initialization, enabling
efficient solves of the linear system in the global optimization step. Note that since $\bm{q} \in \mathbb{R}^{m \times 3}$ in \cref{eq:pd-global-system}, 
the global system can be solved independently and in parallel for each coordinate.

The last property follows from the fact that the distance measure $d$ in \cref{eq:pd-distance-measures} has no dependencies between 
$x$-, $y$- and $z$-coordinates. This detail demonstrates that restricting to PD energy potentials comes at the cost of generality: 
Many arbitrary nonlinear elastic potentials, particulary those that have dependencies between $x$-, $y$- and $z$-coordinates, cannot be expressed 
in terms of PD elastic potentials. Additionally, many classical energies like the Neo-Hookean and St.\ Venant-Kirchoff energies do not fit 
into the PD framework \cite{liu2017}. On the other hand, the authors show that various different types of constraints, including strain constraints, 
bending constraints, collisions and positional constraints can be expressed in terms of PD potentials and handled by the PD solver in a 
unified manner \cite{bouaziz2014}. Where applicable, the constraints are derived from continuous energies, leaving them reasonably independent 
to the underlying meshing.

It is also important to note that it is impossible to implement hard constraints via energy potentials. Increasing
the weights of constraints allows approximating hard constraints. However, this comes with adverse effects to the numerical properties of the 
system matrix $\bm{S}$.

While a simplified minimization problem is constructed by restricting to PD energy potentials, the solver does converge to a 
true solution of \cref{eq:pd-minimization}. That means that the solution strikes a balance between preserving 
the momenta of particles while minimizing the energy potentials. The objective function is quadratic, bounded below and both local and 
global steps are guaranteed to weakly decrease it. As a result, the optimization converges without additional safeguards, even if 
non-convex constraint manifolds are used in the energy potentials.

The PD solver (\cref{alg:pd}) performs implicit integration and introduces numerical damping as a result (see \cref{ss:implicit-euler}).
According to \cite{bouaziz2014}, this is particularly severe when the optimization is terminated early and large meshes are used. One possible
explanation is that external forces might not be able to propagate fully through the mesh if the optimization is not run for enough iterations
\cite{bouaziz2014} \textcolor{red}{(Investigate this with experiments!!!)}.

Lastly, it is important to note that the PD solver is not suited for handling frequently changing constraint sets. For example, every time 
a collision is detected, a new constraint needs to be added to the simulation and the global system matrix $\bm{S}$ needs
to be refactorized. This can slow down the PD solver quite significantly and lead to unpredictable solver speeds that are infeasible in the
context of real-time simulations.

\begin{itemize}
    \item \textcolor{red}{Not sure whether comparisons to the Newton solver belong here or not. Leave them as bullet points for now.}
    \item In terms of iterations, of course inferior to a Newton solver since the PD solver only exhibits linear convergence. 
        Either way, after a couple of iterations of the PD solver, the results are visually 
        indistinguishable from the true solution computed by Newton's method.
    \item Simplicity. Much easier than implementing a Newton solver, which requires second derivatives, a line search and possible 
        Hessian modifications if the Hessian is not positive definite. 
\end{itemize}

\subsection{Projective Dynamics as a Special Case of Quasi-Newton Methods}\label{ss:pd-quasi-newton}
In PD, the variational form of implicit Euler integration that results from restricting to PD energy potentials (\cref{eq:pd-minimization}) 
is solved by using a specialized local/global alternating minimization technique (\cref{ss:pd-solver}). If the projection points 
$\bm{p}^j_{\bm{q}}$ with 

\[
    \psi_j({\bm{q}}) = \min_{\bm{p}} \frac{w_j}{2} \norm{\bm{Gq} - \bm{p}}^2_F + \delta_{\bm{C}}(\bm{p})
    = \frac{w_j}{2} \norm{\bm{Gq} - \bm{p}^i_\bm{q}}^2_F
\]

\noindent are considered functions of $\bm{q}$ with $\bm{p}_j(\bm{q}) = \bm{p}^j_{\bm{q}}$, then the equivalent optimization problem

\begin{equation}\label{eq:pd-minimization-q}
    \min_{\bm{q}} g(\bm{q}) = 
    \min_{\bm{q}} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_j \frac{w_j}{2} \norm{\bm{G}_j\bm{q}
    - \bm{p_j}(\bm{q})}^2_F
\end{equation}

\noindent can be solved using general purpose algorithms for unconstrained optimization, including Newton's method (\cref{sss:newton-method}),
the BFGS method (\cref{sss:quasi-newton}) or the L-BFGS method (\cref{sss:limited-memory-quasi-newton}). In fact, it can be shown that
the PD solver applied to \cref{eq:pd-minimization} is a special case of a Quasi-Newton method with constant Hessian approximation 
applied to \cref{eq:pd-minimization-q} \cite{liu2017}. 

The gradient $\nabla g$ of the objective function $g$ from \cref{eq:pd-minimization-q} needs to be computed for all the line search 
methods mentioned above. Liu et al. \cite{liu2017} show that \textcolor{red}{(maybe put the derivation into the appendix)} $\nabla g$ 
is given by

\begin{equation}\label{eq:pd-gradient-qn}
    \nabla g(\bm{q}) = \frac{\bm{M}}{h^2}(\bm{q} - \bm{s}_n) + \sum_j w_j \bm{G}^T_j \bm{G}_j \bm{q}
    + \sum_j w_j \bm{G}^T_j \bm{p}_j(\bm{q}).
\end{equation}

Surprisingly, this is the same as the gradient $\nabla_{\bm{q}} \tilde{g}(\bm{q}, \bm{p}_j)$ of the global optimization problem of the original
PD algorithm (\cref{eq:pd-gradient-q}). Thus, the gradient is unaffected by whether $\bm{p}_j$ is considered constant or a function
$\bm{p}_j(\bm{q})$ of the positions $\bm{q}$. In Newton's method, the search direction for the current iteration $\bm{r}^N_k$ is given
by $-(\nabla^2 g(\bm{q}))^{-1} \nabla g(\bm{q})$, which is a descent direction if $\nabla^2 g(\bm{q})$ is positive definite 
(\cref{sss:newton-method}). In Quasi-Newton methods, the true Hessian $\nabla^2 g(\bm{q})$ is approximated by some positive definite matrix $\bm{B}_k$ 
instead (\cref{sss:quasi-newton}). If $\bm{B}_k = \bm{S}$ -- i.e.\ the system matrix 
(\cref{eq:pd-global-system}) from the global optimization in PD -- is used with step size $\alpha = 1$ the following update is recovered:

\[
    \bm{S}^{-1} \nabla g(\bm{q}) = 
    \bm{q} - (\frac{\bm{M}}{h^2} + \sum_j w_j \bm{G}_j^T \bm{G}_j)^{-1} 
    (\frac{\bm{M}}{h^2}\bm{s}_n + \sum_j w_j \bm{G}_j^T \bm{p}_j(\bm{q}))
\]

\noindent Note that 

\[
    \bm{q}^* \coloneqq \bm{S}^{-1} (\frac{\bm{M}}{h^2}\bm{s}_n + \sum_j w_j 
    \bm{G}_j^T \bm{p}_j(\bm{q}))
\]

\noindent is exactly the solution of the global linear system from PD in \cref{eq:pd-global-system}. Together

\[
    \bm{q}^* = \bm{q} -\bm{S}^{-1} \nabla g(\bm{q}) 
\]

\noindent shows that performing a Quasi-Newton step with Hessian approximation $\bm{B}_k = \bm{S}$ and step size 
$\alpha_k = 1$ on the 
minimization problem in \cref{eq:pd-minimization-q} is equivalent to performing a local/global iteration of the PD solver 
(\cref{alg:pd}). The Quasi-Newton version of PD is summarized in \cref{alg:pd-qn}.

\begin{algorithm}
\caption{Projective Dynamics as a Quasi-Newton Method}\label{alg:pd-qn}
\begin{algorithmic}
\Procedure{solvePDViaQN}{$\bm{q}_n$, $\bm{v}_n$, $\bm{f}_{\text{ext}}$, $h$}
\State $\bm{s}_n = \bm{q}_n + h\bm{v}_n + h^2\bm{M}^{-1}\bm{f}_{\text{ext}}$
\State $\bm{q}_k = \bm{s}_n$
\For{all iterations}
\State $\bm{p}_k \gets$ solution of $\bm{S}\bm{p} = -\nabla g(\bm{q}_k)$
\State $\bm{q}_k = \bm{q}_k + \bm{p}_k$
\EndFor
\State \textbf{return with result } $\bm{q}_{n+1} = \bm{q}_k, \bm{v}_{n+1} = (\bm{q}_{n+1} - \bm{q}_n)/h$
\EndProcedure
\end{algorithmic}
\end{algorithm}

This insight that PD is a special case of Quasi-Newton methods applied to $\cref{eq:pd-minimization-q}$ can be leveraged to
bring performance improvements to the original PD solver and to design a natural extension of PD to energies that do not fit 
into the original PD framework. Both are discussed in \cref{s:qn-rts}.

\section{Quasi-Newton methods for Physical Simulations}\label{s:qn-rts}
In \cref{ss:pd-quasi-newton}, we discussed that the PD solver for the minimization problem \cref{eq:pd-minimization}
can be interpreted as a special case of a Quasi-Newton method with constant Hessian approximation and step size $\alpha = 1$
applied to the corresponding minimization problem \cref{eq:pd-minimization-q}. The minimization problem for the Quasi-Newton
method

\begin{equation}\label{eq:pd-minimization-q2}
    \min_{\bm{q}} g(\bm{q}) = 
    \min_{\bm{q}} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_j \frac{w_j}{2} \norm{\bm{G}_j\bm{q}
    - \bm{p_j}(\bm{q})}^2_F
\end{equation}

\noindent and the global system matrix $\bm{S}$ which is used as the constant Hessian approximation

\begin{equation}\label{eq:global-matrix}
    \bm{S} \coloneqq \frac{\bm{M}}{h^2} + \sum_j w_j \bm{G}_j^T \bm{G}_j  
\end{equation}

\noindent are stated here once more for convenience.

As the Hessian matrix $\nabla^2 g(\bm{q}_k)$ generally changes between iterations, the Hessian approximations of the 
BFGS (\cref{sss:quasi-newton}) and L-BFGS method (\cref{sss:limited-memory-quasi-newton}) do so as well.
This is in contrast to the constant Hessian approximation $\bm{S}$, which does not incorporate local curvature information
at the current iterate at all. Combining both approaches in order to accelerate convergence is discussed 
in \cref{ss:qn-pd}.

Since Quasi-Newton methods can be applied to the variational form of 
implicit Euler integration with general conservative energy potentials (\cref{eq:variational-implicit}), this suggests a 
natural extension of the approach mentioned above to energies that do not fit into the original PD framework. However,
if general conservative energy potentials are used, it is not obvious how to construct the initial Hessian approximation
$\bm{S}$ anymore. Liu et al.\ suggest a way to emulate the global system matrix $S$ for energies that can be written in
the Valanis-Landel form, which includes Neo-Hookean and St.\ Venant-Kirchoff energies. This extension is covered in 
\cref{ss:qn-valanis-landel}

\subsection{Quasi-Newton Methods for PD Energy Potentials}\label{ss:qn-pd}
As discussed in \cref{sss:quasi-newton}, 
the choice of the initial inverse Hessian approximation $\bm{H}_0$ has a strong impact on the performance of Quasi-Newton
methods such as the BFGS and L-BFGS method. Popular choices like scaled versions of the identitiy matrix generally do not
satisfy any formal optimality conditions but are picked heuristically instead. This suggests that finding more suitable 
candidates for $\bm{H}_0$ -- or alternatively for $\bm{B}_0$ -- is an avenue towards improving the convergence properties of 
Quasi-Newton methods. It stands to reason that due to its effectiveness in PD, $\bm{S}$ is a viable choice for the 
initial Hessian approximation $\bm{B}_0$ for the minimization of \cref{eq:pd-minimization-q2} \cite{liu2017}. From the lens
of the Quasi-Newton version of the PD solver (\cref{alg:pd-qn}), benefits of incorporating local curvature information into
the constant Hessian approximations $S$ by applying BFGS or L-BFGS updates are to be expected.

Due to its favorable space complexity over the BFGS method for large-scale problems (see \cref{sss:limited-memory-quasi-newton}), 
Liu et al.\ focus on the L-BFGS method with $\bm{B}_0 = \bm{S}$ \cite{liu2017}. This leads to the algorithm that is laid out in
\cref{alg:pd-lbfgs}. The occurrences of $f$ in the two-loop recursion (\cref{alg:lbfgs-recursion}) need to be replaced by $g$ 
in the appropriate places. Again, the details of maintaining the history of $\bm{s}, \bm{y}, \rho$ are omitted for the sake of clarity.

\begin{algorithm}
\caption{L-BFGS method for PD energies}\label{alg:pd-lbfgs}
\begin{algorithmic}[1]
\State \textbf{require } $\beta \in (0, 1)$, $t \in (0, 1)$
\Procedure{solvePDViaLBFGS}{$\bm{q}_n$, $\bm{v}_n$, $\bm{f}_{\text{ext}}$, $m$, $h$}
\State $\bm{s}_n = \bm{q}_n + h\bm{v}_n + h^2\bm{M}^{-1}\bm{f}_{\text{ext}}$
\State $\bm{q}_k = \bm{s}_n$
\For{all iterations}
\State $\bm{s_k} = \bm{q}_k - \bm{q}_{k-1}, \bm{y}_k = \nabla g(\bm{q}_k) - \nabla g(\bm{q}_{k-1}), \rho_k = 1 / (\bm{s}^T_k \bm{y}_k)$
\State $\bm{p}_k = \text{\textsc{twoLoopRecursion}}(\bm{S}, \bm{q}_k, \bm{s}, \bm{y}, \rho, m, k)$   (\cref{alg:lbfgs-recursion})
\State $\alpha_k = 1$
\If{$\alpha_k$ does not satisfy the strong Wolfe conditions}
\State compute $\alpha_k$ that satisfies the strong Wolfe conditions 
\State \textbf{or} $\alpha_k = \text{\textsc{backtrack}}(\bm{q}_k, \bm{p}_k, 1, \beta, t)$ (\cref{alg:backtracking})
\EndIf
\State $\bm{q}_k = \bm{q}_k + \alpha_k \bm{p}_k$
\EndFor
\State \textbf{return with result } $\bm{q}_{n+1} = \bm{q}_k, \bm{v}_{n+1} = (\bm{q}_{n+1} - \bm{q}_n)/h$
\EndProcedure
\end{algorithmic}
\end{algorithm}


Note that step-size $\alpha_k = 1$ is 
used during each iteration of the Quasi-Newton version of the PD solver (\cref{alg:pd-qn}).
While this works well for the constant Hessian approximation $\bm{S}$, it is not viable in L-BFGS. The step-size $\alpha_k = 1$
is not guaranteed to satisfy the strong Wolfe conditions (\cref{eq:wolfe1}, \cref{eq:wolfe2}) if the L-BFGS update is used. However,
the strong Wolfe conditions are required to ensure that the curvature condition (\cref{eq:curvature-condition}) is satisfied 
and $\bm{H}_k$ stays symmetric positive definite. 

While Liu et al.\ \cite{liu2017} show that always picking $\alpha_k = 1$ can lead to
unstable simulations, they report that using backtracking (\cref{alg:backtracking}) yields satisfactory results, even though 
the resulting step-size is not guaranteed to satisfy the second Wolfe condition. This is in contrast to Nocedal's and Wright's
recommendation \cite{nocedal2006} to avoid backtracking in the context of  Quasi-Newton methods. One possible explanation why 
backtracking seems to suffice could be that the inverse 
Hessian approximations $\bm{H}_k$ that arise from the L-BFGS method with initial matrix $\bm{B}_0 = \bm{S}$ are better than
Hessian approximations that arise when traditional initial matrices are used and make up for the inaccuracy in the step length
algorithm.

\subsection{Quasi-Newton Methods for Valanis-Landel Energies}\label{ss:qn-valanis-landel}
In order to achieve satisfactory performance when applying the L-BFGS method to the general form of the implicit Euler integration 
(\cref{eq:variational-implicit}) without the need to restrict to PD energy potentials (\cref{eq:pd-potentials}), a suitable
candidate for the initial Hessian approximation $\bm{B}_0$ or its inverse $\bm{H}_0$ needs to be found. The choice $\bm{B}_0 = 
\bm{S} = \frac{\bm{M}}{h^2} + \sum_j w_j \bm{G}_j^T \bm{G}_j$ from \cref{alg:pd-lbfgs} cannot be applied to the general setting 
without modification as the matrices $\bm{G}_j$ are taken directly from the definitions of the individual PD energy potentials.

We focus on the setting of 3-manifold simplicial complexes where energy potentials are defined for each tetrahedron and the
energy of the entire body is the sum of the individual tetrahedral energies \textcolor{red}{(refer to the appropriate section)}.
As shown in \cref{ss:pd-potentials}, the strain energy of a single tetrahedron can be emulated with special PD strain 
potentials (\cref{eq:pd-strain}). Here $\bm{G}_j = \bm{A}_j$, where $\bm{A}_j$ is the linear operator that maps $\bm{q}$ 
to the tranpose of the deformation gradient $\bm{F}^T_j$, $\bm{C}_j = \text{SO}(3)$ and $w_j = k_jV_j$, where $V_j$ is the
volume of the undeformed tetrahedron and $k_j$ is a user-defined stiffness value. 
Liu et al.\ suggest approximating more general tetrahedral energies with PD strain potentials and using the global system
matrix $\bm{S}$ that arises as the initial Hessian approximation $\bm{B}_0$ given by

\begin{equation}\label{eq:global-matrix-strain}
    \bm{B}_0 = \bm{S} = \frac{\bm{M}}{h^2} + \sum_j w_j \bm{A}_j^T \bm{A}_j.
\end{equation}

Instead of using user-defined stiffness values $k_j$, a procedure for setting $k_j$ from the original, more general energy
potential is required. The discussion is restricted to isotropic and world-space rotation invariant material models that 
can be defined in terms of the singular 
values $\sigma_1, \sigma_2, \sigma_3$ of $\bm{F_j}$ called the principal stretches \cite{sifakis2012}. Liu et al.\ 
\cite{liu2017} present a strategy for the subclass of these material models that can be written in Valanis-Landel form

\begin{equation}\label{eq:valanis-landel}
    \Psi(\sigma_1, \sigma_2, \sigma_3) = a(\sigma_1) + a(\sigma_2) + a(\sigma_3) + b(\sigma_1 \sigma_2) 
    + b(\sigma_2 \sigma_3) + b(\sigma_1 \sigma_3)
\end{equation}

\noindent with $a, b, c : \mathbb{R} \to \mathbb{R}$. Many popular material models including St.\ Venant-Kirchhoff and 
Neo-Hookean 
can be expressed in this form \textcolor{red}{(How? I can't seem to find how to do this in detail. There is a paper that 
might be useful called 'The ValanisLandel Strain-Energy Function', but I am not sure it is useful \ldots)}.

The approach uses the insight that for linear materials that follow Hooke's law, the stiffness $k_j$ is given as the second 
derivative of the energy potential. Computing first and second partial derivatives in the rest configuration $\sigma_1, 
\sigma_2, \sigma_3 = 1$ yields

\begin{align}
    \evalat[\bigg]{\frac{d \psi}{d \sigma_i}}{\sigma_j, \sigma_k = 1} 
    &= a\prime(\sigma_i) + 2b\prime(\sigma_i) + c\prime(\sigma_i) \label{eq:valandis-landel-first} \\
    \evalat[\bigg]{\frac{d^2 \psi}{d \sigma_i}}{\sigma_j, \sigma_k = 1} 
    &= a\prime\prime(\sigma_i) + 2b\prime\prime(\sigma_i) + c\prime\prime(\sigma_i) \label{eq:valandis-landel-second},
\end{align}

\noindent where $i, j, k \in [1, 3], i \neq j \neq k$. Thus, first and second partial derivatives at the rest configuration are the same
for each of the principal stretches, allowing for convenient representation of stiffness in a single scalar value. However,
simply picking

\[
    k_j = \evalat[\bigg]{\frac{d^2 \psi}{d \sigma_i}}{\sigma_i, \sigma_j, \sigma_k = 1} 
    &= a\prime\prime(1) + 2b\prime\prime(1) + c\prime\prime(1)
\]

\noindent runs into issues as the expression often evaluates to zero, even in common non-pathological cases. This issue arises because
the second derivative in \cref{eq:valandis-landel-second} is not representative of the stiffness behavior of the material in the 
entire range of principal stretches $[\sigma_{\text{min}}, \sigma_{\text{max}}]$ that is expected to be encountered during simulation.

To alleviate this, Liu et al.\ \cite{liu2017} propose approximating the rate of change of the first derivative \cref{eq:valandis-landel-first}
by computing the slope of its best linear approximation over the interval $[\sigma_{\text{min}}, \sigma_{\text{max}}]$. Formally, $k$ is 
defined by

\begin{equation}\label{eq:valani-landel-k}
    k \coloneqq \argminB_{k} \int^{\sigma_{\text{max}}}_{\sigma_{\text{min}}} (k(\sigma - 1) - (a\prime(\sigma) + 2b\prime(\sigma) + 
        c\prime(\sigma))^2 d\sigma
\end{equation}

\noindent Using these stiffness values in \cref{eq:global-matrix-strain} yields a suitable initial Hessian approximation $\B_0 = S$ for
the minimization of the variational form of the implicit Euler integration with Valanis-Landel materials via \cref{alg:pd-lbfgs}. According
to Liu et al.\ \cref{alg:pd-lbfgs} is insensitive to the size of the interval $[\sigma_{\text{min}}, \sigma_{\text{max}}]$. It is important
to note that while PD strain energies are used to approximate the original energy potentials when constructing $\bm{B}_0$, the function
evaluations $g(\bm{q}_k)$ and gradients $\nabla g(\bm{q}_k)$ are computed from the original potential energies in \cref{alg:pd-lbfgs}.

\subsection{Properties of Quasi-Newton Methods for Physical Simulations}\label{ss:properties-qn}
\begin{itemize}
    \item Stability, some nice properties of PD are lost due to the L-BFGS update and step length algorithm / backtracking
    \item Efficient structure ($\mathbb{R}^{m \times m}$ vs $\mathbb{R}^{3m \times 3m}$) that allows solving in parallel.
    \item Gradients and function evaluations can be computed in parallel
    \item Generally very few line searches required, but Armijo safeguard is essential
    \item Considerations about window size
    \item Convergence properties compared to regular PD, Newton's method, L-BFGS with classical initializations
    \item Complexity compared to Newton's method (no second derivatives required)
    \item Backtracking vs proper step length algorithm 
    \item Comparison to QN methods with iterative solvers
    \item Collisions
    \item Numerical Damping
    \item Issue: In Hooke's law, the derivatives are in terms of positions, but in our derivations the derivatives are in terms of the 
        singular values!
    \item How to write Neo-Hookean in Valanis-Landel form?
\end{itemize}








