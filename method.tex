\chapter{Method}\label{ch:method}

\section{Time-Integration of Physical Systems}\label{s:physical-integration}
In most approaches for simulation of physical systems, the motion of the system is assumed to be in accordance with Newton's laws of
motion. Due to Newton's second law, it is possible to derive accelerations from forces acting on the system. The motion of the system
can then be described in terms of an ordinary differential equation (ODE) which is integrated over time in order to arrive at the 
configuration of the system at the next time step. Usually, this is achieved via numerical integration schemes. In particular, both
xPBD and PD are based on a numerical integration technique called implicit Euler integration. The ODE is introduced in \cref{s:newton-ode}. 
Common approaches for numerical integration are briefly covered in \cref{s:numerical-integration}.

\subsection{Newton's Ordinary Differential Equation}\label{s:newton-ode}

The motion of a spatially discretized system with $m$ particles evolving in time according to Newton's laws of motion can be modeled via 
the following ODE, which will be referred to as Newton's ODE \cite{bouaziz2014, macklin2016, bender2017}:

\begin{align}
    \begin{split}\label{eq:newton-ode}
        \bm{q}(t)\prime &= \bm{v}(t) \\
        \bm{v}(t)\prime &= \bm{M}^{-1}\bm{f}(\bm{q}(t), \bm{v}(t))
    \end{split}
\end{align}

\noindent where $\bm{q}(t)$, $\bm{v}(t)$, $\bm{f}(\bm{q}(t), \bm{v}(t))$ are the particle positions, particle velocities and forces acting on each particle
at time $t$, respectively, and $\bm{M}$ is a diagonal matrix with the particle masses as diagonal entries. Depending on the context, either 
$\bm{q}(t), \bm{v}(t), \bm{f}(\bm{q}(t), \bm{v}(t)) \in \mathbb{R}^{m \times 3}$ and $\bm{M} \in \mathbb{R}^{m \times m}$ or $\bm{q}(t), 
\bm{v}(t), \bm{f}(\bm{q}(t), \bm{v}(t)) \in \mathbb{R}^{3m}$ and $\bm{M} \in \mathbb{R}^{3m \times 3m}$. $\bm{q}(t)\prime$ and $\bm{v}(t)\prime$ are short for $\bm{D_tq}(t)$ and
$\bm{D_tv}(t)$, respectively. From now on, we write $\bm{q}$ and $\dot{\bm{q}}$ instead of $\bm{q}(t)$ and $\bm{q}(t)\prime$ for 
time-dependent quantities for the sake of brevity.

The positions $\bm{q}$ and velocities $\bm{v}$ of the system at time $t$ can be determind by solving this ODE. For general nonlinear forces,
analytical solutions to Newton's ODE are usually not available. Thus the ODE needs to be solved numerically.

\subsection{Numerical Integration of Newton's Ordinary Differential Equation}\label{s:numerical-integration}
\textcolor{red}{Write introductory paragraph!}

\subsubsection{Explicit Euler Integration}\label{ss:explicit-euler}
The simplest approach to numerical integration is the explict Euler integration \cite{chapra2005}. Here, the positions and velocities 
are computed at discrete timesteps via the following update formulas:

\begin{align*}
    \bm{q}_{n+1} &= \bm{q}_n + h\bm{v}_n\\
    \bm{v}_{n+1} &= \bm{v}_n + h\bm{M}^{-1}\bm{f}(\bm{q}_n, \bm{p}_n)
\end{align*}

\noindent Here, $h$ is the timestep. The idea is to simplify the integration of the functions $\bm{\dot{q}}, \bm{\dot{v}}$ over the timestep by 
using constant approximations. 
Then, time integration is as simple as multiplying this constant function value with the timestep. In the explicit Euler method, we 
approximate $\bm{\dot{q}}, \bm{\dot{v}}$ by their function values $\bm{\dot{q}}(t_n), \bm{\dot{v}}(t_n)$ at the beginning of the timestep.
While simple, the explicit Euler method is not stable for stiff systems, i.e. systems with accelerations of large magnitude 
\cite{chapra2005}. It can be shown that the explicit Euler method does not conserve the system's energy unless the timestep is kept 
prohibitively small. This often manifests itself in exploding simulations.

\subsubsection{Symplectic Euler Integration}\label{ss:symplectic-euler}
A variation of the explicit Euler method, called the symplectic Euler method, arises when the new velocities $\bm{v}_{n+1}$ instead of the
old velocities $\bm{v}_n$ are used in the position update \textcolor{red}{(find citation)}. This leads to the following update formula:

\begin{align}
    \begin{split}\label{eq:symplectic-euler}
        \bm{q}_{n+1} &= \bm{q}_n + h\bm{v}_{n+1}\\
        \bm{v}_{n+1} &= \bm{v}_n + h\bm{M}^{-1}\bm{f}(\bm{q}_n, \bm{p}_n)
    \end{split}
\end{align}

While this method has favorable energy conservation properties in comparison to the explicit Euler method, it still is not unconditionally
stable \textcolor{red}{(find citation)}.

\subsubsection{Implicit Euler Integration}\label{ss:implicit-euler}
Another popular integration scheme for tackling Newton's ODE is implicit Euler integration \cite{bouaziz2014, macklin2016, bender2017}, given
by the update formula

\begin{align}
    \begin{split}\label{eq:implicit-euler}
        \bm{q}_{n+1} &= \bm{q}_n + h\bm{v}_{n+1}\\
        \bm{v}_{n+1} &= \bm{v}_n + h\bm{M}^{-1}\bm{f}(\bm{q}_{n+1}, \bm{p}_{n+1}).
    \end{split}
\end{align}

\noindent Note how $\bm{q}_{n+1}$ and $\bm{v}_{n+1}$ appear on both sides of the equations. Consequently, performing implicit 
Euler integration includes solving a set of nonlinear algebraic equations. Despite the added complexity compared to the explicit and
symplectic Euler integration schemes implicit Euler integration is popular since it can be shown to be unconditionally stable and first-order
accurate \cite{chapra2005}. However, it is also known to exhibit numerical damping \cite{servin2006, bender2017, macklin2019}.

By rewriting the first line of \cref{eq:implicit-euler} as

\[
    \bm{v}_{n+1} = \frac{1}{h}(\bm{q}_{n+1} - \bm{q}_n)
\]

\noindent and substituting into the velocity update of \cref{eq:implicit-euler} the following equation can be derived

\begin{equation}\label{eq:implicit-positional}
    \bm{M}(\bm{q}_{n+1} - \bm{q}_n - h\bm{v}_n) = h^2(\bm{f}(\bm{q}_{n+1}, \bm{v}_{n+1})).
\end{equation}

\textcolor{red}{Possibly show that this system is often solved by linearizing the forces via first-order Taylor approximation.}

We separate forces $\bm{f}(\bm{q}, \bm{v})$ into internal forces $\bm{f}_{\text{int}}(\bm{q}, \bm{p}) = \sum_i \bm{f}^i_{\text{int}}
(\bm{q}, \bm{p})$ and external forces $\bm{f}_{\text{ext}}(\bm{q}, \bm{p}) = \sum_i \bm{f}^i_{\text{ext}}(\bm{q}, \bm{p})$. 
We consider all external forces to be constant. Internal forces are conservative and defined in terms of scalar potential energy functions 
$\psi_i$ via $\bm{f}^i_{\text{int}}(\bm{q}) = -\nabla \psi_i(\bm{q})$. Together, we have $\bm{f}(\bm{q}, \bm{v}) = \bm{f} (\bm{q}) 
= \bm{f}_{\text{int}} (\bm{q}) + \bm{f}_{\text{ext}} = -\sum_i \nabla \psi_i(\bm{q}) + \bm{f}_{\text{ext}}$. Plugging into 
\cref{eq:implicit-positional}, it is

\[
    \bm{M}(\bm{q}_{n+1} - \bm{q}_n - h\bm{v}_n) = h^2(\bm{f_\text{ext}} - \sum_i \nabla \psi_i(\bm{q})).
\]

By computing first-order optimality conditions, it is easily verified that the above system of equations is equivalent to the optimization 
problem

\begin{equation}\label{eq:variational-implicit}
    \min_{\bm{q}_{n+1}} \frac{1}{2h^2} \norm{\bm{q}_{n+1} - \bm{s}_n}^2_F + \sum_i \psi_i(\bm{q}_{n+1}).
\end{equation}

\noindent where $\bm{s}_n = \bm{q}_n + h\bm{v}_n + h^2\bm{M}^{-1}\bm{f}_{\text{ext}}$. This minimization problem whose solution corresponds to the next
iteration of the state of the implicit Euler integration is called the variational form of implicit Euler integration \cite{bouaziz2014}. 
The first and second term of the objective function are called the momentum potential and the elastic potential, respectively. Thus, the 
minimization problem requires that the solution minimizes the elastic deformation as best as possible while ensuring that the solution is 
close to following its momentum plus external forces. The weighting between the momentum potential and the elastic potential depends on the 
particle masses $\bm{M}$, the timestep $h$ and the material stiffness of the elastic potentials $\psi_i$. According to Noether's theorem, 
the solution preserves linear and angular momentum as long as the elastic potentials are rigid motion invariant.

\textcolor{red}{Add some words about how it is often favorable to use the variational formulation because solving an optimization problem is
often easier than just solving a system of equations. That is because one can be guided by the objective function.}

\section{Unconstrained Optimization}\label{s:unconstrained-optimization}
The goal of unconstrained optimization is to find the global minimizer of smooth, but generally nonlinear functions of the form $f \colon 
\mathbb{R}^n \to \mathbb{R}, n \in \mathbb{N}$, or formally

\[
    \min_{\bm{x}} f(\bm{x}).
\]

\noindent Here, $f$ is called the objective function. 

Most algorithms are incapable of finding global minimizers of general nonlinear functions. 
Instead, these algorithms begin their search at a starting point $\bm{x}_0$ and then iteratively improve this initial guess until a local 
minimizer is found \cite{nocedal2006}. A local minimizer is a point $\bm{x}^*$ such that there is a neighborhood $\mathcal{N}$ of 
$\bm{x}^*$ such that $f(\bm{x}^*) \leq f(\bm{x})$ for all $\bm{x} \in \mathcal{N}$. If the initial guess $\bm{x}^*$ is close enough 
to the global minimizer the local minimizer that the algorithm converges to can often coincide with a global minimizer. 

\subsection{Line Search Methods}\label{ss:line-search}
It can be shown that $\nabla f(\bm{x}^*) = 0$ if $\bm{x}^*$ is a local minimizer and f is continuously differentiable in an open neighborhood
of $\bm{x}^*$ \cite{nocedal2006}. The proof is by contradiction and establishes that if $\nabla f(\bm{x}^*) \neq 0$, then it is possible to pick a descent 
direction along which it is possible to decrease the value of the objective function if the step size is picked sufficiently small. This 
observation gives rise to the idea of a family of optimization algorithms called line search algorithms \cite{nocedal2006}: Given the current 
iterate $\bm{x}_k$, pick a descent direction $\bm{p}_k$ and search along this direction for a new iterate $\bm{x}_{k+1}$ with $\bm{x}_{k+1} = 
\bm{x}_k + \alpha_k \bm{p}_k$. This process is repeated until $\nabla f(\bm{x}_k)$ is sufficiently close to zero. It is important to note that 
$\nabla f(\bm{x})$ does not imply that $\bm{x}$ is a local minimizer. Instead, $\bm{x}$ is only guaranteed to be a local minimizer if the second-order 
optimality conditions are satisfied, which additionally require $\nabla^2 f(\bm{x})$ to be positive semidefinite \cite{nocedal2006}.

Ideally, $\alpha_k$ is picked such that it is the minimizer of the one-dimensional optimization problem

\[
    \min_{\alpha_k > 0} f(\bm{x}_k + \alpha_k \bm{p}_k).
\]

\noindent In most cases, it is infeasible to compute $\alpha_k$ exactly. Instead, the idea is to compute an approximation of $\alpha_k$ such that 
the objective function decreases sufficiently and that $\alpha_k$ is close enough to the true minimizer. Formally, these requirements
are captured in the strong Wolfe conditions for step lenghts $\alpha_k$ \cite{nocedal2006}:

\begin{align}
    f(\bm{x}_k + \alpha_k \bm{p}_k) &\leq f(\bm{x}_k) + c_1 \alpha_k \nabla f(\bm{x}_k) \bm{p}_k \label{eq:wolfe1} \\
    \abs{\nabla f(\bm{x}_k + \alpha_k \bm{p}_k)^T \bm{p}_k} &\leq c_2 \abs{\nabla f(\bm{x}_k)^T \bm{p}_k} \label{eq:wolfe2}
\end{align}

\noindent for some constants $c_1 \in (0, 1), c_2 \in (c_1, 1)$. \cref{eq:wolfe1} is called the sufficient decrease or the Armijo condition 
and states that the reduction in $f$ should be proportional to both the step length $\alpha_k$ and the directional derivative 
$\nabla f(\bm{x}_k \bm{p}_k)$. Informally, the second condition (\cref{eq:wolfe2}), known as the curvature condition, ensures that there 
is no more fast 
progress to be made along the search direction $\bm{p}_k$, indicated by the fact that $\abs{\nabla f(\bm{x}_k + \alpha_k \bm{p}_k)^T 
\bm{p}_k}$ is already rather small. 

Step sizes satisfying the strong Wolfe conditions have the following properties under mild assumptions \cite{nocedal2006}. Firstly, 
if $\bm{p}_k$ is a descent direction, it is possible to find a step size that satisfies the strong Wolfe conditions. Secondly, it 
can be shown that line search methods where $\alpha_k$ satisfies the strong Wolfe conditions for all $k$ converge to a stationary
point $\bm{x}^*$ with $\nabla f(\bm{x}^*) = 0$ if the search direction $\bm{p}_k$ is sufficiently far from orthogonal to the steepest
descent direction $\nabla f(\bm{x}_k)$ for all $k$. Such line search algorithms are called globally convergent.

\subsubsection{Steepest Descent}\label{sss:steepest-descent}
The most obvious choice for the search direction $\bm{p}_k$ at iteration $k$ is the steepest descent direction given by 
\[
    \bm{p}_k = -\nabla f(\bm{x}_k).
\]

\noindent This method is called steepest descent. While simple, steepest descent exhibits poor performance, even for simple problems \cite{nocedal2006}. 
Its convergence rate is only linear and depends on the eigenvalue distribution of the Hessian $\nabla^2 f(\bm{x}^*)$ at the local minimizer
$\bm{x}^*$. If the eigenvalues distribution is wide, steepest descent often requires an unacceptably large number of iterations to find a 
stationary point.

\subsubsection{Newton Method}\label{sss:newton-method}
It can be shown that any search direction $\bm{p}_k$ that makes an angle of strictly less than $\pi/2$ radians with the steepest descent
direction $\nabla f(\bm{x}_k)$ is a descent direction as well \cite{nocedal2006}. As long as $\bm{p}_k$ does not get arbitrarily close to 
orthogonal to $\nabla f(\bm{x}_k)$, any such $\bm{p}_k$ can be used in the line search framework. The so called Newton direction $\bm{p}^N_k$ 
is a popular choice. It is derived from the second-order Taylor series approximation to $f(\bm{x}_k + \bm{p})$ which is given by

\begin{equation}\label{eq:newton-model}
    f(\bm{x}_k + \bm{p}) \approx f(\bm{x}_k) + \bm{p}^T \nabla f(\bm{x}_k) + \frac{1}{2}\bm{p}^T \nabla^2 f(\bm{x}_k) \bm{p} \eqqcolon 
    m_k(\bm{p}).
\end{equation}

\noindent The model function $m_k$ has a unique minimizer if $\nabla^2 f(\bm{x}_k)$ is positive definite. In this case, the Newton direction 
is defined
as the unique minimizer $\bm{p}^N_k$ of $m_k$, which can be found by setting the derivative of $m_k(\bm{p})$ to zero:

\begin{equation}\label{eq:newton-diretion}
    \bm{p}^N_k = - (\nabla^2 f(\bm{x}_k))^{-1} \nabla f(\bm{x_k}).
\end{equation}

\noindent The better the quadratic model function $m_k(\bm{p})$ approximates $f(\bm{x}_k + \bm{p})$ around $\bm{x}_k$, the more reliable is the 
Newton direction. 

It is easy to show that $\bm{p}^N_k$ is a descent direction, given that $\nabla^2 f(\bm{x}_k)$ is positive definite \cite{nocedal2006}. 
Otherwise, the Newton direction is not guaranteed to exist, or to be a descent direction if it does. In such cases, the Newton direction cannot 
be used without modification. Thus, in its naive form, the Newton method is not globally convergent. However, if $\nabla^2 f(\bm{x}^*)$ is positive
definite at a local solution $\bm{x}^*$ and $f$ is twice differentiable, then $\nabla^2 f(\bm{x})$ is also positive definite for $\bm{x} \in 
\mathcal{N}$ for some neighborhood $\mathcal{N}$ of $\bm{x}^*$. If we have $\bm{x}_0 \in \mathcal{N}$ for the starting point of $\bm{x}_0$
of Newton's method and $\bm{x}_0$ is sufficiently close to the solution $\bm{x}^*$ it can be shown that Newton's method with step length
$\alpha_k = 1$ converges to $\bm{x}^*$ with a quadratic rate of convergence under mild conditions \cite{nocedal2006}. Thus, Newton's method 
has satisfactory convergence properties close to the solution $\bm{x}^*$ and the Newton direction $\bm{p}^N_k$ has a natural step size 
$\alpha_k = 1$ associated with it. Since $\alpha_k = 1$ often does not satisfy the Wolfe conditions when the current iterate $\bm{x}_k$ is still 
far away from the solution $\bm{x}^*$, line searches are still necessary in Newton's method. However, it is recommended to use $\alpha_k = 1$ as the
initial guess as $\alpha_k = 1$ guarantees quadratic convergence once $\bm{x}_k$ gets sufficiently close to $\bm{x}^*$.

Despite its favorable convergence properties, Newton's method comes with a couple of disadvantages. Firstly, computing the Hessian matrix
$\nabla^2 f(\bm{x}_k)$ is expensive and error prone. Additionally, a new system 

\[
    \nabla^2 f(\bm{x}_k) \bm{p}^N_k = - \nabla f(\bm{x_k})
\]

\noindent needs to be solved at every iteration as the Hessian matrix changes with the current iterate $\bm{x}_k$.
If the Hessian $\nabla^2 f(\bm{x}_k)$ is sparse, its factorization can be computed via sparse elimination techniques. However, there is no
guarantee for the matrix factorization of a sparse matrix to be sparse itself in the general case.
For these reasons, while a single
Newton iteration often makes quite a lot of progress towards the solution, it takes a significant amount of time to compute. If $\bm{x}_k
\in \mathbb{R}^n$ for some large $n \in \mathbb{N}$, computing the exact Newton iteration can become infeasible, especially for real-time
applications. Concomitantly, the memory required to store the Hessian matrix of size $\mathcal{O}(n^2)$ becomes prohibitive.

\subsubsection{Quasi-Newton Methods}\label{sss:quasi-newton}
Due to the shortcomings of Newton's method mentioned in \cref{sss:quasi-newton}, it can be favorable to simply approximate the Newton 
direction
in order to find an effective search direction while keeping the cost of a single iteration low. Effective Newton approximations can be 
computed without the need to compute the Hessian $\nabla^2 f(\bm{x}_k)$ during each iteration \cite{nocedal2006}. Often, multiple Quasi-Newton 
iterations fit into the same time budget as a single Newton iteration. As a result, Quasi-Newton methods can converge to a solution in a 
shorter amount of time than the Newton method, even though their search directions are not as effective as the exact Newton direction.

In Quasi-Newton methods, search directions of the following form are used

\begin{equation}\label{eq:quasi-newton-direction}
    \bm{p}_k = -\bm{B}^{-1}_k \nabla f(\bm{x}_k),
\end{equation}

\noindent where $\bm{B}_k \in \mathbb{R}^{n \times n}$ is positive definite \cite{nocedal2006}. Note that the Newton direction is a special 
case of 
\cref{eq:quasi-newton-direction} with $\bm{B}_k = \nabla^2 f(\bm{x}_k)$. Just like for the Newton direction $\bm{p}^N_k$ in
\cref{eq:newton-model}, a model function $m_k$ 
that attains its minimum at $\bm{p}_k  = -\bm{B}^{-1}_k \nabla f(\bm{x}_k)$ can be defined via

\begin{equation}\label{eq:quasi-newton-model}
    m_k(\bm{p}) = f(\bm{x}_k)  + \nabla f(\bm{x}_k)^T \bm{p} + \frac{1}{2} \bm{p}^T\bm{B}_k\bm{p}.
\end{equation}

\noindent As $\bm{B}_k \neq \nabla^2 f(\bm{x}_k)$, $m_k$ does not correspond to a second-order Taylor approximation of $f$ around 
$\bm{x}_k$ anymore. Instead, $\bm{B}_k$ is picked such that the gradient of $m_k$ matches the gradient of $f$ at the last two iterates 
$\bm{x}_k$ and $\bm{x}_{k-1}$.
Since $\nabla m_{k}(\bm{0}) = \nabla f(\bm{x}_k)$, the first condition is true independent of $\bm{B}_k$. The 
second condition yields

\[
    \nabla m_{k}(-\alpha_{k-1}\bm{p}_{k-1}) = \nabla f(\bm{x}_k) - \alpha_{k-1}\bm{B}_{k}\bm{p}_{k-1} = \nabla f(\bm{x}_{k-1}).
\]

\noindent Rearranging gives

\begin{equation}\label{eq:secant-equation}
    \bm{B}_k \bm{s}_{k-1} = \bm{y}_{k-1},
\end{equation}

\noindent where $\bm{s}_{k-1} = \bm{x}_k - \bm{x}_{k-1} = \alpha_{k-1}\bm{p}_{k-1}$. This is called the secant equation. 
Multiplying both sides from the left with $\bm{s}_{k-1}^T$ yields the curvature condition given by

\begin{equation}\label{eq:curvature-condition}
    \bm{s}_{k-1}^T \bm{y}_{k-1} > 0,
\end{equation}

\noindent since $\bm{B}_k$ is positive definite. Note that the curvature condition is not satisfied for arbitrary $\bm{x}_k, \bm{x}_{k-1}$ 
if $f$ is 
not convex. However, it can be shown that the curvature condition always holds when the step size $\alpha_{k-1}$ satisfies the strong Wolfe 
conditions \cite{nocedal2006}. Thus, a proper line search strategy is vital for the viability of Quasi-Newton methods.

Since $\bm{B}_k$ is positive definite, the secant equation can be written in terms of the inverse $\bm{H}_k \coloneqq \bm{B}^{-1}_k$ as

\[
    \bm{H}_k \bm{y}_{k-1} = \bm{s}_{k-1}
\]

\noindent and the formula for the new search direction becomes $-\bm{H}_k \nabla f(\bm{x}_k)$. The secant equation is not enough to uniquely determine
the entries of $\bm{H}_k$, even if $\bm{H}_k$ is required to be symmetric positive definite. Thus, the additional requirement that $\bm{H}_k$
is closest to $\bm{H}_{k-1}$ according to some norm is imposed. In summary, $\bm{H}_k$ is picked such that it solves the following constrained
minimization problem

\begin{align*}
    \min_{H} \norm{\bm{H} - \bm{H}_{k-1}} \text{, subject to } \bm{H} = \bm{H}^T \text{ and } \bm{H}\bm{y}_{k-1} = \bm{s}_{k-1}.
\end{align*}

Using a scale-invariant version of the weighted Frobenius norm gives rise to the popular Broyden- Fletcher-Goldfarb-Shanno (BFGS) algorithm.
It is defined via the following update formula for $\bm{H}_k$

\begin{equation}\label{eq:bfgs-update}
    \bm{H}_k = (I - \rho_{k-1}\bm{s}_{k-1}\bm{y}^T_{k-1})\bm{H}_{k-1}(I - \rho_{k-1}\bm{s}_{k-1}\bm{y}^T_{k-1}) + \rho_{k-1}\bm{s}_{k-1}\bm{s}^T_{k-1},
\end{equation}

\noindent where $\rho_{k-1} = 1 / (\bm{s}^T_{k-1}\bm{y}_{k-1})$. Is is possible to give a similar update formula in terms of $\bm{B}_k$.
Generally, using the formulation in terms of the inverse matrices $\bm{H}_k$ is preferrable since the computation of the new descent 
direction can
be achieved by simple matrix-vector multiplication instead of solving a linear system if $\bm{B}_k$ is maintained instead.

While global convergence of the BFGS method cannot be established for general nonlinear smooth functions, it is possible to show that it converges 
superlinearly if the initial guess $\bm{x}_0$ is close to the solution $\bm{x}^*$ and $\alpha_k = 1$ for sufficiently large $k$ \cite{nocedal2006}
under mild conditions. Thus, just like the Newton method (\cref{sss:newton-method}), the BFGS method has a natural step length $\alpha=1$,
which should be the initial guess for all line search algorithms. Typically, the BFGS method dramatically outperforms steepest 
descent and performs comparably to Newton's method on many practical problems. 

The behavior of the BFGS method depends on the choice of the initial inverse matrix $\bm{H}_0$. One obvious choice is $\bm{H}_0 = \nabla^2 
f(\bm{x}_0)$. However, there is no guarantee that $\nabla^2 f(\bm{x}_0)$ is positive definite. Additionally, computing even a single inverse
matrix can be prohibitively expensive for large problems. Thus, scaled versions of the identity matrix $\gamma I, \gamma \in \mathbb{R}^+$ are
often used instead. There is no good general strategy for choosing $\gamma$, even though heuristic appraoches are popular. \textcolor{red}{Maybe
explain one heuristic, if necessary down the line}.

Even though BFGS iterations are typically faster to compute than Newton iterations, the BFGS method is still not suitable for large problems 
in its naive form. Just like in Newton's method, either $\bm{H}_k$ or $\bm{B}_k$ needs to be stored explicitly, which can be infeasible for 
large-scale problems. While the BFGS update formula using the inverse matrices $\bm{H}_k$ replaces the need for a matrix factorization with a simple 
matrix-vector multiplication, $\bm{H}_k$ and $\bm{B}_k$ are generally dense, even if $\nabla^2 f(\bm{x}_k)$ is sparse. This removes the possibility
of alleviating storage requirements and speeding up computations via sparse matrix techniques when using the naive BFGS method.

\subsubsection{Limited-Memory Quasi-Newton Methods}\label{sss:limited-memory-quasi-newton}
As discussed in \cref{sss:quasi-newton}, the BFGS method is unsuitable for large-scale problems due to the storage requirements of the 
typically dense inverse Hessian approximation $\bm{H}_k$. This highlights the need for effective Hessian approximations that are not only
cheap to compute, but also cheap to store. Just like Quasi-Newton methods use approximations of the Newton direction in order to keep 
the computational cost of a single iteration low, limited-memory Quasi-Newton methods approximate Quasi-Newton directions with 
the goal of reducing the memory footprint of a single iteration. This comes at the prize of inferiornocedal2006 convergence properties. On the upside,
limited-memory Quasi-Newton directions can sometimes be computed by using only a couple of vectors of size $n$, without the need to 
explicitly form the inverse Hessian approximation $\bm{H}_k$. This can drop the space complexity of a single iteration to $\mathcal{O}(n)$ 
compared to $\mathcal{O}(n^2)$ for the BFGS method.

A popular limited-memory method called L-BFGS can be derived from the BFGS update formula for the inverse Hessian approximation 
$\bm{H}_k$, given by \cref{eq:bfgs-update} \cite{nocedal2006}. Note that the BFGS update in iteration $k$ is specified entirely 
by the vector 
pair $(\bm{s}_n, \bm{y}_n) \in \mathbb{R}^n$. Consequently, $\bm{H}_k$ can be constructed from the initial matrix $\bm{H}_0$ and the familiy 
of vector pairs $((\bm{s}_i, \bm{y}_i))_{i \in [0, k-1]}$ by simply performing $k$ update steps according to $\cref{eq:bfgs-update}$.
The idea of L-BFGS is to only keep track of the most recent $m$ vector pairs and generate a modified version of the Hessian approximation 
from the BFGS method by applying the $m$ updates defined by $((\bm{s}_i, \bm{y}_i))_{i \in [k-m, k-1]}$ to the 
initial matrix $\bm{H}_0$ at each iteration $k$.

It is important to note that its not the L-BFGS Hessian approximation $\bm{H}_k$ itself, but the search direction $\bm{p}_k = -\bm{H}_k 
\nabla f(\bm{x}_k)$ that is of interest. It turns out that the L-BFGS search direction $\bm{p}_k$ can be computed without explicitly 
constructing $\bm{H}_k$ using an algorithm called the L-BFGS two-loop recursion (\cref{alg:lbfgs-recursion}) \cite{nocedal2006}.

\begin{algorithm}
\caption{L-BFGS two-loop recursion}\label{alg:lbfgs-recursion}
\begin{algorithmic}
\State $\bm{t} = \nabla f(\bm{x}_k)$
\For{$i = k-1, k-2, \ldots, k-m$}
\State $\alpha_i = \rho_i \bm{s}^T_i \bm{t}$
\State $\bm{t} = \bm{t} - \alpha_i \bm{y}_i$
\EndFor
\State $\bm{r} = \bm{H}_0 \bm{t}$
\For{$i = k-m, k-m+1, \ldots, k-1$}
\State $\beta = \rho_i \bm{y}^T_i \bm{r}$
\State $\bm{r} = \bm{r} + \bm{s}_i(\alpha_i - \beta)$
\EndFor
\State \textbf{return with result } $\bm{H}_k \nabla f(\bm{x}_k) = \bm{r}$.
\end{algorithmic}
\end{algorithm}

Excluding the matrix-vector multiplication $\bm{H}_0 \bm{t}$, the two-loop recursion scheme has time complexity $\mathcal{O}(n)$. Thus,
if $\bm{H}_0$ is chosen to be diagonal, the entire L-BFGS iteration can be computed in $\mathcal{O}(n)$. Similarly, the space complexity
of the L-BFGS iteration is only $\mathcal{O}(n)$ if $\bm{H}_0$ is diagonal. Even if $\bm{H}_0$ is not diagonal, but sparse, the two-loop
recursion can be significantly faster and more space efficient than a BFGS update where matrix-vector multiplication with a dense matrix
is required in general.

L-BFGS shares many properties with the BFGS method discussed in \cref{sss:quasi-newton}. The performance of the L-BFGS method depends 
on the choice of the initial matrix $\bm{H}_0$, with scaled diagonal matrices being popular choices. Again, there is no generally viable
strategy for picking the scaling factor $\gamma \in \mathbb{R}$. Similarly, the initial guess for the step size $\alpha_k=1$ should be used.
The window size $m$ is a parameter that needs to be tuned on a per-problem basis \cite{nocedal2006}. While the L-BFGS algorithm is 
generally less robust if
$m$ is small, making $m$ arbitrarily large increases the amount of time required to perform the two-loop recursion. If the matrix-vector
multiplication in \cref{alg:lbfgs-recursion} is expensive to compute, the additional computational cost incurred by increasing $m$ is 
usually overshadowed by the matrix-vector multiplication. Still, larger values of $m$ do not necessarily lead to better performance. 
\cite{liu2017} suggest that curvature information from vector pairs $(\bm{s}_i, \bm{y}_i)$ from iterations i with $i << k$ can become 
out of date, making moderately large values of $m$ more beneficial. The main weakness of the L-BFGS method is its slow convergence on 
problems where the true Hessian matrices $\nabla^2 f(\bm{x})_k$ are ill-conditioned \cite{nocedal2006}.

\section{Dynamic Simulation}\label{s:dynamic-simulation}
\begin{itemize}
    \item Write a paragraph that gives an overview
    \item Use $\bm{q}$ instead of $\bm{x}$ everywhere
    \item Rewrite this entire section from scratch. Make sure that the notation is unified. At the end of each method,
        point out what its issues are. When the next method is introduced that solves some of these issues, highlight
        how with a couple of sentences.
\end{itemize}

\subsection{Stiff Springs}\label{ss:stiff-springs}
Simulating effects such as incompressibility, inextensibility and joints between articulated rigid bodies 
in elasticity-based simulations can be achieved by using high stiffness values. High stiffness values lead to 
large forces which in turn cause numerical issues in the solver. 

We demonstrate these issues based on the example of maintaining a desired distance between two points using a stiff 
spring \cite{tournier2015}. Let $\bm{x_1, x_2}$ be the positions, $\bm{v_1, v_2}$ the velocities and $\bm{a_1, a_2}$
be the accelerations of the two particles. Let $\overline{l}$ be the rest length and $l = \lVert \bm{x_1} - \bm{x_2} \rVert$ 
be the current length of the spring with stiffness $k$. It can be shown that the force that the spring applies at each particle
is equal to $\bm{f_1} = -\bm{f_2} = \lambda\bm{u}$, where $\bm{u} = (\bm{x_1} - \bm{x_2}) / l$
and $\lambda = -\frac{\delta V}{\delta l} = k(\overline{l} - l)$. 

Once the forces, accelerations, velocities and positions are combined into vectors $\bm{f}, \bm{a}, \bm{v}, \bm{x}$, 
respectively, the motions of the system can be modeled via Newton's Ordinary Differential Equation (ODE) $\bm{f} = \bm{Ma}$,
where $\bm{M}$ is a $n_d \times n_d$ diagonal matrix and $n_d$ is the total number of independent degrees of freedom for the 
particles. \textcolor{red}{Explain Newton's ODE elsewhere and refer to it here.}

This system can be integrated via the symplectic Euler method as follows \textcolor{red}{(I believe this should be moved into
the section on numerical integration...)}:

\begin{align*}
    \bm{v_{n+1}} &= \bm{v_n} + h\bm{a_n} \\
    \bm{x_{n+1}} &= \bm{x_n} + h\bm{v_{n+1}}
\end{align*}

As the stiffness $k$ of the spring increases, so does the magnitude of the acceleration $\bm{a}$. Consequently, the integration
diverges unless the timestep is prohibitively small. The stability issues are often addressed by switching to an implicit 
integration scheme, such as the backward Euler method \cite{baraff1998} \textcolor{red}{(refer to the section on numerical 
integration here)}. Replacing current accelerations with future accelerations requires the solution of the following linear 
system of equations (LSE):

\[
    (\bm{M} - h^2\bm{K})\bm{v_{n+1}} = \bm{p} + h\bm{f}
\]

where $\bm{p} = \bm{Mv_n}$ is the momentum, and $\bm{K} = \frac{\delta \bm{f}}{\delta \bm{x}}$ is the stiffness matrix. Note that 
$\bm{K}$ is typically non-singular since elastic forces are invariant under rigid body transforms. When using large stiffness 
$k$ for springs, the entries of $\bm{K}$ are large (due to large restorative forces for stiff springs) and dominate the entries 
of the system matrix 

\begin{equation}\label{eq:system-H}
    \bm{H} = \bm{M} - h^2\bm{K}.
\end{equation}

In these cases, $\bm{H}$ will be almost non-singular as well, leading to numerical issues and poor convergence for many solvers. 
Additionally, implicit integration introduces noticable numerical damping \cite{servin2006}.

\textcolor{blue}{This system results from performing the implicit integration and solving the non-linear system via linearization
using the Taylor expansion. Positions can be expressed in terms of velocities and eliminated from the system.}

\subsection{Penalty Forces}\label{ss:penalty-forces}
In \cref{ss:stiff-springs}, the energy was derived from Hooke's Law for springs. However, it is also possible to derive energies from 
geometric displacement functions $\bm{\phi(x)}$ which vanish in the rest configuration. From the displacement functions, quadratic 
potential energies of the form $U(\bm{x}) = \Sigma_i (k / 2) \bm{\phi^2(x)}$, where $k$ is a positive stiffness parameter, are 
constructed \cite{terz1987}. The potential energy $U(\bm{x})$ is zero if the displacement function is satisfied, and greater than 
zero otherwise. The resulting forces are called penalty forces. \textcolor{red}{Make sure to be consistent with naming of potentials
across the thesis.}

Using the geometric displacement function $\bm{\phi_{\text{spring}}(x)} = (\lVert \bm{x_i} - \bm{x_j} \rVert) - l$ with $k_{\text{spring}}$ 
recovers the behavior of a spring with stiffness $k_{\text{spring}}$ (\cref{ss:stiff-springs}). Its displacement function 
$\bm{\phi_{\text{spring}}(x)}$ is satisfied when the distance of the particles $\bm{x_i}, \bm{x_j}$ is equal to a desired rest length $l$. 
By constructing different geometric displacement functions, various properties such as the bending angle between triangles and in-plane 
shearing of triangles can be controlled via the corresponding quadratic energy potentials \cite{baraff1998}. Geometric displacement 
functions with the desired effect are often intuitive and simple to define. However, as the corresponding energy potentials are not physically 
derived, choosing stiffness parameters that correspond to measurable physical properties of the simulated material and orchestrating 
multiple constraints becomes challenging \cite{servin2006, nealen2006}. Additionally, the generated penalty forces do not converge in the 
limit of infinite stiffess, leading to oscillations unless the timestep is reduced significantly \cite{rubin1957}.

\textcolor{blue}{Maybe explain the challenges with penalty forces a bit better! Also read \cite{terz1987, nealen2006, rubin1957}. 
I just skimmed over \cite{terz1987} for now, but want to make sure that I am citing this correctly. The term penalty forces is not used
in the paper, I am just following the trail from \cite{servin2006}. \cite{nealen2006} is a review that might be intersting to read.
\cite{rubin1957} would be really interesting to read for once, just to understand why strong penalty forces oscillate. Is this a
general problem with penalty forces, or is it an issue with the solver?}

\subsection{Mass Modification}\label{ss:mass-modification}
\textcolor{red}{Might be worth removing this section. Or at the very least, make it more obvious why this is relevant to other 
approaches.}

The motion of a particle can be influenced by modifying the inverse mass matrix $\bm{M^{-1}}$ of the system. 
For a single particle $\bm{x_i}$, it is $\ddot{\bm{x_i}} = \bm{M_i^{-1} f}$ \textcolor{red}{(make sure to introduce the notation
with the dot first)}, where $\bm{M_i^{-1}}$ is the inverse mass matrix for particle $i$. If, for example, the first diagonal entry 
of $\bm{M_i^{-1}}$ is zero, no acceleration in the $x$-direction is possible. It is possible to construct modified inverse mass 
matrices $\bm{W}$ such that the accelerations in the three axes of an arbitraty orthogonal coordinate system can be restricted. 
The modified inverse mass matrices $\bm{W}$ can be used in the LSE that results from the implicit integration above. By adding 
simple velocity and position terms to the system equations the magnitude of the change in velocity in each direction and even the 
exact position of each constrained particle can be controlled. This approach is called mass modification \cite{baraff1998}. In 
\cite{baraff1998}, the authors use mass modification to model collision constraints between objects and cloth and other user 
defined constraints. 

Since the velocity and position of each constrained particle is controlled via a single velocity and position term, multiple 
constraints that affect the same particle have to be handled together. This can lead to constraints which affect arbitrarily many
particles. For that reason, self-collisions of cloth are not handled via mass modification in \cite{baraff1998}. Instead, penalty
forces are used (\cref{ss:penalty-forces}). Additionally, accurately constraining particle positions is only possible for particles 
whose velocity is constrained as well. The resulting system is unbanded, but sparse, and is solved using a modified version of the 
conjugate gradient (CG) method. \textcolor{red}{Maybe conjugate gradient solver needs to be introduced elsewhere now. Check again
why this formulation lends itself to a CG method and why this is better than just solving the system directly.}

\subsection{Constraint-based Dynamics}\label{ss:constraint-based-dynamics}

\subsubsection{Hard Constraints}\label{sss:hard-constraints}
The problem of maintaining hard distance constraints between particles can be formulated as a Differential Algebraic Equation (DAE)
\cite{ascher1995, baraff1996}. In this framework, Newton's ODE \textcolor{red}{(reference somewhere)} is handled together with 
algebraic equations that model the constraints on the positions of the system. Distance constraints are typically implemented using 
holonomic constraints 
of the form $\bm{\phi(x)} = 0$. Note that the distance constraint $\bm{\phi}(x)$ is formulated in terms of the particle positions, 
whereas the ODE works on accelerations or velocities. Consequently, the constraints need to be differentiated with respect to time
once or twice so that they can be 
combined with the ODE in terms of velocties or accelerations, respectively. \textcolor{blue}{In xPBD, we go the other way! The ODE
is tanslated so that it is in terms of positions, so that it can be handled together with the constraints. Is there a reason nobody 
bothered to
do this before? What are the challenges here? Is this exactly what xPBD is? Is there a way to view the simplifications made in 
terms of the other frameworks?}. Using $\bm{J} = \frac{\delta \bm{\phi}}{\delta \bm{x}}$, where $\bm{J}$ is a $n_c \times n_d$ matrix
and $n_c$ is the number of scalar constraints, this leads to the following constraint formulations:

\begin{align*}
    \bm{Jv} &= 0 \\
    \bm{Ja} &= \bm{c(v)}
\end{align*}

for some $\bm{c(v)}$. \textcolor{red}{If you check \cite{ascher1995}, see that $c(v)$ also depends on the positions $q$. That should 
be indicated!} 
Additionally, constraint forces \textcolor{red}{(use internal forces, more general and will be used throughout the thesis)} are 
required in order to link the algebraic constraint equations with the ODE describing the motion of 
the system. It can be shown that the constraint forces $\bm{f_c}$ applied to the particles have to be in the following form in order to 
avoid adding linear and angular momentum to the system \cite{baraff1996}:

\begin{equation}\label{eq:constraint-forces}
    \bm{f_c} = \bm{J^T \lambda}
\end{equation}

where the $\lambda$ are the Lagrange multipliers of the constraints. With external forces $\bm{f}_{\text{ext}}$, the DAE can now be 
expressed as follows 
\cite{ascher1995}:

\[
    \begin{pmatrix}
        \bm{M} & \bm{-J^T} \\
        \bm{J} & 0
    \end{pmatrix}
    \begin{pmatrix}
        \bm{a} \\
        \bm{\lambda}
    \end{pmatrix}
    =
    \begin{pmatrix}
        \bm{f_e} \\
        \bm{c(v)}
    \end{pmatrix}
\]

Note that the lower block-row of the system drives towards accelerations that satisfy the constraints imposed by $\bm{\phi(x)}$ (or, striclty 
speaking, the differentiations thereof) exactly. This is indicated by the lower-right zero block in the system matrix in either formulation. 
Thus, the system does not have a solution if constraints are contradictory. \textcolor{blue}{Aren't $\dot{q} = v$ and $\dot{v} = a$ 
also part of the differential equation? Because $c(v)$ and $f_e$ also depend on $q$!}

In \cite{ascher1995}, the DAE is approached by eliminating the $\lambda$ from the system entirely and constructing an ODE in terms of positions
and velocities. In \cite{tournier2015}, the authors suggest applying implicit integration schemes to the system directly by constructing the 
following Karush-Kuhn-Tucker (KKT) equation system:

\[
\begin{pmatrix}
    \bm{M} & \bm{-J^T} \\
    \bm{J} & 0
\end{pmatrix}
\begin{pmatrix}
    \bm{v_{n+1}} \\
    \bm{\mu_{n+1}}
\end{pmatrix}
=
\begin{pmatrix}
    \bm{p} + h\bm{f_e} \\
    0
\end{pmatrix}
\]

Here, the external forces $\bm{f}_{\text{ext}}$ and the constraint gradients $\bm{J}$ are considered constant across the timestep 
and $\bm{J(x_{n+1})}$ 
is not approximated using the Taylor expansion like it is in \cite{baraff1998}. If internal forces are taken into account, the upper-left 
matrix $\bm{M}$ is replaced by the matrix $\bm{H}$ from \cref{eq:system-H}.

\textcolor{blue}{Reverse-engineering how the authors arrived at this system is quite enlightening. Start out from the equations of motion 
\cite{ascher1995}
    \begin{align*}
        \dot{\bm{v}} &= \bm{M^{-1}(f - J^T) \lambda}
    \end{align*}
    and perform implicit integration:
    \begin{align*}
        \bm{v_{n+1}} &= \bm{v_n} + h\bm{M^{-1}(f_e(x_{n+1})} - \bm{J^T(x_{n+1})\lambda(x_{n+1}))} \\
        \bm{Mv_{n+1}} &= \bm{p} + h\bm{f_e(x_{n+1})} - h\bm{J^T(x_{n+1})\lambda(x_{n+1})} \\ 
        \bm{Mv_{n+1}} + h\bm{J^T(x_{n+1})\lambda(x_{n+1})} &= \bm{p} + h\bm{f_e(x_{n+1})} \\ 
        \bm{Mv_{n+1}} + \bm{J^T(x_{n+1}) \mu(x_{n+1})} &= \bm{p} + h\bm{f_e(x_{n+1})}
    \end{align*}
}
\textcolor{red}{If we assume that $\bm{f_e}$ and the constraint gradients $\bm{J}$ are constant across the time step, we arrive at the 
formulation from the paper. For the external forces, which are usually only comprised of gravitational forces, this is not a big 
deal. For the constraint gradients, I am not sure what the ramifications are. In \cite{baraff1998}, the Taylor expansion is performed
which requires the compution of second derivatives over the constraint functions. This is not happening here at all! Is this what 
authors mean when they say that the constraints are effectively linearized during one solve, e.g. second page 
of \cite{mueller2020}? Technically, speaking, even if the Taylor expansion is performed, the constraints are linearized, if I 
understand correctly.}

Note that the system matrix is sparse, which can be exploited by sparse-matrix solvers in order to solve the system efficiently
\cite{baraff1996}. Alternatively, the Schur complement can be constructed since the mass matrix in the upper left block is invertible.
This leads to a smaller, albeit less sparse system \cite{tournier2015}:

\[
    \bm{JM^{-1}J^T \mu} = \bm{-JM^{-1}(p + } h \bm{f_e)}
\]

If the constraints are not redundant, $\bm{JM^{-1}J^T}$ is non-singular and symmetric positive definite \cite{baraff1996}, which are desirable
properties for many solvers. According to \cite{servin2006}, the common approaches for linearizing the constraint forces and stabilizing 
the constraints $\bm{\phi(x)} = 0$ are notoriously unstable \textcolor{red}{(I need to look this up again. I do not understand what exactly 
this means anymore)}. Additionally, instabilities in the traverse direction of the constraints occur when the tensile force with respect to 
particle masses is large when using hard constraints \cite{tournier2015}.

\subsubsection*{Compliant Constraints}
By combining ideas from hard constraints (\cref{sss:hard-constraints}) and penalty forces (\cref{ss:penalty-forces}), it is possible to 
formulate the system matrix for hard constraints such that constraints do not have to be enforced exactly. In this approach, called compliant 
constraints, the constraints are combined with the Newton's ODE \textcolor{red}{(Maybe refer to Newton's ODE here and don't rewrite it
again)} in a way that allows relaxation of constraints in a physically meaningful manner \cite{servin2006}. The key insight is that constraints 
of the form $\bm{\phi(x)}$ are the physical limit of strong potential forces of the form $\frac{k}{2}\bm{\phi^2(x)}$ with high stiffness values 
$k$. However, using large, but finite, stiffness values has adverse affects on the numerical properties of the system matrix 
(\cref{ss:stiff-springs}). Thus, the equations of motion are rewritten in terms of the inverse stiffness. The potential energy for the 
constraint $\bm{\phi}$ is then defined as:

\[
    U(\bm{x}) = \frac{1}{2}\bm{\phi^T(x)} \alpha^{-1}\bm{\phi(x)}
\]

where $\alpha$ is a symmetric, positive definite matrix of dimension $n_c \times n_c$ \textcolor{red}{(If I recall correctly, $\alpha$ can only
ever be a matrix if we are dealing with constraints that map to vectors. This will never be the case in this thesis, so the formulation should
be adapted so that $\alpha$ is simply a scalar)}. The correspondence to the penalty terms above is the case where $\alpha^{-1}$ is a diagonal 
matrix with diagonal entries $\frac{1}{k_i}$ for the stiffness $k_i$ of constraint $\bm{\phi(x)}$. The resulting forces $\bm{f_c} = \delta U / 
\delta \bm{x} = -J^T\alpha^{-1} \bm{\phi}$. In order to replace the large parameters $\alpha^{-1}$ with the small $\alpha$ in the equations of 
motion, artificial variables $\lambda = -\alpha^{-1}\bm{\phi}$ are introduced, yielding $\bm{f_c} = J^T\lambda$.

This leads to the following DAE:

\begin{align*}
    \bm{\dot{x}} &= \bm{v} \\
    \bm{M\dot{v}} &= \bm{f_{e} + J^T\lambda} \\
    \alpha\lambda(\bm{x}, t) &= -\bm{\phi}(\bm{x}, t)
\end{align*}

Note, that in the limit of infinite stiffness, the formulation from hard constraints is recovered. By performing backwards differentiation and 
assuming that the constraint gradients are constant across the timestep, it is:

\[
    \bm{\alpha\lambda_{n+1}} = \bm{C}\frac{\bm{\mu_{n+1}}}{h} = -\bm{\phi_{n+1}} \approx -\bm{\phi} - h\bm{Jv_{n+1}}
\]

leading to the following LSE \cite{tournier2015}:

\[
\begin{pmatrix}
    \bm{M} & \bm{-J^T} \\
    \bm{J} & \frac{1}{h^2}\bm{\alpha}
\end{pmatrix}
\begin{pmatrix}
    \bm{v_{n+1}} \\
    \bm{\mu_{n+1}}
\end{pmatrix}
=
\begin{pmatrix}
    \bm{p} + h\bm{f_e} \\
    - \frac{1}{h}\bm{\phi}
\end{pmatrix}
\]

\textcolor{red}{Regarding the backwards differentiation above, this does not perform the Taylor approximation again. It should be something
like:
\begin{align*}
    \phi_+ \approx \phi + h\dot{\phi_+} &= \phi + hJ_+v_+ \\
                                        &\approx \phi + h(J + h\dot{J})v_+ \\
                                        &= \phi + h(J + h\frac{\delta J}{\delta x}\frac{\delta x}{\delta t})v_+ \\
                                        &= \phi + h(J + h\frac{\delta J}{\delta x}v)v_+
\end{align*}
Now, we need second derivatives of the constraints. This can be seen in \cite{baraff1998} and is also mentioned in \cite{servin2006}.
}

This formulation comes with a couple of advantages. Firstly, relaxing the constraints by keeping a finite but large penalty parameter helps
counteracting numerical problems in the presence of over defined or degenerate constraints. Secondly, in comparison to the system from hard
constraints, introducing $\alpha$ in the lower right block of the system matrix makes the system matrix strongly positive definite, which 
is beneficial for many solvers. Lastly, in comparison to penalty forces, entries of large magnitudes in the system matrix due to high 
stiffness terms are exchanged for small entries in terms of inverse stiffness, which improves the condition number of the matrix. 

\textcolor{red}{
    All these concepts from numerics are a bit unclear to me. I might have to go back to some textbook and do some reading to improve my understanding. 
    I might have to go back to some textbook and do some reading to improve my understanding. Not sure the last part is entirely true.}

\textcolor{red}{
    In \cite{servin2006}, a solver based on symplectic Euler which does not require second derivatives is derived. I do not understand some of the
    estimations made in that derivation. In particular the mean of a function $f$ over and interval $(a, b)$ is defined as $\frac{1}{b-a}
    \int_a^b f(x) dx$, so what they are saying does not make a lot of sense.}


\section{Projective Dynamics}\label{s:pd}

In the approaches to physical simulations via implicit time integration that we have encountered so far, a new linear system needs to be solved
at every timestep. If the linear system is solved directly, this can quickly become prohibitively expensive for large simulations since 
a new matrix factorization needs to be computed every time a new sytem needs to be solved. In PBD, this issue is dealt with by using an iterative 
solver. In Projective Dynamics (\emph{PD}\index{PD}), a different approach is used. Energy potentials are restricted to a specific structure which allow for 
efficient implicit time integration via alternating steps of local and global optimization \cite{bouaziz2014}. The local optimization 
steps are comprised of 
per-constraint projections of particle positions onto constraint manifolds. The global optimization step combines the results from the individual 
local projection steps while taking into consideration global effects including inertia and external forces. This is achieved by solving a 
linear system of equations whose system matrix is constant across timesteps. Since the local steps can be carried out in parallel and the 
factorization for the system matrix of the global step can be precomputed and reused, physical simulations that are restricted to energy potentials 
from the PD framework can be solved efficienty.

\subsection{Energy Potentials}\label{ss:pd-potentials}

Let the positions of $m$ particles in a mesh be stored in a matrix $\bm{q} \in \mathbb{R}^{m \times 3}$ with deformation gradient $\bm{F} 
\coloneqq \bm{F(\bm{q})} \in \mathbb{R}^{3 \times 3}$. Then, energy potentials of the general form $\psi(\bm{E}(\bm{F}))$, where 
$\bm{E}(\bm{F})$ is a strain measure that depends on the deformation gradient of a discrete element, are frequently used in nonlinear 
continuum mechanics. If $\bm{E}$ is Green's strain measure $\bm{E_{\text{Green}}}$ defined by 

\[
\bm{E_{\text{Green}}}(\bm{F}) = \frac{1}{2}(\bm{F^TF} - \bm{I})
\]

\noindent then $\bm{E_{\text{Green}}}(\bm{F}) = 0$ is equivalent to $\bm{F^TF} = \bm{I}$. Thus, $\bm{E_{\text{Green}}}(\bm{F}) = 0$ defines a constraint
manifold that accepts deformations whose deformation gradients $\bm{F}$ are rotation matrices. These deformations are exactly the rigid-body 
transforms, i.e. transforms that alter the body's position and orientation but keep the body's volume undeformed. Assuming that $\psi(\bm{0}) 
= \rho$ for some $\rho \in \mathbb{R}$ and that $\psi$ reaches its minimum at the undeformed configuration, then 

\[
    d(\bm{E_{\text{Green}}}(\bm{F})) = \psi(\bm{E_{\text{Green}}}(\bm{F})) - \rho
\]

\noindent can be considered a distance measure of how far the configuration is away from the constraint manifold defined by the undeformed 
configurations. 

The energy potentials in PD are designed to fit into this framework \cite{bouaziz2014}: Energy potentials are defined by a constraint 
manifold $\bm{C}$ -- which 
can be different from $\bm{E_{\text{Green}}(\bm{F})} = 0$ -- and a distance measure $d$ of the body's current configuration to that constraint 
manifold. Formally, this leads to energy potentials which of the 
following form:

\[
    \psi({\bm{q}}) = \min_{\bm{p}} d(\bm{q}, \bm{p}) + \delta_{\bm{C}}(\bm{p}).
\]

\noindent Here, $\bm{p} \in \mathbb{R}^{r \times 3}, r \in \mathbb{N}$ are auxiliary projection variables and $\delta_{\bm{C}}(\bm{p})$ is an indicator function with 

\[
    \delta_{\bm{C}}(\bm{p})= 
\begin{cases}
0,& \text{if } \bm{p} \text{ lies on the constraint manifold } \bm{C}\\
\infty,& \text{otherwise.}
\end{cases}
\]

\noindent Define $\bm{p_{\bm{q}}}$ such that $\psi({\bm{q}}) = d(\bm{q}, \bm{p_{\bm{q}}}) + \delta_{\bm{C}}(\bm{p_{\bm{q}}})$. Then obviously 
$\delta_{\bm{C}}(\bm{p_{\bm{q}}}) = 0$, meaning that $\bm{p_{\bm{q}}}$ lies on $\bm{C}$. Together, $\bm{p_{\bm{q}}}$ is the 
configuration on the constraint manifold $\bm{C}$ with minimal distance $d(\bm{q}, \bm{p_{\bm{q}}})$ to current configuration $\bm{q}$.
Consequently, $\psi(\bm{q})$ measures the distance of $\bm{q}$ to the constraint manifold $\bm{C}$.

The authors claim that since the constraint manifolds already capture nonlinearities the need for complicated distance functions $d$
can be relaxed while still achieving visually plausible simulations \cite{bouaziz2014}. In PD, distance measures $d$ are restricted to 
quadratic functions of the form

\begin{equation}\label{eq:pd-distance-measures}
    d(\bm{q}) = \frac{w}{2} \norm{\bm{Gq} - \bm{p}}^2_F,
\end{equation}

\noindent where $\bm{G} \in \mathbb{R}^{r \times m}$ for some $r \in \mathbb{N}$ and $w$ is the constraint stiffness. In summary, PD 
energy potentials have the following form:

\begin{equation}\label{eq:pd-potentials}
    \psi({\bm{q}}) = \min_{\bm{p}} \frac{w}{2} \norm{\bm{Gq} - \bm{p}}^2_F + \delta_{\bm{C}}(\bm{p}).
\end{equation}

\subsection{Projective Implicit Euler Solver}\label{ss:pd-solver}
We start by substituting the PD energy potentials (\cref{eq:pd-potentials}) into the variatonal form of implicit Euler integration
(\cref{eq:variational-implicit}), which yields the following joint 
optimization problem over the positions $\bm{q}_{n+1}$ and auxiliary variables $\bm{p}_i$ and write $\bm{q} \coloneqq \bm{q}_{n+1}$ 
for the sake of brevity

\begin{equation}\label{eq:pd-minimization}
    \min_{\bm{q}, \bm{p_i}} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_i \frac{w_i}{2} \norm{\bm{G}_i\bm{q}
    - \bm{p_i}}^2_F + \delta_{\bm{C}_i}(\bm{p_i}).
\end{equation}

\noindent This optimization problem is optimized using a local/global alternating minimization technique. Local and global steps 
are carried out sequentially for a fixed number of iterations during each timestep. 

The local step consists of minimizing the objective function \cref{eq:pd-minimization} over 
the auxiliary variables $\bm{p}_i$ while keeping the positions $\bm{q}$ fixed. This corresponds to finding the projection points of 
the current positions onto the constraint manifolds used to define the PD energy potentials. Each constraint has its own 
set of auxiliary variables, meaning that the projection steps can be carried out independently. For each energy potential, we solve the 
following minimization problem

\begin{equation}\label{eq:pd-local-minimization}
    \min_{\bm{p}_i} \frac{w_i}{2}\norm{\bm{G}_i\bm{q} - \bm{p}_i}^2_F + \delta_{\bm{C}_i}(\bm{p}_i).
\end{equation}

In the global step, the minimization problem \cref{eq:pd-minimization} is optimized over the positions $\bm{q}$ while keeping the auxiliary 
variables $\bm{p}_i$ fixed.
This corresponds to moving the positions $\bm{q}$ according to their momentum and external forces while trying to maintain short distances
to the projections points as defined by the distance measures of the PD energy potentials. The optimization problem for the global solve is 
given by

\begin{equation}\label{eq:pd-global-minimization}
    \min_{\bm{q}} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_i \frac{w_i}{2} \norm{\bm{G}_i\bm{q} - \bm{p_i}}^2_F.
\end{equation}

\noindent By design of the PD energy potentials, the objective function of the global optimization problem is quadratic in the positions 
$\bm{q}$. Consequently, the minimization can be carried out in a single step by picking $\bm{q}$ such that the first-order optimality 
conditions are satisfied \cite{nocedal2006}. This requires solving the linear system

\begin{equation}\label{eq:pd-global-system}
    (\frac{\bm{M}}{h^2} + \sum_i w_i \bm{G}_i^T \bm{G}_i)\bm{q} = \frac{\bm{M}}{h^2}\bm{s}_n + \sum_i w_i \bm{G}_i^T \bm{p}_i.
\end{equation}

Note that the system matrix is constant as long as the constraint set remains unchanged. The right side needs to be recomputed in every 
iteration as the projections $\bm{p}_i$ change during the local optimization steps.  An overview over the algorithm is given in \cref{alg:pd}.

\begin{algorithm}
\caption{Projective Implicit Euler Solver}\label{alg:pd}
\begin{algorithmic}
\State $\bm{s}_n \gets \bm{q}_n + h\bm{v}_n + h^2\bm{M}^{-1}\bm{f}_{\text{ext}}$
\State $\bm{q}_{n+1} = \bm{s}_n$
\For{all iterations}
\For{constraints $i$}
\State $\bm{p}_i = \text{ProjectOnConstraintSet}(\bm{C}_i, \bm{q}_{n+1}) $
\EndFor
\State $\bm{q}_{n+1} = \text{SolveLinearSystem}(\bm{s}_n, \bm{p}_1, \bm{p}_2, \ldots) $
\EndFor
\State $\bm{v}_{n+1} = (\bm{q}_{n+1} - \bm{q}_n) / h$
\end{algorithmic}
\end{algorithm}

\subsection{Properties of Projective Dynamics}\label{ss:pd-properties}
The structure of the PD energy potentials allows for \cref{alg:pd} to be implemented efficiently. Since the constraint projections
in \cref{eq:pd-local-minimization} can be carried out independently, the local optimization step lends itself to massive parallelization. 
Further, because the system matrix in \cref{eq:pd-global-system} is constant its prefactorization can be computed at initialization, enabling
efficient solves of the linear system in the global optimization step. Note that since $\bm{q} \in \mathbb{R}^{m \times 3}$ in \cref{eq:pd-global-system}, 
the global system can be solved independently and in parallel for each coordinate.

The last property follows from the fact that the distance measure $d$ in \cref{eq:pd-distance-measures} has no dependencies between 
$x$-, $y$- and $z$-coordinates. This detail demonstrates that restricting to PD energy potentials comes at the cost of generality: 
Many arbitrary nonlinear elastic potentials, particulary those that have dependencies between $x$-, $y$- and $z$-coordinates, cannot be expressed 
in terms of PD elastic potentials. Additionally, many classical energies like the Neo-Hookean and St.\ Venant-Kirchoff energies do not fit 
into the PD framework \cite{liu2017}. On the other hand, the authors show that various different types of constraints, including strain constraints, 
bending constraints, collisions and positional constraints can be expressed in terms of PD potentials and handled by the PD solver in a 
unified manner \cite{bouaziz2014}. Where applicable, the constraints are derived from continuous energies, leaving them reasonably independent 
to the underlying meshing.

It is also important to note that it is impossible to implement hard constraints via energy potentials. Increasing
the weights of constraints allows approximating hard constraints. However, this comes with adverse effects to the numerical properties of the 
system matrix in \cref{eq:pd-global-system}.

While a simplified minimization problem is constructed by restricting to PD energy potentials, the solver does converge to a 
true solution of \cref{eq:pd-minimization}. That means that the solution strikes a balance between preserving 
the momenta of particles while minimizing the energy potentials. The objective function is quadratic, bounded below and both local and 
global steps are guaranteed to weakly decrease it. As a result, the optimization converges without additional safeguards, even if 
non-convex constraint manifolds are used in the energy potentials.

The PD solver (\cref{alg:pd}) performs implicit integration and introduces numerical damping as a result (see \cref{ss:implicit-euler}).
According to \cite{bouaziz2014}, this is particularly severe when the optimization is terminated early and large meshes are used. One possible
explanation is that external forces might not be able to propagate fully through the mesh if the optimization is not run for enough iterations
\cite{bouaziz2014} \textcolor{red}{(Investigate this with experiments!!!)}.

Lastly, it is important to note that the PD solver is not suited for handling frequently changing constraint sets. For example, every time 
a collision is detected, a new constraint needs to be added to the simulation and the global system matrix from \ref{eq:pd-global-system} needs
to be refactorized. This can slow down the PD solver quite significantly and lead to unpredictable solver speeds that are infeasible in the
context of real-time simulations.

\begin{itemize}
    \item \textcolor{red}{Not sure whether comparisons to the Newton solver belong here or not. Leave them as bullet points for now.}
    \item In terms of iterations, of course inferior to a Newton solver since the PD solver only exhibits linear convergence. 
        Either way, after a couple of iterations of the PD solver, the results are visually 
        indistinguishable from the true solution computed by Newton's method.
    \item Simplicity. Much easier than implementing a Newton solver, which requires second derivatives, a line search and possible 
        Hessian modifications if the Hessian is not positive definite. 
\end{itemize}

\subsection{Projective Dynamics as a Special Case of Quasi-Newton Methods}\label{ss:pd-quasi-newton}
In PD, the variational form of implicit Euler integration that results from restricting to PD energy potentials (\cref{eq:pd-minimization}) 
is solved by using a specialized local/global alternating minimization technique (\cref{ss:pd-solver}). If the projection points 
$\bm{p}^i_{\bm{q}}$ with 

\[
    \psi_i({\bm{q}}) = \min_{\bm{p}} \frac{w_i}{2} \norm{\bm{Gq} - \bm{p}}^2_F + \delta_{\bm{C}}(\bm{p})
    = \frac{w_i}{2} \norm{\bm{Gq} - \bm{p}^i_\bm{q}}^2_F
\]

\noindent are considered functions of $\bm{q}$ with $\bm{p}_i(\bm{q}) = \bm{p}^i_{\bm{q}}$, then the equivalent optimization problem

\begin{equation}\label{eq:pd-minimization-q}
    \min_{\bm{q}} \frac{1}{2h^2} \norm{\bm{M}^{1/2}(\bm{q} - \bm{s}_n)}^2_F + \sum_i \frac{w_i}{2} \norm{\bm{G}_i\bm{q}
    - \bm{p_i}(\bm{q})}^2_F
\end{equation}

\noindent can be solved using general purpose algorithms for unconstrained optimization, including Newton's method (\cref{sss:newton-method}),
the BFGS method (\cref{sss:quasi-newton}) or the L-BFGS method (\cref{sss:limited-memory-quasi-newton}). In fact, it can be shown that
the PD solver applied to \cref{eq:pd-minimization} is a special case of a Quasi-Newton method with constant Hessian approximation 
applied to \cref{eq:pd-minimization-q} \cite{liu2017}. This allows improving the performance of PD by applying insights from the unconstrained 
optimization literature. Additionally, since Quasi-Newton methods can be applied to the variational form of implicit Euler integration
with general conservative energy potentials (\cref{eq:variational-implicit}), this suggests a natural extension of PD to energies that
do not fit into the original PD framework.














